{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating - single feature, single label dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Without standard scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.round(np.random.uniform(0,5, size= 1000), 3)\n",
    "\n",
    "a, b  = np.random.normal(0, 0.1), np.random.normal(0, 0.2)#y_pred = a+ bx\n",
    "error = np.random.normal(0, 1, size= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.634</td>\n",
       "      <td>-0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.095</td>\n",
       "      <td>-0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.865</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.968</td>\n",
       "      <td>1.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.029</td>\n",
       "      <td>1.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features  targets\n",
       "0     1.634   -0.840\n",
       "1     1.095   -0.810\n",
       "2     4.865    0.510\n",
       "3     1.968    1.468\n",
       "4     0.029    1.850"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f= lambda x,e : np.round(a +b*x + e, 3)\n",
    "data = pd.DataFrame({'features': X, 'targets':f(X, error)})\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"reg_sim_data.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "feats, targets= data['features'].values, data['targets'].values\n",
    "feats= sm.add_constant(feats, prepend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.020\n",
      "Model:                            OLS   Adj. R-squared:                  0.019\n",
      "Method:                 Least Squares   F-statistic:                     20.34\n",
      "Date:                Mon, 23 Mar 2020   Prob (F-statistic):           7.24e-06\n",
      "Time:                        08:44:21   Log-Likelihood:                -1454.1\n",
      "No. Observations:                1000   AIC:                             2912.\n",
      "Df Residuals:                     998   BIC:                             2922.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.1044      0.023      4.510      0.000       0.059       0.150\n",
      "const          0.1640      0.066      2.490      0.013       0.035       0.293\n",
      "==============================================================================\n",
      "Omnibus:                        2.545   Durbin-Watson:                   1.955\n",
      "Prob(Omnibus):                  0.280   Jarque-Bera (JB):                2.374\n",
      "Skew:                           0.057   Prob(JB):                        0.305\n",
      "Kurtosis:                       2.790   Cond. No.                         6.26\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Without standard scaling of data\n",
    "model_stm = sm.OLS(targets, feats, hasconst=True)\n",
    "result= model_stm.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference values from simulated dataset weight : 0.10458035217582123 & bias: 0.11878560346515568\n"
     ]
    }
   ],
   "source": [
    "#Without standard scaling of data\n",
    "print('Reference values from simulated dataset weight : {} & bias: {}'.format(b,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toynet(\n",
       "  (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "class toynet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(toynet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1,1)\n",
    "        torch.nn.init.xavier_normal_(self.fc1.weight)\n",
    "    def forward(self, x):\n",
    "        x= self.fc1(x)\n",
    "        return x\n",
    "\n",
    "model = toynet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(df, count):\n",
    "    idx= np.random.randint(df.shape[0], size=count)\n",
    "    x,y = df.values[idx][:,0].reshape(-1,1), df.values[idx][:,1]\n",
    "    return x,y\n",
    "\n",
    "def eval_hessian(loss_grad, model):\n",
    "    cnt = 0\n",
    "    for g in loss_grad:\n",
    "        g_vector = g.contiguous().view(-1) if cnt == 0 else torch.cat([g_vector, g.contiguous().view(-1)])\n",
    "        cnt = 1\n",
    "    l = g_vector.size(0)\n",
    "    hessian = torch.zeros(l, l)\n",
    "    for idx in range(l):\n",
    "        grad2rd = torch.autograd.grad(g_vector[idx], model.parameters(), create_graph=True)\n",
    "        cnt = 0\n",
    "        for g in grad2rd:\n",
    "            g2 = g.contiguous().view(-1) if cnt == 0 else torch.cat([g2, g.contiguous().view(-1)])\n",
    "            cnt = 1\n",
    "        hessian[idx] = g2\n",
    "    return hessian.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  2.4449501037597656\n",
      "epoch:  500  loss:  1.2961708307266235\n",
      "epoch:  1000  loss:  1.3966047763824463\n",
      "epoch:  1500  loss:  1.5072994232177734\n",
      "epoch:  2000  loss:  1.6176228523254395\n",
      "epoch:  2500  loss:  1.184489130973816\n",
      "epoch:  3000  loss:  0.8819632530212402\n",
      "epoch:  3500  loss:  0.8783103227615356\n"
     ]
    }
   ],
   "source": [
    "wts_bias_progression= list()\n",
    "all_grads= list()\n",
    "losses= list()\n",
    "\n",
    "d2loss_dg= list()\n",
    "diags= list()\n",
    "f= lambda x: np.sqrt(np.abs(np.diag(np.linalg.inv(x)))).tolist()\n",
    "\n",
    "for epoch in range(4000):\n",
    "    x_, y_ = sample(data, count= 64)\n",
    "    #x_,y_= data.values[:,0].reshape(-1,1), data.values[:,1]\n",
    "    trainx = Variable(torch.Tensor(x_).float(), requires_grad= True)\n",
    "    trainy = Variable(torch.reshape(torch.Tensor(y_).float(), (-1,1)))\n",
    "    optimizer.zero_grad()\n",
    "    y_pred= model(trainx)\n",
    "    \n",
    "    l = loss(y_pred, trainy)\n",
    "    losses.append(l.item())\n",
    "    if epoch%500==0:\n",
    "        print('epoch: ', epoch, ' loss: ', l.item());\n",
    "    \n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    wts_bias = list(model.parameters())\n",
    "    wts_bias_vals= torch.cat((wts_bias[0], torch.reshape(wts_bias[1], (-1,1))),1)\n",
    "    wts_bias_progression.append(wts_bias_vals.tolist())\n",
    "    \n",
    "    wts_bias_grads = torch.cat((wts_bias[0].grad, torch.reshape(wts_bias[1].grad, (-1,1))),1)\n",
    "    #i_grads= trainx.grad\n",
    "    all_grads.append(wts_bias_grads.tolist())#i_grads)\n",
    "    d1loss_dg = torch.autograd.grad(loss(model(trainx), trainy), wts_bias, create_graph=True)\n",
    "    d2loss_dg.append(eval_hessian(d1loss_dg, model))\n",
    "    diags.append(f(d2loss_dg[-1]))\n",
    "\n",
    "all_wts_bias = np.array(wts_bias_progression).reshape(-1,wts_bias_vals.shape[1])\n",
    "all_wts_bias_df= pd.DataFrame(all_wts_bias, columns=['weight_{}'.format(idx) for idx in range(1,wts_bias_vals.shape[1])]+ ['bias'])\n",
    "\n",
    "all_grads = np.array(all_grads).reshape(-1,wts_bias_vals.shape[1])\n",
    "all_grads_df= pd.DataFrame(all_grads, columns=['beta_{}'.format(idx) for idx in range(1,wts_bias_vals.shape[1]+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.1043]], requires_grad=True), Parameter containing:\n",
       " tensor([0.1559], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytical standard error & T-value for b (slope estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023173378506969208"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#S_b calc\n",
    "sum_sqr_err = (1/(data['features'].shape[0] - 2))*(np.sum(error**2))\n",
    "sum_sqr_diffx = np.sum((data['features'].values - np.mean(data['features'].values))**2)\n",
    "s_beta = np.sqrt(sum_sqr_err/sum_sqr_diffx)\n",
    "s_beta\n",
    "#(1/(1000-2))*(np.sum(error**2))/np.sum((data['features'].values - np.mean(data['features'].values))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0112]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_pred = list(model.parameters())[0] \n",
    "t= (b_pred - b)/s_beta\n",
    "t#t-val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Pytorch Standar error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batches= list()#contains mini_batches of gradients from 200 epochs\n",
    "mean_mini_batches= list()#contains mean of each of 200 epochs each in a mini_batches of gradients from 200 epochs\n",
    "mini_size= 200\n",
    "for batch in range(1, (len(all_grads))//mini_size):\n",
    "    mini_batches.append(all_grads[batch*mini_size:batch*mini_size+ mini_size])\n",
    "    mean_mini_batches.append(np.mean(mini_batches[-1], axis=0).tolist())\n",
    "\n",
    "grad_mini_batch_arr = np.array(mean_mini_batches).T\n",
    "grad_mini_batch_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35230668, 0.09230267])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariant_mat= np.cov(grad_mini_batch_arr)\n",
    "pytorch_stderr= np.sqrt(covariant_mat.diagonal())#**2\n",
    "pytorch_stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stasmodel vs Pytorch comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>x1</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.023</td>\n",
       "      <td>4.510</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>const</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.066</td>\n",
       "      <td>2.490</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef    std err          t   P>|t|     [0.025     0.975]\n",
       "0     x1      0.1044      0.023      4.510   0.000      0.059      0.150\n",
       "1  const      0.1640      0.066      2.490   0.013      0.035      0.293"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary= result.summary()\n",
    "statsm_df = pd.DataFrame(summary.tables[1].data[1:], columns=summary.tables[1].data[0])\n",
    "statsm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pytorch_grads</th>\n",
       "      <th>simulated_params</th>\n",
       "      <th>pytorch_params</th>\n",
       "      <th>statsmodel_params</th>\n",
       "      <th>statsmodel_stderr</th>\n",
       "      <th>pytorch_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>b (slope/weight)</td>\n",
       "      <td>-1.481094</td>\n",
       "      <td>0.104580</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.352307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a (intercept/bias)</td>\n",
       "      <td>-0.359463</td>\n",
       "      <td>0.118786</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.092303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pytorch_grads  simulated_params  pytorch_params  \\\n",
       "b (slope/weight)        -1.481094          0.104580           0.104   \n",
       "a (intercept/bias)      -0.359463          0.118786           0.156   \n",
       "\n",
       "                    statsmodel_params statsmodel_stderr  pytorch_stderr  \n",
       "b (slope/weight)                0.104             0.023        0.352307  \n",
       "a (intercept/bias)              0.164             0.066        0.092303  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di = dict(zip('pytorch_grads,simulated_params,pytorch_params,statsmodel_params,statsmodel_stderr'.split(','), [all_grads[-1,:], [b,a], all_wts_bias[-1,:], result.params, statsm_df[\"std err\"].values]))#all_grads\n",
    "di.update({'pytorch_stderr':pytorch_stderr})\n",
    "comp_df = pd.DataFrame(di, index=['b (slope/weight)','a (intercept/bias)'])\n",
    "#comp_df['pytorch_stderr']= pytorch_stderr\n",
    "comp_df['pytorch_params'] = comp_df['pytorch_params'].apply(lambda x:np.round(x,3))\n",
    "comp_df['statsmodel_params'] = comp_df['statsmodel_params'].apply(lambda x:np.round(x,3))\n",
    "#comp_df['Simulated_params']= [b,a]\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **With Standard scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.588673</td>\n",
       "      <td>-1.205922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.969278</td>\n",
       "      <td>-1.177249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.692836</td>\n",
       "      <td>0.084374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.352825</td>\n",
       "      <td>1.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.722013</td>\n",
       "      <td>1.365112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features   targets\n",
       "0 -0.588673 -1.205922\n",
       "1 -0.969278 -1.177249\n",
       "2  1.692836  0.084374\n",
       "3 -0.352825  1.000006\n",
       "4 -1.722013  1.365112"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "data_trans = data.copy()\n",
    "trans_mat = sc.fit_transform(data_trans)\n",
    "data_trans['features'] = trans_mat[:,0]\n",
    "data_trans['targets']= trans_mat[:,1]\n",
    "data_trans.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.020\n",
      "Model:                            OLS   Adj. R-squared:                  0.019\n",
      "Method:                 Least Squares   F-statistic:                     20.34\n",
      "Date:                Mon, 23 Mar 2020   Prob (F-statistic):           7.24e-06\n",
      "Time:                        08:46:02   Log-Likelihood:                -1408.8\n",
      "No. Observations:                1000   AIC:                             2822.\n",
      "Df Residuals:                     998   BIC:                             2832.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.1413      0.031      4.510      0.000       0.080       0.203\n",
      "const               0      0.031          0      1.000      -0.061       0.061\n",
      "==============================================================================\n",
      "Omnibus:                        2.545   Durbin-Watson:                   1.955\n",
      "Prob(Omnibus):                  0.280   Jarque-Bera (JB):                2.374\n",
      "Skew:                           0.057   Prob(JB):                        0.305\n",
      "Kurtosis:                       2.790   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#With standard scaling of data\n",
    "feats, targets= data_trans['features'].values, data_trans['targets'].values\n",
    "feats= sm.add_constant(feats, prepend=False)\n",
    "\n",
    "model_stm = sm.OLS(targets, feats, hasconst=True)\n",
    "result_sc= model_stm.fit()\n",
    "print(result_sc.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference values from simulated dataset weight : 0.10458035217582123 & bias: 0.11878560346515568\n"
     ]
    }
   ],
   "source": [
    "#With standard scaling of data\n",
    "print('Reference values from simulated dataset weight : {} & bias: {}'.format(b,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sc = toynet()\n",
    "\n",
    "optimizer_sc = optim.Adam(model_sc.parameters())\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  2.634622097015381\n",
      "epoch:  500  loss:  1.6234681606292725\n",
      "epoch:  1000  loss:  1.1310476064682007\n",
      "epoch:  1500  loss:  0.9287221431732178\n",
      "epoch:  2000  loss:  0.8867921233177185\n",
      "epoch:  2500  loss:  1.0071184635162354\n",
      "epoch:  3000  loss:  0.9728839993476868\n",
      "epoch:  3500  loss:  1.019735336303711\n"
     ]
    }
   ],
   "source": [
    "wts_bias_progression= list()\n",
    "all_grads= list()\n",
    "losses= list()\n",
    "\n",
    "d2loss_dg= list()\n",
    "diags= list()\n",
    "f= lambda x: np.sqrt(np.abs(np.diag(np.linalg.inv(x)))).tolist()\n",
    "\n",
    "for epoch in range(4000):\n",
    "    x_, y_ = sample(data_trans, count= 64)\n",
    "    #x_,y_= data.values[:,0].reshape(-1,1), data.values[:,1]\n",
    "    trainx = Variable(torch.Tensor(x_).float(), requires_grad= True)\n",
    "    trainy = Variable(torch.reshape(torch.Tensor(y_).float(), (-1,1)))\n",
    "    optimizer_sc.zero_grad()\n",
    "    y_pred= model_sc(trainx)\n",
    "    \n",
    "    l = loss(y_pred, trainy)\n",
    "    losses.append(l.item())\n",
    "    if epoch%500==0:\n",
    "        print('epoch: ', epoch, ' loss: ', l.item());\n",
    "    \n",
    "    l.backward()\n",
    "    optimizer_sc.step()\n",
    "    \n",
    "    wts_bias = list(model_sc.parameters())\n",
    "    wts_bias_vals= torch.cat((wts_bias[0], torch.reshape(wts_bias[1], (-1,1))),1)\n",
    "    wts_bias_progression.append(wts_bias_vals.tolist())\n",
    "    \n",
    "    wts_bias_grads = torch.cat((wts_bias[0].grad, torch.reshape(wts_bias[1].grad, (-1,1))),1)\n",
    "    #i_grads= trainx.grad\n",
    "    all_grads.append(wts_bias_grads.tolist())#i_grads)\n",
    "    d1loss_dg = torch.autograd.grad(loss(model_sc(trainx), trainy), wts_bias, create_graph=True)\n",
    "    d2loss_dg.append(eval_hessian(d1loss_dg, model_sc))\n",
    "    diags.append(f(d2loss_dg[-1]))\n",
    "\n",
    "all_wts_bias = np.array(wts_bias_progression).reshape(-1, wts_bias_vals.shape[1])\n",
    "all_wts_bias_df= pd.DataFrame(all_wts_bias, columns=['weight_{}'.format(idx) for idx in range(1,wts_bias_vals.shape[1])]+ ['bias'])\n",
    "\n",
    "all_grads = np.array(all_grads).reshape(-1,wts_bias_vals.shape[1])\n",
    "all_grads_df= pd.DataFrame(all_grads, columns=['beta_{}'.format(idx) for idx in range(1,wts_bias_vals.shape[1]+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.1385]], requires_grad=True), Parameter containing:\n",
       " tensor([0.0001], requires_grad=True)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_sc.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytical standard error & T-value for b (slope estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03281739536037299"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#S_b calc\n",
    "sum_sqr_err = (1/(data_trans['features'].shape[0] - 2))*(np.sum(error**2))\n",
    "sum_sqr_diffx = np.sum((data_trans['features'].values - np.mean(data_trans['features'].values))**2)\n",
    "s_beta = np.sqrt(sum_sqr_err/sum_sqr_diffx)\n",
    "s_beta\n",
    "#(1/(1000-2))*(np.sum(error**2))/np.sum((data['features'].values - np.mean(data['features'].values))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0348]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_pred = list(model_sc.parameters())[0] \n",
    "t= (b_pred - b)/s_beta\n",
    "t#t-val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Pytorch Standar error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 19)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batches= list()#contains mini_batches of gradients from 200 epochs\n",
    "mean_mini_batches= list()#contains mean of each of 200 epochs each in a mini_batches of gradients from 200 epochs\n",
    "mini_size= 200\n",
    "for batch in range(1, (len(all_grads))//mini_size):\n",
    "    mini_batches.append(all_grads[batch*mini_size:batch*mini_size+ mini_size])\n",
    "    mean_mini_batches.append(np.mean(mini_batches[-1], axis=0).tolist())\n",
    "\n",
    "grad_mini_batch_arr = np.array(mean_mini_batches).T\n",
    "grad_mini_batch_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4363688 , 0.36669437])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariant_mat= np.cov(grad_mini_batch_arr)\n",
    "pytorch_stderr_sc= np.sqrt(covariant_mat.diagonal())#**2\n",
    "pytorch_stderr_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stasmodel vs Pytorch comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>x1</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.031</td>\n",
       "      <td>4.510</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>const</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef    std err          t   P>|t|     [0.025     0.975]\n",
       "0     x1      0.1413      0.031      4.510   0.000      0.080      0.203\n",
       "1  const           0      0.031          0   1.000     -0.061      0.061"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary= result_sc.summary()\n",
    "statsm_df = pd.DataFrame(summary.tables[1].data[1:], columns=summary.tables[1].data[0])\n",
    "statsm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pytorch_grads_sc</th>\n",
       "      <th>simulated_params_sc</th>\n",
       "      <th>pytorch_params_sc</th>\n",
       "      <th>statsmodel_params_sc</th>\n",
       "      <th>statsmodel_stderr_sc</th>\n",
       "      <th>pytorch_stderr_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>b (slope/weight)</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.104580</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.436369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a (intercept/bias)</td>\n",
       "      <td>-0.071120</td>\n",
       "      <td>0.118786</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.366694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pytorch_grads_sc  simulated_params_sc  pytorch_params_sc  \\\n",
       "b (slope/weight)           -0.002663             0.104580              0.139   \n",
       "a (intercept/bias)         -0.071120             0.118786              0.000   \n",
       "\n",
       "                    statsmodel_params_sc statsmodel_stderr_sc  \\\n",
       "b (slope/weight)                   0.141                0.031   \n",
       "a (intercept/bias)                 0.000                0.031   \n",
       "\n",
       "                    pytorch_stderr_sc  \n",
       "b (slope/weight)             0.436369  \n",
       "a (intercept/bias)           0.366694  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di = dict(zip('pytorch_grads_sc,simulated_params_sc,pytorch_params_sc,statsmodel_params_sc,statsmodel_stderr_sc'.split(','), [all_grads[-1,:], [b,a], all_wts_bias[-1,:], result_sc.params, statsm_df[\"std err\"].values]))#all_grads\n",
    "di.update({'pytorch_stderr_sc':pytorch_stderr_sc})\n",
    "comp_df_sc = pd.DataFrame(di, index=['b (slope/weight)','a (intercept/bias)'])\n",
    "#comp_df['pytorch_stderr']= pytorch_stderr\n",
    "comp_df_sc['pytorch_params_sc'] = comp_df_sc['pytorch_params_sc'].apply(lambda x:np.round(x,3))\n",
    "comp_df_sc['statsmodel_params_sc'] = comp_df_sc['statsmodel_params_sc'].apply(lambda x:np.round(x,3))\n",
    "#comp_df['Simulated_params']= [b,a]\n",
    "comp_df_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled vs. Unscaled parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pytorch_grads</th>\n",
       "      <th>simulated_params</th>\n",
       "      <th>pytorch_params</th>\n",
       "      <th>statsmodel_params</th>\n",
       "      <th>statsmodel_stderr</th>\n",
       "      <th>pytorch_stderr</th>\n",
       "      <th>pytorch_grads_sc</th>\n",
       "      <th>simulated_params_sc</th>\n",
       "      <th>pytorch_params_sc</th>\n",
       "      <th>statsmodel_params_sc</th>\n",
       "      <th>statsmodel_stderr_sc</th>\n",
       "      <th>pytorch_stderr_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>b (slope/weight)</td>\n",
       "      <td>-1.481094</td>\n",
       "      <td>0.104580</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.352307</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.104580</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.436369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a (intercept/bias)</td>\n",
       "      <td>-0.359463</td>\n",
       "      <td>0.118786</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.092303</td>\n",
       "      <td>-0.071120</td>\n",
       "      <td>0.118786</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.366694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pytorch_grads  simulated_params  pytorch_params  \\\n",
       "b (slope/weight)        -1.481094          0.104580           0.104   \n",
       "a (intercept/bias)      -0.359463          0.118786           0.156   \n",
       "\n",
       "                    statsmodel_params statsmodel_stderr  pytorch_stderr  \\\n",
       "b (slope/weight)                0.104             0.023        0.352307   \n",
       "a (intercept/bias)              0.164             0.066        0.092303   \n",
       "\n",
       "                    pytorch_grads_sc  simulated_params_sc  pytorch_params_sc  \\\n",
       "b (slope/weight)           -0.002663             0.104580              0.139   \n",
       "a (intercept/bias)         -0.071120             0.118786              0.000   \n",
       "\n",
       "                    statsmodel_params_sc statsmodel_stderr_sc  \\\n",
       "b (slope/weight)                   0.141                0.031   \n",
       "a (intercept/bias)                 0.000                0.031   \n",
       "\n",
       "                    pytorch_stderr_sc  \n",
       "b (slope/weight)             0.436369  \n",
       "a (intercept/bias)           0.366694  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([comp_df, comp_df_sc], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.round(np.random.uniform(0,5, size= 20), 3)\n",
    "\n",
    "a_s, b_s  = np.random.normal(0, 0.1), np.random.normal(0, 0.2)\n",
    "error_s = np.random.normal(0, 1, size= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.246088</td>\n",
       "      <td>1.880965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.903562</td>\n",
       "      <td>-1.152908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.848669</td>\n",
       "      <td>-0.900387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.114438</td>\n",
       "      <td>0.984018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.072415</td>\n",
       "      <td>-0.968269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.135371</td>\n",
       "      <td>-0.607137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.311990</td>\n",
       "      <td>0.521515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.781228</td>\n",
       "      <td>-0.041453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-0.360215</td>\n",
       "      <td>-0.654202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.182678</td>\n",
       "      <td>0.329635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-1.696872</td>\n",
       "      <td>0.078924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.703528</td>\n",
       "      <td>0.902559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>-1.154146</td>\n",
       "      <td>0.678096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>-1.061883</td>\n",
       "      <td>-0.871424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>-1.267343</td>\n",
       "      <td>-0.670493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>-0.650961</td>\n",
       "      <td>0.947814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.736867</td>\n",
       "      <td>1.459192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>-0.859523</td>\n",
       "      <td>-2.284275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.111181</td>\n",
       "      <td>-0.282208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.099885</td>\n",
       "      <td>0.650038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features   targets\n",
       "0   0.246088  1.880965\n",
       "1   0.903562 -1.152908\n",
       "2  -0.848669 -0.900387\n",
       "3  -0.114438  0.984018\n",
       "4   0.072415 -0.968269\n",
       "5  -0.135371 -0.607137\n",
       "6   0.311990  0.521515\n",
       "7   1.781228 -0.041453\n",
       "8  -0.360215 -0.654202\n",
       "9   1.182678  0.329635\n",
       "10 -1.696872  0.078924\n",
       "11  0.703528  0.902559\n",
       "12 -1.154146  0.678096\n",
       "13 -1.061883 -0.871424\n",
       "14 -1.267343 -0.670493\n",
       "15 -0.650961  0.947814\n",
       "16  0.736867  1.459192\n",
       "17 -0.859523 -2.284275\n",
       "18  0.111181 -0.282208\n",
       "19  2.099885  0.650038"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f= lambda x,e : np.round(a_s +b_s*x + e, 3)\n",
    "data_s = pd.DataFrame({'features': Xs, 'targets':f(Xs, error_s)})\n",
    "sc= StandardScaler()\n",
    "trans_mat_s = sc.fit_transform(data_s)\n",
    "\n",
    "data_s['features'] = trans_mat_s[:,0]\n",
    "data_s['targets']= trans_mat_s[:,1]\n",
    "\n",
    "data_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "feats_s, targets_s= data_s['features'].values, data_s['targets'].values\n",
    "feats_s= sm.add_constant(feats_s, prepend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.091\n",
      "Model:                            OLS   Adj. R-squared:                  0.041\n",
      "Method:                 Least Squares   F-statistic:                     1.812\n",
      "Date:                Mon, 23 Mar 2020   Prob (F-statistic):              0.195\n",
      "Time:                        09:23:04   Log-Likelihood:                -27.420\n",
      "No. Observations:                  20   AIC:                             58.84\n",
      "Df Residuals:                      18   BIC:                             60.83\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.3024      0.225      1.346      0.195      -0.170       0.774\n",
      "const               0      0.225          0      1.000      -0.472       0.472\n",
      "==============================================================================\n",
      "Omnibus:                        0.087   Durbin-Watson:                   2.152\n",
      "Prob(Omnibus):                  0.957   Jarque-Bera (JB):                0.307\n",
      "Skew:                          -0.067   Prob(JB):                        0.858\n",
      "Kurtosis:                       2.408   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Without standard_scaling of data\n",
    "model_stm_s = sm.OLS(targets_s, feats_s, hasconst=True)\n",
    "result_s= model_stm_s.fit()\n",
    "print(result_s.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From dataset weight : 0.10144210862371957 & bias: -0.2742068459149354\n"
     ]
    }
   ],
   "source": [
    "#Without standard_scaling of data\n",
    "print('From dataset weight : {} & bias: {}'.format(b_s,a_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s = toynet()\n",
    "optimizer_s = optim.Adam(model_s.parameters())\n",
    "loss_s = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  0.7195181250572205\n",
      "epoch:  500  loss:  0.8909294009208679\n",
      "epoch:  1000  loss:  0.9296377897262573\n",
      "epoch:  1500  loss:  0.38164255023002625\n",
      "epoch:  2000  loss:  0.6488150358200073\n",
      "epoch:  2500  loss:  0.4885692000389099\n",
      "epoch:  3000  loss:  0.9722121953964233\n",
      "epoch:  3500  loss:  1.1143834590911865\n"
     ]
    }
   ],
   "source": [
    "wts_bias_progression_s= list()\n",
    "all_grads_s= list()\n",
    "losses_s= list()\n",
    "\n",
    "d2loss_dg_s= list()\n",
    "diags_s= list()\n",
    "f= lambda x: np.sqrt(np.abs(np.diag(np.linalg.inv(x)))).tolist()\n",
    "\n",
    "for epoch in range(4000):\n",
    "    x_, y_ = sample(data_s, count= 8)\n",
    "    #x_,y_= data.values[:,0].reshape(-1,1), data.values[:,1]\n",
    "    trainx = Variable(torch.Tensor(x_).float(), requires_grad= True)\n",
    "    trainy = Variable(torch.reshape(torch.Tensor(y_).float(), (-1,1)))\n",
    "    optimizer_s.zero_grad()\n",
    "    y_pred= model_s(trainx)\n",
    "    \n",
    "    l = loss_s(y_pred, trainy)\n",
    "    losses_s.append(l.item())\n",
    "    if epoch%500==0:\n",
    "        print('epoch: ', epoch, ' loss: ', l.item());\n",
    "    \n",
    "    l.backward()\n",
    "    optimizer_s.step()\n",
    "    \n",
    "    wts_bias = list(model_s.parameters())\n",
    "    wts_bias_vals= torch.cat((wts_bias[0], torch.reshape(wts_bias[1], (-1,1))),1)\n",
    "    wts_bias_progression_s.append(wts_bias_vals.tolist())\n",
    "    \n",
    "    wts_bias_grads = torch.cat((wts_bias[0].grad, torch.reshape(wts_bias[1].grad, (-1,1))),1)\n",
    "    #i_grads= trainx.grad\n",
    "    all_grads_s.append(wts_bias_grads.tolist())#i_grads)\n",
    "    d1loss_dg_s = torch.autograd.grad(loss_s(model_s(trainx), trainy), wts_bias, create_graph=True)\n",
    "    d2loss_dg_s.append(eval_hessian(d1loss_dg_s, model_s))\n",
    "    diags_s.append(f(d2loss_dg_s[-1]))\n",
    "\n",
    "all_wts_bias_s = np.array(wts_bias_progression_s).reshape(-1,wts_bias_vals.shape[1])\n",
    "all_wts_bias_df_s= pd.DataFrame(all_wts_bias_s, columns=['weight_{}'.format(idx) for idx in range(1,wts_bias_vals.shape[1])]+ ['bias'])\n",
    "\n",
    "all_grads_s = np.array(all_grads_s).reshape(-1,wts_bias_vals.shape[1])\n",
    "all_grads_df_s= pd.DataFrame(all_grads_s, columns=['beta_{}'.format(idx) for idx in range(1,wts_bias_vals.shape[1]+1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating Pytorch Standar error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 19)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batches_s= list()#contains mini_batches of gradients from 200 epochs\n",
    "mean_mini_batches_s= list()#contains mean of each of 200 epochs each in a mini_batches of gradients from 200 epochs\n",
    "mini_size= 200\n",
    "for batch in range(1, (len(all_grads_s))//mini_size):\n",
    "    mini_batches_s.append(all_grads_s[batch*mini_size:batch*mini_size+ mini_size])\n",
    "    mean_mini_batches_s.append(np.mean(mini_batches_s[-1], axis=0).tolist())\n",
    "\n",
    "grad_mini_batch_arr_s = np.array(mean_mini_batches_s).T\n",
    "grad_mini_batch_arr_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09007549, 0.19764432])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariant_mat_s= np.cov(grad_mini_batch_arr_s)\n",
    "pytorch_stderr_s= np.sqrt(covariant_mat_s.diagonal())#**2\n",
    "pytorch_stderr_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>x1</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.225</td>\n",
       "      <td>1.346</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>const</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>0.472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef    std err          t   P>|t|     [0.025     0.975]\n",
       "0     x1      0.3024      0.225      1.346   0.195     -0.170      0.774\n",
       "1  const           0      0.225          0   1.000     -0.472      0.472"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_s= result_s.summary()\n",
    "statsm_df_s = pd.DataFrame(summary_s.tables[1].data[1:], columns=summary_s.tables[1].data[0])\n",
    "statsm_df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pytorch_grads</th>\n",
       "      <th>simulated_params</th>\n",
       "      <th>pytorch_params</th>\n",
       "      <th>statsmodel_params</th>\n",
       "      <th>statsmodel_stderr</th>\n",
       "      <th>pytorch_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>b (slope/weight)</td>\n",
       "      <td>-0.266607</td>\n",
       "      <td>0.101442</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.090075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a (intercept/bias)</td>\n",
       "      <td>0.256882</td>\n",
       "      <td>-0.274207</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.197644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pytorch_grads  simulated_params  pytorch_params  \\\n",
       "b (slope/weight)        -0.266607          0.101442           0.308   \n",
       "a (intercept/bias)       0.256882         -0.274207          -0.000   \n",
       "\n",
       "                    statsmodel_params statsmodel_stderr  pytorch_stderr  \n",
       "b (slope/weight)                0.302             0.225        0.090075  \n",
       "a (intercept/bias)              0.000             0.225        0.197644  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Without standard_scaling\n",
    "di_s = dict(zip('pytorch_grads,simulated_params,pytorch_params,statsmodel_params,statsmodel_stderr'.split(','), [all_grads_s[-1,:], [b_s,a_s], all_wts_bias_s[-1,:], result_s.params, statsm_df_s[\"std err\"].values]))#all_grads\n",
    "di_s.update({'pytorch_stderr':pytorch_stderr_s})\n",
    "comp_df_s = pd.DataFrame(di_s, index=['b (slope/weight)','a (intercept/bias)'])\n",
    "comp_df_s['pytorch_params'] = comp_df_s['pytorch_params'].apply(lambda x:np.round(x,3))\n",
    "comp_df_s['statsmodel_params'] = comp_df_s['statsmodel_params'].apply(lambda x:np.round(x,3))\n",
    "#comp_df['Simulated_params']= [b,a]\n",
    "comp_df_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standard error & T-value for b (slope estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2553713206689374"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#S_b calc\n",
    "sum_sqr_err_s = (1/(data_s['features'].shape[0] - 2))*(np.sum(error_s**2))\n",
    "sum_sqr_diffx_s = np.sum((data_s['features'].values - np.mean(data_s['features'].values))**2)\n",
    "s_beta_s = np.sqrt(sum_sqr_err_s/sum_sqr_diffx_s)\n",
    "s_beta_s\n",
    "#(1/(1000-2))*(np.sum(error**2))/np.sum((data['features'].values - np.mean(data['features'].values))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8091]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t-value = (b'- b)/(S_b)\n",
    "b_pred_s = list(model_s.parameters())[0] \n",
    "t_s= (b_pred_s - b_s)/s_beta_s\n",
    "t_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With standard_scaling & glorot normal kernel init, values of a & b vary farther from originally simulated for both pytorch & statsmodel\n",
    "* Statsmodel returned equal std error for a & b in case of both dataset_1 & dataset_2; Whereas pytroch std_Error values were different.\n",
    "* For dataset 1, pytorch a & b and statsmodel a & looked almost similar, but Both were far from simulated a & b vals.\n",
    "* For dataset 2, all 3 a & b pairs from simulated, pytorch & statsmodel differed significantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "178.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
