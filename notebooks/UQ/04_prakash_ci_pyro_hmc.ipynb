{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyro-ppl==1.3.0\n",
      "  Downloading pyro_ppl-1.3.0-py3-none-any.whl (495 kB)\n",
      "\u001b[K     |████████████████████████████████| 495 kB 658 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/numpy-1.17.3-py3.6-linux-x86_64.egg (from pyro-ppl==1.3.0) (1.17.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages (from pyro-ppl==1.3.0) (3.1.0)\n",
      "Requirement already satisfied: tqdm>=4.36 in /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages (from pyro-ppl==1.3.0) (4.41.1)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages (from pyro-ppl==1.3.0) (0.1.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages (from pyro-ppl==1.3.0) (1.4.0+cpu)\n",
      "Installing collected packages: pyro-ppl\n",
      "  Attempting uninstall: pyro-ppl\n",
      "    Found existing installation: pyro-ppl 1.3.1\n",
      "    Uninstalling pyro-ppl-1.3.1:\n",
      "      Successfully uninstalled pyro-ppl-1.3.1\n",
      "Successfully installed pyro-ppl-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyro-ppl==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrasting Pyro HMC Vs. statsmodel results\n",
    "**For a regression model trained on country topographical rugged index and GDP data.**\n",
    "\n",
    "#### A. Pyro model training & HMC sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "\n",
    "DATA_URL = \"https://d2hg8soec8ck9v.cloudfront.net/datasets/rugged_data.csv\"\n",
    "rugged_data = pd.read_csv(DATA_URL, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Define pyro model and guide:**\n",
    "    * Priors are deined in model function for intercept `b`, feature 1 `b_a`, feature 2 `b_r`, feature 3 `b_ar`\n",
    "    * mean is the expresion `f(feat1, feat2, feat3, b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(is_cont_africa, ruggedness, log_gdp):\n",
    "    b = pyro.sample(\"bias\", dist.Normal(0., 10.))\n",
    "    b_a = pyro.sample(\"feat_1\", dist.Normal(0., 1.))\n",
    "    b_r = pyro.sample(\"feat_2\", dist.Normal(0., 1.))\n",
    "    b_ar = pyro.sample(\"feat_3\", dist.Normal(0., 1.))\n",
    "    sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "    mean = b + b_a * is_cont_africa + b_r * ruggedness + b_ar * is_cont_africa * ruggedness\n",
    "    with pyro.plate(\"data\", len(ruggedness)):\n",
    "        pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=log_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def guide(is_cont_africa, ruggedness, log_gdp):\n",
    "    b_loc = pyro.param('bias_loc', torch.tensor(0.))\n",
    "    b_scale = pyro.param('bias_scale', torch.tensor(1.),\n",
    "                         constraint=constraints.positive)\n",
    "    sigma_loc = pyro.param('sigma_loc', torch.tensor(1.),\n",
    "                             constraint=constraints.positive)\n",
    "    weights_loc = pyro.param('weights_loc', torch.randn(3))\n",
    "    weights_scale = pyro.param('weights_scale', torch.ones(3),\n",
    "                               constraint=constraints.positive)\n",
    "    b = pyro.sample(\"bias\", dist.Normal(b_loc, b_scale))\n",
    "    b_a = pyro.sample(\"feat_1\", dist.Normal(weights_loc[0], weights_scale[0]))\n",
    "    b_r = pyro.sample(\"feat_2\", dist.Normal(weights_loc[1], weights_scale[1]))\n",
    "    b_ar = pyro.sample(\"feat_3\", dist.Normal(weights_loc[2], weights_scale[2]))\n",
    "    sigma = pyro.sample(\"sigma\", dist.Normal(sigma_loc, torch.tensor(0.05)))\n",
    "    mean = a + b_a * is_cont_africa + b_r * ruggedness + b_ar * is_cont_africa * ruggedness\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "df = rugged_data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
    "df = df[np.isfinite(df.rgdppc_2000)]\n",
    "df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])\n",
    "train = torch.tensor(df.values, dtype=torch.float)\n",
    "\n",
    "is_cont_africa, ruggedness, log_gdp = train[:, 0], train[:, 1], train[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **HMC Sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1200/1200 [00:53, 22.48it/s, step size=4.02e-01, acc. prob=0.941]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "nuts_kernel = NUTS(model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run(is_cont_africa, ruggedness, log_gdp)\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Summary of hmc samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>bias</td>\n",
       "      <td>9.177086</td>\n",
       "      <td>0.132103</td>\n",
       "      <td>8.964320</td>\n",
       "      <td>9.087749</td>\n",
       "      <td>9.177876</td>\n",
       "      <td>9.266782</td>\n",
       "      <td>9.405351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feat_1</td>\n",
       "      <td>-1.833916</td>\n",
       "      <td>0.211210</td>\n",
       "      <td>-2.177543</td>\n",
       "      <td>-1.981985</td>\n",
       "      <td>-1.827741</td>\n",
       "      <td>-1.684364</td>\n",
       "      <td>-1.481710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feat_2</td>\n",
       "      <td>-0.180611</td>\n",
       "      <td>0.072021</td>\n",
       "      <td>-0.297735</td>\n",
       "      <td>-0.229140</td>\n",
       "      <td>-0.182988</td>\n",
       "      <td>-0.133065</td>\n",
       "      <td>-0.056745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feat_3</td>\n",
       "      <td>0.338777</td>\n",
       "      <td>0.126823</td>\n",
       "      <td>0.132223</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>0.339038</td>\n",
       "      <td>0.425461</td>\n",
       "      <td>0.543319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sigma</td>\n",
       "      <td>0.950159</td>\n",
       "      <td>0.050119</td>\n",
       "      <td>0.869279</td>\n",
       "      <td>0.916199</td>\n",
       "      <td>0.948648</td>\n",
       "      <td>0.984792</td>\n",
       "      <td>1.031622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       std        5%       25%       50%       75%       95%\n",
       "bias    9.177086  0.132103  8.964320  9.087749  9.177876  9.266782  9.405351\n",
       "feat_1 -1.833916  0.211210 -2.177543 -1.981985 -1.827741 -1.684364 -1.481710\n",
       "feat_2 -0.180611  0.072021 -0.297735 -0.229140 -0.182988 -0.133065 -0.056745\n",
       "feat_3  0.338777  0.126823  0.132223  0.249588  0.339038  0.425461  0.543319\n",
       "sigma   0.950159  0.050119  0.869279  0.916199  0.948648  0.984792  1.031622"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utility function to print latent sites' quantile information.\n",
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "    return site_stats\n",
    "\n",
    "hmc_df= pd.DataFrame()\n",
    "for key in summary(hmc_samples).keys():\n",
    "    temp = summary(hmc_samples)[key]\n",
    "    temp.index= [key]\n",
    "    hmc_df= pd.concat([hmc_df, temp])\n",
    "\n",
    "hmc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Statsmodel training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining feature_3 for statsmodel**\n",
    "* For statsmodel training, there are 3 features (`cont_africa`,`rugged`,`cont_africa_x_rugged`), 1 bias and 1 target label `rgdppc_2000`(GDP_per_capita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont_africa</th>\n",
       "      <th>rugged</th>\n",
       "      <th>rgdppc_2000</th>\n",
       "      <th>cont_africa_x_rugged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.858</td>\n",
       "      <td>7.492609</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.427</td>\n",
       "      <td>8.216929</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769</td>\n",
       "      <td>9.933263</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont_africa  rugged  rgdppc_2000  cont_africa_x_rugged\n",
       "2            1   0.858     7.492609                 0.858\n",
       "4            0   3.427     8.216929                 0.000\n",
       "7            0   0.769     9.933263                 0.000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cont_africa_x_rugged\"] = df[\"cont_africa\"] * df[\"rugged\"]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "feats, targets= df[['cont_africa', 'rugged', 'cont_africa_x_rugged']].values, df['rgdppc_2000'].values\n",
    "feats= sm.add_constant(feats, prepend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.357\n",
      "Model:                            OLS   Adj. R-squared:                  0.345\n",
      "Method:                 Least Squares   F-statistic:                     30.71\n",
      "Date:                Wed, 22 Apr 2020   Prob (F-statistic):           7.60e-16\n",
      "Time:                        11:39:01   Log-Likelihood:                -229.37\n",
      "No. Observations:                 170   AIC:                             466.7\n",
      "Df Residuals:                     166   BIC:                             479.3\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -1.9480      0.227     -8.572      0.000      -2.397      -1.499\n",
      "x2            -0.2029      0.077     -2.621      0.010      -0.356      -0.050\n",
      "x3             0.3934      0.132      2.989      0.003       0.134       0.653\n",
      "const          9.2232      0.140     66.044      0.000       8.948       9.499\n",
      "==============================================================================\n",
      "Omnibus:                       10.107   Durbin-Watson:                   1.978\n",
      "Prob(Omnibus):                  0.006   Jarque-Bera (JB):                5.025\n",
      "Skew:                           0.192   Prob(JB):                       0.0810\n",
      "Kurtosis:                       2.251   Cond. No.                         7.54\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_stm = sm.OLS(targets, feats, hasconst=True)\n",
    "result= model_stm.fit(disp=0)\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Summary of statsmodel result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>x1</td>\n",
       "      <td>-1.9480</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-8.572</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-2.397</td>\n",
       "      <td>-1.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>x2</td>\n",
       "      <td>-0.2029</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-2.621</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>x3</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>0.132</td>\n",
       "      <td>2.989</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>const</td>\n",
       "      <td>9.2232</td>\n",
       "      <td>0.140</td>\n",
       "      <td>66.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.948</td>\n",
       "      <td>9.499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef    std err          t   P>|t|     [0.025     0.975]\n",
       "0     x1     -1.9480      0.227     -8.572   0.000     -2.397     -1.499\n",
       "1     x2     -0.2029      0.077     -2.621   0.010     -0.356     -0.050\n",
       "2     x3      0.3934      0.132      2.989   0.003      0.134      0.653\n",
       "3  const      9.2232      0.140     66.044   0.000      8.948      9.499"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_summary= result.summary()\n",
    "statsm_df = pd.DataFrame(stats_summary.tables[1].data[1:], columns=stats_summary.tables[1].data[0])\n",
    "statsm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contrasting resulst from HMC sampling and Statsmodel training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For feature bias:\n",
      ". . .val from HMC obtained samples: {} 9.177085876464844\n",
      ". . .val from statsmodel training: {}     9.2232 \n",
      "\n",
      "For feature feat_1:\n",
      ". . .val from HMC obtained samples: {} -1.8339163064956665\n",
      ". . .val from statsmodel training: {}    -1.9480 \n",
      "\n",
      "For feature feat_2:\n",
      ". . .val from HMC obtained samples: {} -0.1806105077266693\n",
      ". . .val from statsmodel training: {}    -0.2029 \n",
      "\n",
      "For feature feat_3:\n",
      ". . .val from HMC obtained samples: {} 0.3387771546840668\n",
      ". . .val from statsmodel training: {}     0.3934 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hmc_statsmodel_keys= {'bias':3, 'feat_1':0,'feat_2':1,'feat_3':2}#{0:X1,1:X2,2:X3, 3:const}\n",
    "\n",
    "stats_hmc_di= dict()\n",
    "for key, val in hmc_statsmodel_keys.items():\n",
    "    print(\"For feature {}:\".format(key))#site\n",
    "    print('. . .val from HMC obtained samples: {}',hmc_df['mean'][key])\n",
    "    print('. . .val from statsmodel training: {}',statsm_df['coef'][val], \"\\n\")\n",
    "    stats_hmc_di['param_val_{}'.format(key)]= [hmc_df['mean'][key], statsm_df['coef'][val]]\n",
    "    stats_hmc_di['std_error_{}'.format(key)]= [hmc_df['std'][key], statsm_df['std err'][val]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_val_bias</th>\n",
       "      <th>std_error_bias</th>\n",
       "      <th>param_val_feat_1</th>\n",
       "      <th>std_error_feat_1</th>\n",
       "      <th>param_val_feat_2</th>\n",
       "      <th>std_error_feat_2</th>\n",
       "      <th>param_val_feat_3</th>\n",
       "      <th>std_error_feat_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>hmc_samples</td>\n",
       "      <td>9.17709</td>\n",
       "      <td>0.132103</td>\n",
       "      <td>-1.83392</td>\n",
       "      <td>0.21121</td>\n",
       "      <td>-0.180611</td>\n",
       "      <td>0.072021</td>\n",
       "      <td>0.338777</td>\n",
       "      <td>0.126823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>statsmodel_results</td>\n",
       "      <td>9.2232</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-1.9480</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.2029</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   param_val_bias std_error_bias param_val_feat_1  \\\n",
       "hmc_samples               9.17709       0.132103         -1.83392   \n",
       "statsmodel_results         9.2232          0.140          -1.9480   \n",
       "\n",
       "                   std_error_feat_1 param_val_feat_2 std_error_feat_2  \\\n",
       "hmc_samples                 0.21121        -0.180611         0.072021   \n",
       "statsmodel_results            0.227          -0.2029            0.077   \n",
       "\n",
       "                   param_val_feat_3 std_error_feat_3  \n",
       "hmc_samples                0.338777         0.126823  \n",
       "statsmodel_results           0.3934            0.132  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stats_hmc_di, index= ['hmc_samples','statsmodel_results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HMC sampling on explicit pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.nn import PyroSample\n",
    "from torch import nn\n",
    "from pyro.nn import PyroModule\n",
    "\n",
    "class regression_model(PyroModule):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = PyroModule[nn.Linear](in_features, out_features)\n",
    "        self.linear.weight = PyroSample(dist.Normal(0., 1.).expand([out_features, in_features]).to_event(2))\n",
    "        self.linear.bias = PyroSample(dist.Normal(0., 10.).expand([out_features]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "        mean = self.linear(x).squeeze(-1)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)\n",
    "        return mean\n",
    "\n",
    "model2 = regression_model(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(df[[\"cont_africa\", \"rugged\", \"cont_africa_x_rugged\", \"rgdppc_2000\"]].values,\n",
    "                        dtype=torch.float)\n",
    "x_data, y_data = data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1200/1200 [00:39, 30.61it/s, step size=4.29e-01, acc. prob=0.910]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(model2)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run(x_data, y_data)#is_cont_africa, ruggedness, log_gdp)\n",
    "hmc_samples2 = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>feat_1</td>\n",
       "      <td>-1.851923</td>\n",
       "      <td>0.226410</td>\n",
       "      <td>-2.215584</td>\n",
       "      <td>-2.011727</td>\n",
       "      <td>-1.856236</td>\n",
       "      <td>-1.703061</td>\n",
       "      <td>-1.452867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feat_2</td>\n",
       "      <td>-0.187826</td>\n",
       "      <td>0.078391</td>\n",
       "      <td>-0.318569</td>\n",
       "      <td>-0.239004</td>\n",
       "      <td>-0.183455</td>\n",
       "      <td>-0.136097</td>\n",
       "      <td>-0.065415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feat_3</td>\n",
       "      <td>0.353691</td>\n",
       "      <td>0.129144</td>\n",
       "      <td>0.141936</td>\n",
       "      <td>0.266109</td>\n",
       "      <td>0.358820</td>\n",
       "      <td>0.438002</td>\n",
       "      <td>0.564123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bias</td>\n",
       "      <td>9.189334</td>\n",
       "      <td>0.136106</td>\n",
       "      <td>8.966088</td>\n",
       "      <td>9.093130</td>\n",
       "      <td>9.189205</td>\n",
       "      <td>9.282696</td>\n",
       "      <td>9.408723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       std        5%       25%       50%       75%       95%\n",
       "feat_1 -1.851923  0.226410 -2.215584 -2.011727 -1.856236 -1.703061 -1.452867\n",
       "feat_2 -0.187826  0.078391 -0.318569 -0.239004 -0.183455 -0.136097 -0.065415\n",
       "feat_3  0.353691  0.129144  0.141936  0.266109  0.358820  0.438002  0.564123\n",
       "bias    9.189334  0.136106  8.966088  9.093130  9.189205  9.282696  9.408723"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmc_samples_di = {'feat_1':hmc_samples2['linear.weight'].reshape(-1,3)[:,0],'feat_2':hmc_samples2['linear.weight'].reshape(-1,3)[:,1], 'feat_3':hmc_samples2['linear.weight'].reshape(-1,3)[:,2], 'bias':hmc_samples2['linear.bias'].reshape(-1)}#hmc_samples2['linear.weight'].reshape(-1,3)\n",
    "hmc_df2= pd.DataFrame()\n",
    "for key in summary(hmc_samples_di).keys():\n",
    "    temp = summary(hmc_samples_di)[key]\n",
    "    temp.index= [key]\n",
    "    hmc_df2= pd.concat([hmc_df2, temp])\n",
    "\n",
    "hmc_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For feature bias:\n",
      ". . .val from HMC obtained samples: {} 9.18933391571045\n",
      ". . .val from statsmodel training: {}     9.2232 \n",
      "\n",
      "For feature feat_1:\n",
      ". . .val from HMC obtained samples: {} -1.8519231081008911\n",
      ". . .val from statsmodel training: {}    -1.9480 \n",
      "\n",
      "For feature feat_2:\n",
      ". . .val from HMC obtained samples: {} -0.18782629072666168\n",
      ". . .val from statsmodel training: {}    -0.2029 \n",
      "\n",
      "For feature feat_3:\n",
      ". . .val from HMC obtained samples: {} 0.35369056463241577\n",
      ". . .val from statsmodel training: {}     0.3934 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hmc_statsmodel_keys= {'bias':3, 'feat_1':0,'feat_2':1,'feat_3':2}#{0:X1,1:X2,2:X3, 3:const}\n",
    "\n",
    "stats_hmc_di_2= dict()\n",
    "for key, val in hmc_statsmodel_keys.items():\n",
    "    print(\"For feature {}:\".format(key))#site\n",
    "    print('. . .val from HMC obtained samples: {}',hmc_df2['mean'][key])\n",
    "    print('. . .val from statsmodel training: {}',statsm_df['coef'][val], \"\\n\")\n",
    "    stats_hmc_di_2['param_val_{}'.format(key)]= [hmc_df2['mean'][key], statsm_df['coef'][val]]\n",
    "    stats_hmc_di_2['std_error_{}'.format(key)]= [hmc_df2['std'][key], statsm_df['std err'][val]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_val_bias</th>\n",
       "      <th>std_error_bias</th>\n",
       "      <th>param_val_feat_1</th>\n",
       "      <th>std_error_feat_1</th>\n",
       "      <th>param_val_feat_2</th>\n",
       "      <th>std_error_feat_2</th>\n",
       "      <th>param_val_feat_3</th>\n",
       "      <th>std_error_feat_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>hmc_samples</td>\n",
       "      <td>9.18933</td>\n",
       "      <td>0.136106</td>\n",
       "      <td>-1.85192</td>\n",
       "      <td>0.22641</td>\n",
       "      <td>-0.187826</td>\n",
       "      <td>0.078391</td>\n",
       "      <td>0.353691</td>\n",
       "      <td>0.129144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>statsmodel_results</td>\n",
       "      <td>9.2232</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-1.9480</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.2029</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   param_val_bias std_error_bias param_val_feat_1  \\\n",
       "hmc_samples               9.18933       0.136106         -1.85192   \n",
       "statsmodel_results         9.2232          0.140          -1.9480   \n",
       "\n",
       "                   std_error_feat_1 param_val_feat_2 std_error_feat_2  \\\n",
       "hmc_samples                 0.22641        -0.187826         0.078391   \n",
       "statsmodel_results            0.227          -0.2029            0.077   \n",
       "\n",
       "                   param_val_feat_3 std_error_feat_3  \n",
       "hmc_samples                0.353691         0.129144  \n",
       "statsmodel_results           0.3934            0.132  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stats_hmc_di_2, index= ['hmc_samples','statsmodel_results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Pytorch model with SGD & setting priors from converged values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toynet(\n",
       "  (fc1): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "#from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "class toynet(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(toynet, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, out_features)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    def forward(self,  x, y=None):\n",
    "        x= self.fc1(x)\n",
    "        return x\n",
    "model3 = toynet(3, 1)\n",
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer3 = optim.Adam(model3.parameters())\n",
    "loss3 = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data as d\n",
    "import time\n",
    "\n",
    "class Dataset(d.Dataset):\n",
    "    def __init__(self, list_IDs, features, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.features= features\n",
    "        self.list_IDs = list_IDs\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = self.features[ID]#torch.load('data/' + ID + '.pt')\n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X, y\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "\n",
    "partition = {'train':list(range(y_data.shape[0]))}# IDs\n",
    "features= {idx:record for idx, record in enumerate(x_data)}\n",
    "labels = {idx:record for idx, record in enumerate(y_data)}# Labels\n",
    "training_set = Dataset(partition['train'],features, labels)\n",
    "training_generator = d.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  63.119693756103516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([42])) that is different to the input size (torch.Size([42, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  50  loss:  62.37919998168945\n",
      "epoch:  100  loss:  64.35924530029297\n",
      "epoch:  150  loss:  57.75749969482422\n",
      "epoch:  200  loss:  62.62089157104492\n",
      "epoch:  250  loss:  61.59002685546875\n",
      "epoch:  300  loss:  60.481849670410156\n",
      "epoch:  350  loss:  60.46846389770508\n",
      "total exe. time: 17.99188256263733\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "max_epochs = 400\n",
    "t1=time.time()\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    for local_batch, local_labels in training_generator:\n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        optimizer3.zero_grad()\n",
    "        y_pred= model3(local_batch)    \n",
    "        l = loss3(y_pred, local_labels)\n",
    "        l.backward()\n",
    "        optimizer3.step()\n",
    "    if epoch%50==0:\n",
    "            print('epoch: ', epoch, ' loss: ', l.item());\n",
    "print('total exe. time:', time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.5054, -0.2933, -0.5212]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.5618], requires_grad=True)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model3.parameters())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class regression_model_2(PyroModule):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = PyroModule[nn.Linear](in_features, out_features)\n",
    "        self.linear.weight = PyroSample(dist.Normal(list(model3.parameters())[0][0], 1.).expand([out_features, in_features]).to_event(2))\n",
    "        self.linear.bias = PyroSample(dist.Normal(list(model3.parameters())[1][0], 10.).expand([out_features]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "        mean = self.linear(x).squeeze(-1)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)\n",
    "        return mean\n",
    "model4= regression_model_2(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1200/1200 [00:25, 47.05it/s, step size=3.84e-01, acc. prob=0.921]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(model4)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run(x_data, y_data)#is_cont_africa, ruggedness, log_gdp)\n",
    "hmc_samples4 = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>feat_1</td>\n",
       "      <td>-1.810519</td>\n",
       "      <td>0.217312</td>\n",
       "      <td>-2.166240</td>\n",
       "      <td>-1.962683</td>\n",
       "      <td>-1.803437</td>\n",
       "      <td>-1.660652</td>\n",
       "      <td>-1.446860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feat_2</td>\n",
       "      <td>-0.182261</td>\n",
       "      <td>0.072628</td>\n",
       "      <td>-0.304403</td>\n",
       "      <td>-0.228927</td>\n",
       "      <td>-0.183999</td>\n",
       "      <td>-0.129148</td>\n",
       "      <td>-0.063949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>feat_3</td>\n",
       "      <td>0.331030</td>\n",
       "      <td>0.128846</td>\n",
       "      <td>0.124735</td>\n",
       "      <td>0.243230</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.418230</td>\n",
       "      <td>0.540064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bias</td>\n",
       "      <td>9.174149</td>\n",
       "      <td>0.133759</td>\n",
       "      <td>8.964955</td>\n",
       "      <td>9.080325</td>\n",
       "      <td>9.169611</td>\n",
       "      <td>9.258896</td>\n",
       "      <td>9.398646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       std        5%       25%       50%       75%       95%\n",
       "feat_1 -1.810519  0.217312 -2.166240 -1.962683 -1.803437 -1.660652 -1.446860\n",
       "feat_2 -0.182261  0.072628 -0.304403 -0.228927 -0.183999 -0.129148 -0.063949\n",
       "feat_3  0.331030  0.128846  0.124735  0.243230  0.333000  0.418230  0.540064\n",
       "bias    9.174149  0.133759  8.964955  9.080325  9.169611  9.258896  9.398646"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmc_samples_di = {'feat_1':hmc_samples4['linear.weight'].reshape(-1,3)[:,0],'feat_2':hmc_samples4['linear.weight'].reshape(-1,3)[:,1], 'feat_3':hmc_samples4['linear.weight'].reshape(-1,3)[:,2], 'bias':hmc_samples4['linear.bias'].reshape(-1)}#hmc_samples2['linear.weight'].reshape(-1,3)\n",
    "hmc_df4= pd.DataFrame()\n",
    "for key in summary(hmc_samples_di).keys():\n",
    "    temp = summary(hmc_samples_di)[key]\n",
    "    temp.index= [key]\n",
    "    hmc_df4= pd.concat([hmc_df4, temp])\n",
    "\n",
    "hmc_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For feature bias:\n",
      ". . .val from HMC obtained samples: {} 9.174148559570312\n",
      ". . .val from statsmodel training: {}     9.2232 \n",
      "\n",
      "For feature feat_1:\n",
      ". . .val from HMC obtained samples: {} -1.810518503189087\n",
      ". . .val from statsmodel training: {}    -1.9480 \n",
      "\n",
      "For feature feat_2:\n",
      ". . .val from HMC obtained samples: {} -0.18226078152656555\n",
      ". . .val from statsmodel training: {}    -0.2029 \n",
      "\n",
      "For feature feat_3:\n",
      ". . .val from HMC obtained samples: {} 0.33103030920028687\n",
      ". . .val from statsmodel training: {}     0.3934 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hmc_statsmodel_keys= {'bias':3, 'feat_1':0,'feat_2':1,'feat_3':2}#{0:X1,1:X2,2:X3, 3:const}\n",
    "\n",
    "stats_hmc_di_4= dict()\n",
    "for key, val in hmc_statsmodel_keys.items():\n",
    "    print(\"For feature {}:\".format(key))#site\n",
    "    print('. . .val from HMC obtained samples: {}',hmc_df4['mean'][key])\n",
    "    print('. . .val from statsmodel training: {}',statsm_df['coef'][val], \"\\n\")\n",
    "    stats_hmc_di_4['param_val_{}'.format(key)]= [hmc_df4['mean'][key], statsm_df['coef'][val]]\n",
    "    stats_hmc_di_4['std_error_{}'.format(key)]= [hmc_df4['std'][key], statsm_df['std err'][val]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_val_bias</th>\n",
       "      <th>std_error_bias</th>\n",
       "      <th>param_val_feat_1</th>\n",
       "      <th>std_error_feat_1</th>\n",
       "      <th>param_val_feat_2</th>\n",
       "      <th>std_error_feat_2</th>\n",
       "      <th>param_val_feat_3</th>\n",
       "      <th>std_error_feat_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>hmc_samples</td>\n",
       "      <td>9.17415</td>\n",
       "      <td>0.133759</td>\n",
       "      <td>-1.81052</td>\n",
       "      <td>0.217312</td>\n",
       "      <td>-0.182261</td>\n",
       "      <td>0.0726282</td>\n",
       "      <td>0.33103</td>\n",
       "      <td>0.128846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>statsmodel_results</td>\n",
       "      <td>9.2232</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-1.9480</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.2029</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   param_val_bias std_error_bias param_val_feat_1  \\\n",
       "hmc_samples               9.17415       0.133759         -1.81052   \n",
       "statsmodel_results         9.2232          0.140          -1.9480   \n",
       "\n",
       "                   std_error_feat_1 param_val_feat_2 std_error_feat_2  \\\n",
       "hmc_samples                0.217312        -0.182261        0.0726282   \n",
       "statsmodel_results            0.227          -0.2029            0.077   \n",
       "\n",
       "                   param_val_feat_3 std_error_feat_3  \n",
       "hmc_samples                 0.33103         0.128846  \n",
       "statsmodel_results           0.3934            0.132  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stats_hmc_di_4, index= ['hmc_samples','statsmodel_results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapping up pytorch & pyro model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pyrotorch():\n",
    "    def __init__(self,  in_features, out_features):\n",
    "        self.in_features= in_features\n",
    "        self.out_features= out_features\n",
    "    class ptmodel(nn.Module):\n",
    "        def __init__(self, in_features, out_features):\n",
    "            super(toynet, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_features, out_features)\n",
    "            self.sig = nn.Sigmoid()\n",
    "            def forward(self,  x, y=None):\n",
    "            x= self.fc1(x)\n",
    "            return x\n",
    "        def forward(self,  x, y=None):\n",
    "            x= self.fc1(x)\n",
    "            return x\n",
    "    model_pt = ptmodel(self.in_features, self.out_features)\n",
    "    optimizer = optim.Adam(model_pt.parameters())\n",
    "    loss = nn.MSELoss()\n",
    "    \n",
    "    ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
