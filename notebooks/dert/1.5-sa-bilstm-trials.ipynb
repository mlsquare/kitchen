{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bfb32572-57e3-48d0-aae6-c6c77bc6e79a",
    "_uuid": "d42c1f22-ed95-4858-938f-1678b062ba57",
    "id": "rEJAt8h2kL5f"
   },
   "source": [
    "## Load dataset and tree info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "94f1bfeb-5db1-402c-a5eb-49390b275754",
    "_uuid": "ef94223f-f6ed-4c27-830c-f4f6dd4d1dad",
    "id": "TqdFRdmtkL5h"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate, GRU, LSTM\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "# from sklearn.metrics import jaccard_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "af237142-80d5-4809-9329-6ee67a905f9f",
    "_uuid": "f21b53b1-463e-4003-b939-6ce0168efe53",
    "id": "RA0dltvOkL5q"
   },
   "outputs": [],
   "source": [
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "         'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "         'hours-per-week', 'native-country', 'target']\n",
    "\n",
    "data = pd.read_csv('../../data/raw/adult.data.csv', delimiter=\",\", header=None, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "8dc1db16-9aa4-451d-8fcd-2d8fe5e2fbb8",
    "_uuid": "476b6e9a-4738-4a99-a6bf-58dcc3d4868f",
    "id": "o2SOoRYrkL50",
    "outputId": "8fb8a914-7873-471a-b3c6-7dab445c5009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  target  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "f63f2ff2-e2fc-427d-a510-2c43075abf4a",
    "_uuid": "19b3bf7c-bc5d-4283-b1e8-d5787f3c5f62",
    "id": "DbCUqAebkL57"
   },
   "outputs": [],
   "source": [
    "data = data[data[\"workclass\"] != \" ?\"]\n",
    "data = data[data[\"occupation\"] != \" ?\"]\n",
    "data = data[data[\"native-country\"] != \" ?\"]\n",
    "\n",
    "# Convert categorical fields #\n",
    "categorical_col = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                   'relationship', 'race', 'sex', 'native-country', 'target']\n",
    "\n",
    "# categorical_col = ['target']\n",
    "    \n",
    "# for col in categorical_col:\n",
    "#     categories = unique_of(data.col)\n",
    "#     num_cat = count(categories)\n",
    "#     for cat in categories:\n",
    "#         data.col[cat] = index_of(cat in categories)\n",
    "\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "feature_list = names[:14]\n",
    "# Test train split #\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['target']]\n",
    "\n",
    "# Split the dataset into test and train datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "7871bb57-e85f-470e-bd4c-1ab7b50ac959",
    "_uuid": "9d192e14-7640-4a9b-a9fc-f008bc427829",
    "id": "43BPEWI5kL6A"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df = df.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "416427eb-8a2d-45cf-bdd3-6a7b874c1635",
    "_uuid": "7b85281c-91d9-4acb-b3ea-0bf43dafc467",
    "id": "tlrqRs_TFcUL",
    "outputId": "1490e47f-587e-4339-e063-670cf1e6d7b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0   39          5   77516          9             13               4   \n",
       "1   50          4   83311          9             13               2   \n",
       "2   38          2  215646         11              9               0   \n",
       "3   53          2  234721          1              7               2   \n",
       "4   28          2  338409          9             13               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0           0             1     4    1          2174             0   \n",
       "1           3             0     4    1             0             0   \n",
       "2           5             1     4    1             0             0   \n",
       "3           5             0     2    1             0             0   \n",
       "4           9             5     2    0             0             0   \n",
       "\n",
       "   hours-per-week  native-country  \n",
       "0              40              38  \n",
       "1              13              38  \n",
       "2              40              38  \n",
       "3              40              38  \n",
       "4              40               4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "36f2e768-8240-42d1-b0bc-c46e245334ba",
    "_uuid": "2a3669e7-de27-4b94-af19-9d66411319ac",
    "id": "MiH6lLHcHNbt"
   },
   "outputs": [],
   "source": [
    "cont_var = []\n",
    "\n",
    "for i in list(df.columns):\n",
    "  if i not in categorical_col:\n",
    "    cont_var.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b6bc81a7-1e1c-4005-bb1d-7ace2023d62a",
    "_uuid": "b92c7a82-a38d-4e07-9918-81227841626d",
    "id": "Qw6AA4T_F2h7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X = df[cont_var]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "33b3c3f8-79ce-4793-904a-c5e0eec1cdf8",
    "_uuid": "43cd5c23-c66c-4c03-899e-0cbce5c88a4b",
    "id": "yrov14x2FwZX"
   },
   "outputs": [],
   "source": [
    "categorical_col = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                   'relationship', 'race', 'sex', 'native-country']\n",
    "for i in categorical_col:\n",
    "  enc = OneHotEncoder(handle_unknown='ignore')\n",
    "  enc.fit(df[i].values.reshape(-1,1))\n",
    "  temp_df = pd.DataFrame(enc.transform(df[i].values.reshape(-1,1)).toarray())\n",
    "  X = pd.concat([X, temp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "bcd88223-2e97-4f66-8152-07209888c2b1",
    "_uuid": "5d3a6a38-91cb-4e55-815c-525bd206e089",
    "id": "GfN2S4l-MRWZ",
    "outputId": "858b0eb8-61bb-47f5-870d-bc4ae0ec518d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042796</td>\n",
       "      <td>-1.062722</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.146092</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880288</td>\n",
       "      <td>-1.007871</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-2.331531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>0.244693</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.108695</td>\n",
       "      <td>0.425240</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.794697</td>\n",
       "      <td>1.406658</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.109476</td>\n",
       "      <td>0.897180</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.804152</td>\n",
       "      <td>-0.280232</td>\n",
       "      <td>-2.008395</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-2.081109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.032559</td>\n",
       "      <td>0.187865</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.339636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.566290</td>\n",
       "      <td>-1.363097</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>1.754199</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.271203</td>\n",
       "      <td>-0.287217</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.551697</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.109476</td>\n",
       "      <td>0.858203</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>3.261224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.642425</td>\n",
       "      <td>-0.459028</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.175375</td>\n",
       "      <td>-0.639101</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.912474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.490154</td>\n",
       "      <td>0.144108</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.337883</td>\n",
       "      <td>0.527142</td>\n",
       "      <td>-2.400559</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.339636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.023104</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.495104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.490154</td>\n",
       "      <td>-0.028110</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>-1.523000</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.347338</td>\n",
       "      <td>0.969049</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.339636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.118931</td>\n",
       "      <td>0.035306</td>\n",
       "      <td>2.305411</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>1.591745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.184831</td>\n",
       "      <td>1.063425</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-1.747213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.261747</td>\n",
       "      <td>-1.069073</td>\n",
       "      <td>-2.008395</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.347338</td>\n",
       "      <td>-0.688651</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>4.832223</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.565509</td>\n",
       "      <td>-0.764580</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.337102</td>\n",
       "      <td>0.256099</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.479918</td>\n",
       "      <td>-0.203498</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.042796</td>\n",
       "      <td>1.679736</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>3.261224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.804152</td>\n",
       "      <td>0.033811</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.175375</td>\n",
       "      <td>0.008662</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.923953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.403782</td>\n",
       "      <td>0.721441</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.256162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30132</th>\n",
       "      <td>-0.490154</td>\n",
       "      <td>0.204022</td>\n",
       "      <td>-1.616231</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30133</th>\n",
       "      <td>-1.251511</td>\n",
       "      <td>0.131765</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30134</th>\n",
       "      <td>-0.566290</td>\n",
       "      <td>0.972996</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30135</th>\n",
       "      <td>-0.718561</td>\n",
       "      <td>-0.604043</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.495104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30136</th>\n",
       "      <td>-0.337883</td>\n",
       "      <td>0.138826</td>\n",
       "      <td>2.305411</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>1.591745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30137</th>\n",
       "      <td>1.184831</td>\n",
       "      <td>1.402711</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30138</th>\n",
       "      <td>-0.109476</td>\n",
       "      <td>-0.100868</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.161208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30139</th>\n",
       "      <td>-1.251511</td>\n",
       "      <td>1.280053</td>\n",
       "      <td>-0.831902</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.495104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30140</th>\n",
       "      <td>-0.337883</td>\n",
       "      <td>-0.279957</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>1.174375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30141</th>\n",
       "      <td>-0.642425</td>\n",
       "      <td>1.477542</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.423110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30142</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>-0.479065</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>1.880579</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.339636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30143</th>\n",
       "      <td>0.499610</td>\n",
       "      <td>0.590757</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30144</th>\n",
       "      <td>0.499610</td>\n",
       "      <td>-0.668188</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.590057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30145</th>\n",
       "      <td>-0.566290</td>\n",
       "      <td>0.093337</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.912474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30146</th>\n",
       "      <td>0.042796</td>\n",
       "      <td>-0.741069</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-1.747213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30147</th>\n",
       "      <td>-0.109476</td>\n",
       "      <td>0.079717</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30148</th>\n",
       "      <td>0.347338</td>\n",
       "      <td>0.671712</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30149</th>\n",
       "      <td>2.022323</td>\n",
       "      <td>-0.855975</td>\n",
       "      <td>1.913247</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>1.591745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30150</th>\n",
       "      <td>0.347338</td>\n",
       "      <td>0.625087</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30151</th>\n",
       "      <td>0.347338</td>\n",
       "      <td>-1.538570</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30152</th>\n",
       "      <td>-0.490154</td>\n",
       "      <td>-1.473980</td>\n",
       "      <td>-1.616231</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30153</th>\n",
       "      <td>0.347338</td>\n",
       "      <td>-0.995093</td>\n",
       "      <td>0.344590</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.339636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30154</th>\n",
       "      <td>-0.490154</td>\n",
       "      <td>-0.697160</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-2.498479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30155</th>\n",
       "      <td>1.108695</td>\n",
       "      <td>1.250068</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30156</th>\n",
       "      <td>-1.251511</td>\n",
       "      <td>1.139203</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30157</th>\n",
       "      <td>-0.870832</td>\n",
       "      <td>0.638972</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.244682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30158</th>\n",
       "      <td>0.118931</td>\n",
       "      <td>-0.335252</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30159</th>\n",
       "      <td>1.489374</td>\n",
       "      <td>-0.358575</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30160</th>\n",
       "      <td>-1.251511</td>\n",
       "      <td>0.110705</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-1.747213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30161</th>\n",
       "      <td>1.032559</td>\n",
       "      <td>0.928841</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>1.881120</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5    0    1   \\\n",
       "0      0.042796 -1.062722  1.128918  0.146092 -0.218586 -0.077734  0.0  0.0   \n",
       "1      0.880288 -1.007871  1.128918 -0.147445 -0.218586 -2.331531  0.0  0.0   \n",
       "2     -0.033340  0.244693 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "3      1.108695  0.425240 -1.224066 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "4     -0.794697  1.406658  1.128918 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "5     -0.109476  0.897180  1.521083 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "6      0.804152 -0.280232 -2.008395 -0.147445 -0.218586 -2.081109  0.0  0.0   \n",
       "7      1.032559  0.187865 -0.439738 -0.147445 -0.218586  0.339636  0.0  0.0   \n",
       "8     -0.566290 -1.363097  1.521083  1.754199 -0.218586  0.757005  0.0  0.0   \n",
       "9      0.271203 -0.287217  1.128918  0.551697 -0.218586 -0.077734  0.0  0.0   \n",
       "10    -0.109476  0.858203 -0.047574 -0.147445 -0.218586  3.261224  0.0  0.0   \n",
       "11    -0.642425 -0.459028  1.128918 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "12    -1.175375 -0.639101  1.128918 -0.147445 -0.218586 -0.912474  0.0  0.0   \n",
       "13    -0.490154  0.144108  0.736754 -0.147445 -0.218586  0.757005  0.0  0.0   \n",
       "14    -0.337883  0.527142 -2.400559 -0.147445 -0.218586  0.339636  0.0  0.0   \n",
       "15    -1.023104 -0.123404 -0.439738 -0.147445 -0.218586 -0.495104  0.0  0.0   \n",
       "16    -0.490154 -0.028110 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "17    -0.033340 -1.523000 -1.224066 -0.147445 -0.218586  0.757005  0.0  0.0   \n",
       "18     0.347338  0.969049  1.521083 -0.147445 -0.218586  0.339636  0.0  0.0   \n",
       "19     0.118931  0.035306  2.305411 -0.147445 -0.218586  1.591745  0.0  0.0   \n",
       "20     1.184831  1.063425 -0.439738 -0.147445 -0.218586 -1.747213  0.0  0.0   \n",
       "21    -0.261747 -1.069073 -2.008395 -0.147445 -0.218586 -0.077734  1.0  0.0   \n",
       "22     0.347338 -0.688651 -1.224066 -0.147445  4.832223 -0.077734  0.0  0.0   \n",
       "23     1.565509 -0.764580 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "24     1.337102  0.256099  1.128918 -0.147445 -0.218586 -0.077734  0.0  1.0   \n",
       "25    -1.479918 -0.203498 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "26     0.042796  1.679736 -0.439738 -0.147445 -0.218586  3.261224  0.0  0.0   \n",
       "27     0.804152  0.033811 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "28    -1.175375  0.008662  0.736754 -0.147445 -0.218586  0.923953  0.0  1.0   \n",
       "29    -1.403782  0.721441 -0.047574 -0.147445 -0.218586  0.256162  0.0  0.0   \n",
       "...         ...       ...       ...       ...       ...       ...  ...  ...   \n",
       "30132 -0.490154  0.204022 -1.616231 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30133 -1.251511  0.131765 -0.047574 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30134 -0.566290  0.972996 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30135 -0.718561 -0.604043 -0.439738 -0.147445 -0.218586 -0.495104  0.0  0.0   \n",
       "30136 -0.337883  0.138826  2.305411 -0.147445 -0.218586  1.591745  0.0  0.0   \n",
       "30137  1.184831  1.402711  1.128918 -0.147445 -0.218586  0.757005  0.0  0.0   \n",
       "30138 -0.109476 -0.100868 -0.047574 -0.147445 -0.218586 -0.161208  0.0  0.0   \n",
       "30139 -1.251511  1.280053 -0.831902 -0.147445 -0.218586 -0.495104  0.0  0.0   \n",
       "30140 -0.337883 -0.279957  1.128918 -0.147445 -0.218586  1.174375  0.0  0.0   \n",
       "30141 -0.642425  1.477542 -0.439738 -0.147445 -0.218586  0.423110  0.0  0.0   \n",
       "30142 -0.033340 -0.479065  1.128918  1.880579 -0.218586  0.339636  0.0  0.0   \n",
       "30143  0.499610  0.590757 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30144  0.499610 -0.668188  0.736754 -0.147445 -0.218586  0.590057  0.0  1.0   \n",
       "30145 -0.566290  0.093337  1.521083 -0.147445 -0.218586 -0.912474  0.0  0.0   \n",
       "30146  0.042796 -0.741069  0.736754 -0.147445 -0.218586 -1.747213  0.0  1.0   \n",
       "30147 -0.109476  0.079717  0.736754 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30148  0.347338  0.671712 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30149  2.022323 -0.855975  1.913247 -0.000811 -0.218586  1.591745  0.0  0.0   \n",
       "30150  0.347338  0.625087 -0.047574 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30151  0.347338 -1.538570 -0.047574 -0.147445 -0.218586  0.757005  0.0  0.0   \n",
       "30152 -0.490154 -1.473980 -1.616231 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30153  0.347338 -0.995093  0.344590 -0.147445 -0.218586  0.339636  0.0  0.0   \n",
       "30154 -0.490154 -0.697160  1.521083 -0.147445 -0.218586 -2.498479  0.0  0.0   \n",
       "30155  1.108695  1.250068  1.521083 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30156 -1.251511  1.139203 -0.047574 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30157 -0.870832  0.638972  0.736754 -0.147445 -0.218586 -0.244682  0.0  0.0   \n",
       "30158  0.118931 -0.335252 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30159  1.489374 -0.358575 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "30160 -1.251511  0.110705 -0.439738 -0.147445 -0.218586 -1.747213  0.0  0.0   \n",
       "30161  1.032559  0.928841 -0.439738  1.881120 -0.218586 -0.077734  0.0  0.0   \n",
       "\n",
       "        2    3  ...    31   32   33   34   35   36   37   38   39   40  \n",
       "0      0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "1      0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2      1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3      1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4      1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5      1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "6      1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7      0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "8      1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "9      1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "10     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "11     0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "13     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "14     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15     0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "16     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "17     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "18     0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "19     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "20     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "21     0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "22     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "23     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "24     0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "25     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "26     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "27     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "28     0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "29     1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "...    ...  ... ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "30132  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30133  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30134  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30135  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30136  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30137  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "30138  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30139  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30140  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30141  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30142  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30143  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30144  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30145  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30146  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30147  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30148  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "30149  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30150  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30151  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30152  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30153  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30154  1.0  0.0 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "30155  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30156  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30157  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30158  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30159  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30160  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "30161  0.0  1.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[30162 rows x 104 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "80f7d274-4268-4225-a247-1a87c115a3f5",
    "_uuid": "94bfd9b0-0eaa-4918-9829-1574dac11720",
    "id": "esh9PPCGkL6G"
   },
   "outputs": [],
   "source": [
    "bin_labels = pd.read_csv('../../scripts/dert/test_adult_bin_labels_36000.csv', delimiter=\",\",\n",
    "                         header=0, names=['label', 'bins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "6d89c96a-6479-4884-a290-6e2dac1bfecd",
    "_uuid": "3e3f3db1-9549-4f8e-831f-741d0cdd8aea",
    "id": "uKywaQb9kL6L",
    "outputId": "3e012430-9d89-4c75-9457-b2454a9bd3e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AB</td>\n",
       "      <td>39.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABC</td>\n",
       "      <td>(38)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCD</td>\n",
       "      <td>206962.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>859.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label      bins\n",
       "0     A       (5)\n",
       "1    AB      39.5\n",
       "2   ABC      (38)\n",
       "3  ABCD  206962.5\n",
       "4  ABCE     859.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11935, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "967b7cc7-aac7-4b19-97a0-5b9880d85650",
    "_uuid": "5e5f86ea-af3e-4ac8-8e38-0cf8dafb2d04",
    "id": "se7zLwcPkL6Q"
   },
   "outputs": [],
   "source": [
    "Y = Y.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "59a93bd9-b973-48cf-a11b-f715ff9e502e",
    "_uuid": "70e56661-5a2c-44ac-a9a2-5b5ed240ca6f",
    "id": "snFHHHjKkL6a"
   },
   "outputs": [],
   "source": [
    "path_df = pd.read_csv('../../scripts/dert/test_adult_paths_36000.csv', delimiter=\",\",\n",
    "                      header=0, names=['index', 'paths'])\n",
    "path_df = path_df.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "a211dc41-ad01-4815-bb52-5e84dfd4e408",
    "_uuid": "ad7c656a-18f3-4b57-ac9a-e7c494a5921c",
    "id": "jTl94DFbkL6V",
    "outputId": "c278a3b0-c4a6-4690-d167-54c517582fe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b07d6c75-d218-4bd8-9802-2cbef692c8e1",
    "_uuid": "1afd8743-509e-44bd-9aa7-b4ba6542d62e",
    "id": "Oz20kyx0Sa6O",
    "outputId": "35e68b2d-4353-4bba-98fd-3a2654c575a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>284582</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>160187</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>209642</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>45781</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14084</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>159449</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>280464</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>141297</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>122272</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>205019</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>245487</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>176756</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>186824</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>28887</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>292175</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>193524</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>302146</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>76845</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>117037</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2042</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>109015</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>216851</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>168294</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>367260</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>193366</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>190709</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>266015</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>87643</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>106742</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>302122</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>193960</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>185385</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>277647</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>128848</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3471</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>377701</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>157886</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>175958</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>223004</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>199352</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>80</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>29984</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>181651</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>117312</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>34029</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>132879</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>215310</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>55863</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>220384</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>36012</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>137645</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1590</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>191342</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>31339</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>227910</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>173728</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>167816</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>81642</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>195258</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>232475</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0     39          5   77516          9             13               4   \n",
       "1     50          4   83311          9             13               2   \n",
       "2     38          2  215646         11              9               0   \n",
       "3     53          2  234721          1              7               2   \n",
       "4     28          2  338409          9             13               2   \n",
       "5     37          2  284582         12             14               2   \n",
       "6     49          2  160187          6              5               3   \n",
       "7     52          4  209642         11              9               2   \n",
       "8     31          2   45781         12             14               4   \n",
       "9     42          2  159449          9             13               2   \n",
       "10    37          2  280464         15             10               2   \n",
       "11    30          5  141297          9             13               2   \n",
       "12    23          2  122272          9             13               4   \n",
       "13    32          2  205019          7             12               4   \n",
       "14    34          2  245487          5              4               2   \n",
       "15    25          4  176756         11              9               4   \n",
       "16    32          2  186824         11              9               4   \n",
       "17    38          2   28887          1              7               2   \n",
       "18    43          4  292175         12             14               0   \n",
       "19    40          2  193524         10             16               2   \n",
       "20    54          2  302146         11              9               5   \n",
       "21    35          0   76845          6              5               2   \n",
       "22    43          2  117037          1              7               2   \n",
       "23    59          2  109015         11              9               0   \n",
       "24    56          1  216851          9             13               2   \n",
       "25    19          2  168294         11              9               4   \n",
       "26    39          2  367260         11              9               0   \n",
       "27    49          2  193366         11              9               2   \n",
       "28    23          1  190709          7             12               4   \n",
       "29    20          2  266015         15             10               4   \n",
       "..   ...        ...     ...        ...            ...             ...   \n",
       "970   32          2   87643          9             13               2   \n",
       "971   30          4  106742          2              8               2   \n",
       "972   41          2  302122          8             11               0   \n",
       "973   49          1  193960         12             14               2   \n",
       "974   45          2  185385         11              9               2   \n",
       "975   43          4  277647         11              9               2   \n",
       "976   61          2  128848         11              9               2   \n",
       "977   54          2  377701         11              9               2   \n",
       "978   34          2  157886          7             12               5   \n",
       "979   49          2  175958         15             10               2   \n",
       "980   38          2  223004         15             10               4   \n",
       "981   35          2  199352         14             15               2   \n",
       "982   36          2   29984          2              8               2   \n",
       "983   30          2  181651          9             13               2   \n",
       "984   36          2  117312          7             12               0   \n",
       "985   22          1   34029          9             13               4   \n",
       "986   38          2  132879         11              9               2   \n",
       "987   37          2  215310         11              9               2   \n",
       "988   48          5   55863         10             16               2   \n",
       "989   17          2  220384          1              7               4   \n",
       "990   19          4   36012         15             10               4   \n",
       "991   27          2  137645          9             13               4   \n",
       "992   22          2  191342          9             13               4   \n",
       "993   49          2   31339         11              9               2   \n",
       "994   43          5  227910          8             11               2   \n",
       "995   43          2  173728          9             13               5   \n",
       "996   19          1  167816         11              9               0   \n",
       "997   58          4   81642         11              9               2   \n",
       "998   41          1  195258         15             10               2   \n",
       "999   31          2  232475         15             10               2   \n",
       "\n",
       "     occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0             0             1     4    1          2174             0   \n",
       "1             3             0     4    1             0             0   \n",
       "2             5             1     4    1             0             0   \n",
       "3             5             0     2    1             0             0   \n",
       "4             9             5     2    0             0             0   \n",
       "5             3             5     4    0             0             0   \n",
       "6             7             1     2    0             0             0   \n",
       "7             3             0     4    1             0             0   \n",
       "8             9             1     4    0         14084             0   \n",
       "9             3             0     4    1          5178             0   \n",
       "10            3             0     2    1             0             0   \n",
       "11            9             0     1    1             0             0   \n",
       "12            0             3     4    0             0             0   \n",
       "13           11             1     2    1             0             0   \n",
       "14           13             0     0    1             0             0   \n",
       "15            4             3     4    1             0             0   \n",
       "16            6             4     4    1             0             0   \n",
       "17           11             0     4    1             0             0   \n",
       "18            3             4     4    0             0             0   \n",
       "19            9             0     4    1             0             0   \n",
       "20            7             4     2    0             0             0   \n",
       "21            4             0     2    1             0             0   \n",
       "22           13             0     4    1             0          2042   \n",
       "23           12             4     4    0             0             0   \n",
       "24           12             0     4    1             0             0   \n",
       "25            2             3     4    1             0             0   \n",
       "26            3             1     4    1             0             0   \n",
       "27            2             0     4    1             0             0   \n",
       "28           10             1     4    1             0             0   \n",
       "29           11             3     2    1             0             0   \n",
       "..          ...           ...   ...  ...           ...           ...   \n",
       "970          11             0     4    1             0             0   \n",
       "971          13             0     4    1             0             0   \n",
       "972           2             1     4    0             0             0   \n",
       "973           9             0     4    1             0          1902   \n",
       "974           2             0     4    1             0             0   \n",
       "975           3             0     4    1             0             0   \n",
       "976           6             0     4    1          3471             0   \n",
       "977           7             0     4    1             0             0   \n",
       "978           7             4     4    0             0             0   \n",
       "979          11             0     4    1             0             0   \n",
       "980           7             3     4    1             0             0   \n",
       "981           9             0     4    1             0          1977   \n",
       "982          13             0     4    1             0             0   \n",
       "983           3             0     4    1             0             0   \n",
       "984          12             1     4    0             0             0   \n",
       "985           9             3     4    0             0             0   \n",
       "986           2             0     4    1             0          1902   \n",
       "987           2             0     4    1             0             0   \n",
       "988           9             5     4    0             0          1902   \n",
       "989           0             3     4    1             0             0   \n",
       "990           2             3     4    1             0             0   \n",
       "991          11             1     2    0             0          1590   \n",
       "992          11             3     1    1             0             0   \n",
       "993           2             0     4    1             0             0   \n",
       "994           9             5     4    0             0             0   \n",
       "995           9             4     4    0             0             0   \n",
       "996           3             1     4    0             0             0   \n",
       "997           4             0     4    1             0             0   \n",
       "998          10             0     4    1             0             0   \n",
       "999           0             0     4    1             0             0   \n",
       "\n",
       "     hours-per-week  native-country  \n",
       "0                40              38  \n",
       "1                13              38  \n",
       "2                40              38  \n",
       "3                40              38  \n",
       "4                40               4  \n",
       "5                40              38  \n",
       "6                16              22  \n",
       "7                45              38  \n",
       "8                50              38  \n",
       "9                40              38  \n",
       "10               80              38  \n",
       "11               40              18  \n",
       "12               30              38  \n",
       "13               50              38  \n",
       "14               45              25  \n",
       "15               35              38  \n",
       "16               40              38  \n",
       "17               50              38  \n",
       "18               45              38  \n",
       "19               60              38  \n",
       "20               20              38  \n",
       "21               40              38  \n",
       "22               40              38  \n",
       "23               40              38  \n",
       "24               40              38  \n",
       "25               40              38  \n",
       "26               80              38  \n",
       "27               40              38  \n",
       "28               52              38  \n",
       "29               44              38  \n",
       "..              ...             ...  \n",
       "970              40              38  \n",
       "971              75              38  \n",
       "972              40              38  \n",
       "973              40              38  \n",
       "974              47              38  \n",
       "975              35              38  \n",
       "976              40              38  \n",
       "977              32              25  \n",
       "978              40              38  \n",
       "979              80              38  \n",
       "980              40              38  \n",
       "981              80              38  \n",
       "982              40              38  \n",
       "983              50              38  \n",
       "984              60              38  \n",
       "985              20              38  \n",
       "986              40              38  \n",
       "987              50              38  \n",
       "988              46              38  \n",
       "989              15              38  \n",
       "990              20              38  \n",
       "991              40              38  \n",
       "992              50              35  \n",
       "993              40              38  \n",
       "994              40              38  \n",
       "995              40              38  \n",
       "996              35              38  \n",
       "997              60              38  \n",
       "998              40              38  \n",
       "999              40              38  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:1000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "9ac9a9c0-a3d5-4f0a-a6fa-02e44da30037",
    "_uuid": "1871ccf9-08cb-4838-b82c-1cf5a6c566df",
    "id": "MBFeYX_VSgbR",
    "outputId": "674f7363-4e8c-4913-99a7-2539ace1f838"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042796</td>\n",
       "      <td>-1.062722</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.146092</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880288</td>\n",
       "      <td>-1.007871</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-2.331531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>0.244693</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.108695</td>\n",
       "      <td>0.425240</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.794697</td>\n",
       "      <td>1.406658</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.109476</td>\n",
       "      <td>0.897180</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.804152</td>\n",
       "      <td>-0.280232</td>\n",
       "      <td>-2.008395</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-2.081109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.032559</td>\n",
       "      <td>0.187865</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.339636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.566290</td>\n",
       "      <td>-1.363097</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>1.754199</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.271203</td>\n",
       "      <td>-0.287217</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.551697</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.109476</td>\n",
       "      <td>0.858203</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>3.261224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.642425</td>\n",
       "      <td>-0.459028</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.175375</td>\n",
       "      <td>-0.639101</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.912474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.490154</td>\n",
       "      <td>0.144108</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.337883</td>\n",
       "      <td>0.527142</td>\n",
       "      <td>-2.400559</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.339636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.023104</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.495104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.490154</td>\n",
       "      <td>-0.028110</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>-1.523000</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.347338</td>\n",
       "      <td>0.969049</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.339636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.118931</td>\n",
       "      <td>0.035306</td>\n",
       "      <td>2.305411</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>1.591745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.184831</td>\n",
       "      <td>1.063425</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-1.747213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.261747</td>\n",
       "      <td>-1.069073</td>\n",
       "      <td>-2.008395</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.347338</td>\n",
       "      <td>-0.688651</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>4.832223</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.565509</td>\n",
       "      <td>-0.764580</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.337102</td>\n",
       "      <td>0.256099</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.479918</td>\n",
       "      <td>-0.203498</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.042796</td>\n",
       "      <td>1.679736</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>3.261224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.804152</td>\n",
       "      <td>0.033811</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.175375</td>\n",
       "      <td>0.008662</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.923953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.403782</td>\n",
       "      <td>0.721441</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.256162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>-0.490154</td>\n",
       "      <td>-0.966868</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>-0.642425</td>\n",
       "      <td>-0.786094</td>\n",
       "      <td>-0.831902</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>2.843854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.195067</td>\n",
       "      <td>1.063198</td>\n",
       "      <td>0.344590</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.804152</td>\n",
       "      <td>0.039433</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>4.485938</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.499610</td>\n",
       "      <td>-0.041730</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.506584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.347338</td>\n",
       "      <td>0.831540</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.495104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>1.717781</td>\n",
       "      <td>-0.576859</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>0.321215</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>1.184831</td>\n",
       "      <td>1.778561</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.745526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>-0.337883</td>\n",
       "      <td>-0.302011</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.804152</td>\n",
       "      <td>-0.130958</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>3.261224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>0.314338</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-0.261747</td>\n",
       "      <td>0.090469</td>\n",
       "      <td>1.913247</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>4.671448</td>\n",
       "      <td>3.261224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-0.185611</td>\n",
       "      <td>-1.512617</td>\n",
       "      <td>-0.831902</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>-0.642425</td>\n",
       "      <td>-0.077073</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>-0.185611</td>\n",
       "      <td>-0.686048</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>1.591745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>-1.251511</td>\n",
       "      <td>-1.474331</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-1.747213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>-0.538705</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>4.485938</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>-0.109476</td>\n",
       "      <td>0.241513</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.728017</td>\n",
       "      <td>-1.267670</td>\n",
       "      <td>2.305411</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>4.485938</td>\n",
       "      <td>0.423110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>-1.632189</td>\n",
       "      <td>0.289539</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-2.164583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>-1.479918</td>\n",
       "      <td>-1.455561</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-1.747213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>-0.870832</td>\n",
       "      <td>-0.493594</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>3.714218</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>-1.251511</td>\n",
       "      <td>0.014654</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.804152</td>\n",
       "      <td>-1.499792</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.347338</td>\n",
       "      <td>0.360774</td>\n",
       "      <td>0.344590</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.347338</td>\n",
       "      <td>-0.152065</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.479918</td>\n",
       "      <td>-0.208023</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.495104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.489374</td>\n",
       "      <td>-1.023669</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>1.591745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.195067</td>\n",
       "      <td>0.051719</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.566290</td>\n",
       "      <td>0.403982</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5    0    1   \\\n",
       "0    0.042796 -1.062722  1.128918  0.146092 -0.218586 -0.077734  0.0  0.0   \n",
       "1    0.880288 -1.007871  1.128918 -0.147445 -0.218586 -2.331531  0.0  0.0   \n",
       "2   -0.033340  0.244693 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "3    1.108695  0.425240 -1.224066 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "4   -0.794697  1.406658  1.128918 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "5   -0.109476  0.897180  1.521083 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "6    0.804152 -0.280232 -2.008395 -0.147445 -0.218586 -2.081109  0.0  0.0   \n",
       "7    1.032559  0.187865 -0.439738 -0.147445 -0.218586  0.339636  0.0  0.0   \n",
       "8   -0.566290 -1.363097  1.521083  1.754199 -0.218586  0.757005  0.0  0.0   \n",
       "9    0.271203 -0.287217  1.128918  0.551697 -0.218586 -0.077734  0.0  0.0   \n",
       "10  -0.109476  0.858203 -0.047574 -0.147445 -0.218586  3.261224  0.0  0.0   \n",
       "11  -0.642425 -0.459028  1.128918 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "12  -1.175375 -0.639101  1.128918 -0.147445 -0.218586 -0.912474  0.0  0.0   \n",
       "13  -0.490154  0.144108  0.736754 -0.147445 -0.218586  0.757005  0.0  0.0   \n",
       "14  -0.337883  0.527142 -2.400559 -0.147445 -0.218586  0.339636  0.0  0.0   \n",
       "15  -1.023104 -0.123404 -0.439738 -0.147445 -0.218586 -0.495104  0.0  0.0   \n",
       "16  -0.490154 -0.028110 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "17  -0.033340 -1.523000 -1.224066 -0.147445 -0.218586  0.757005  0.0  0.0   \n",
       "18   0.347338  0.969049  1.521083 -0.147445 -0.218586  0.339636  0.0  0.0   \n",
       "19   0.118931  0.035306  2.305411 -0.147445 -0.218586  1.591745  0.0  0.0   \n",
       "20   1.184831  1.063425 -0.439738 -0.147445 -0.218586 -1.747213  0.0  0.0   \n",
       "21  -0.261747 -1.069073 -2.008395 -0.147445 -0.218586 -0.077734  1.0  0.0   \n",
       "22   0.347338 -0.688651 -1.224066 -0.147445  4.832223 -0.077734  0.0  0.0   \n",
       "23   1.565509 -0.764580 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "24   1.337102  0.256099  1.128918 -0.147445 -0.218586 -0.077734  0.0  1.0   \n",
       "25  -1.479918 -0.203498 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "26   0.042796  1.679736 -0.439738 -0.147445 -0.218586  3.261224  0.0  0.0   \n",
       "27   0.804152  0.033811 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "28  -1.175375  0.008662  0.736754 -0.147445 -0.218586  0.923953  0.0  1.0   \n",
       "29  -1.403782  0.721441 -0.047574 -0.147445 -0.218586  0.256162  0.0  0.0   \n",
       "..        ...       ...       ...       ...       ...       ...  ...  ...   \n",
       "970 -0.490154 -0.966868  1.128918 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "971 -0.642425 -0.786094 -0.831902 -0.147445 -0.218586  2.843854  0.0  0.0   \n",
       "972  0.195067  1.063198  0.344590 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "973  0.804152  0.039433  1.521083 -0.147445  4.485938 -0.077734  0.0  1.0   \n",
       "974  0.499610 -0.041730 -0.439738 -0.147445 -0.218586  0.506584  0.0  0.0   \n",
       "975  0.347338  0.831540 -0.439738 -0.147445 -0.218586 -0.495104  0.0  0.0   \n",
       "976  1.717781 -0.576859 -0.439738  0.321215 -0.218586 -0.077734  0.0  0.0   \n",
       "977  1.184831  1.778561 -0.439738 -0.147445 -0.218586 -0.745526  0.0  0.0   \n",
       "978 -0.337883 -0.302011  0.736754 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "979  0.804152 -0.130958 -0.047574 -0.147445 -0.218586  3.261224  0.0  0.0   \n",
       "980 -0.033340  0.314338 -0.047574 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "981 -0.261747  0.090469  1.913247 -0.147445  4.671448  3.261224  0.0  0.0   \n",
       "982 -0.185611 -1.512617 -0.831902 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "983 -0.642425 -0.077073  1.128918 -0.147445 -0.218586  0.757005  0.0  0.0   \n",
       "984 -0.185611 -0.686048  0.736754 -0.147445 -0.218586  1.591745  0.0  0.0   \n",
       "985 -1.251511 -1.474331  1.128918 -0.147445 -0.218586 -1.747213  0.0  1.0   \n",
       "986 -0.033340 -0.538705 -0.439738 -0.147445  4.485938 -0.077734  0.0  0.0   \n",
       "987 -0.109476  0.241513 -0.439738 -0.147445 -0.218586  0.757005  0.0  0.0   \n",
       "988  0.728017 -1.267670  2.305411 -0.147445  4.485938  0.423110  0.0  0.0   \n",
       "989 -1.632189  0.289539 -1.224066 -0.147445 -0.218586 -2.164583  0.0  0.0   \n",
       "990 -1.479918 -1.455561 -0.047574 -0.147445 -0.218586 -1.747213  0.0  0.0   \n",
       "991 -0.870832 -0.493594  1.128918 -0.147445  3.714218 -0.077734  0.0  0.0   \n",
       "992 -1.251511  0.014654  1.128918 -0.147445 -0.218586  0.757005  0.0  0.0   \n",
       "993  0.804152 -1.499792 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "994  0.347338  0.360774  0.344590 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "995  0.347338 -0.152065  1.128918 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "996 -1.479918 -0.208023 -0.439738 -0.147445 -0.218586 -0.495104  0.0  1.0   \n",
       "997  1.489374 -1.023669 -0.439738 -0.147445 -0.218586  1.591745  0.0  0.0   \n",
       "998  0.195067  0.051719 -0.047574 -0.147445 -0.218586 -0.077734  0.0  1.0   \n",
       "999 -0.566290  0.403982 -0.047574 -0.147445 -0.218586 -0.077734  0.0  0.0   \n",
       "\n",
       "      2    3  ...    31   32   33   34   35   36   37   38   39   40  \n",
       "0    0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "1    0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2    1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3    1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4    1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5    1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "6    1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7    0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "8    1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "9    1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "10   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "11   0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "13   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "14   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15   0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "16   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "17   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "18   0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "19   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "20   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "21   0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "22   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "23   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "24   0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "25   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "26   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "27   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "28   0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "29   1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "..   ...  ... ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "970  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "971  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "972  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "973  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "974  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "975  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "976  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "977  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "978  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "979  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "980  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "981  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "982  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "983  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "984  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "985  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "986  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "987  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "988  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "989  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "990  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "991  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "992  1.0  0.0 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "993  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "994  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "995  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "996  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "997  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "998  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "999  1.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[1000 rows x 104 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[:1000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "35700ffb-780d-45de-befc-a1e93068f43d",
    "_uuid": "93ecbff8-cbf2-48fa-a04f-00b522c56cf1",
    "id": "IXMc_VCIkL6f"
   },
   "outputs": [],
   "source": [
    "test_data = pd.concat([X, Y,path_df], axis=1)\n",
    "# test_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "764ba672-bafe-46f2-8f82-18ca6dffe321",
    "_uuid": "dcef55e5-596a-4fb8-ad01-18049de43cf9",
    "id": "-nApFqW3kL6k",
    "outputId": "2919f0b5-9e93-4a94-9b5a-d03ab791a12e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 106)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "9204a195-bb80-42d7-bee1-ccfdcebd014a",
    "_uuid": "c2a099b7-60ea-4cb9-89af-cfb00aa6ed76",
    "id": "5ye6xGLdkL6v"
   },
   "outputs": [],
   "source": [
    "new_path = []\n",
    "for i, val in test_data.iterrows():\n",
    "    new_path.append(val['paths'].split(sep=\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "72849dce-9f4b-4c6f-9e50-8d3561b55f7c",
    "_uuid": "6c95e616-745b-487b-b822-c40fc21c5ff1",
    "id": "XuQDQSGakL65"
   },
   "outputs": [],
   "source": [
    "_ = [x.insert(0, 'S') for x in new_path]\n",
    "_ = [x.append('E') for x in new_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "de1814f0-a5cb-4001-abed-2e3c6a018da7",
    "_uuid": "8351ce71-79e6-4396-bbb8-44341b0ea3a8",
    "id": "4Zros1ZskL7A"
   },
   "outputs": [],
   "source": [
    "test_data['new_path'] = new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "ac212d38-cb9e-4ca6-8f26-1fe71d655c47",
    "_uuid": "6889c860-ff0f-4e5e-9f48-2073ac03844a",
    "id": "OmsS8R-akL7D"
   },
   "outputs": [],
   "source": [
    "test_data = test_data.drop([\"paths\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "2eebcb57-05b7-4872-98fd-f729075600c2",
    "_uuid": "138d8f5d-0a1e-4151-ad44-0dcef8bdcf48",
    "id": "x8ZuSmzjkL6z",
    "outputId": "2b91f3ba-caf8-49ef-c4a1-715966d1eb8f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>target</th>\n",
       "      <th>new_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042796</td>\n",
       "      <td>-1.062722</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.146092</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S, 6A0, 11B0, 14C0, 12D0, 1E0, 2F0, 6A0, E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880288</td>\n",
       "      <td>-1.007871</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-2.331531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S, 11G0, 13H0, 4I0, 8J0, 13K1, E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>0.244693</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S, 8L0, 11M0, 4N0, 13O0, 7P0, 1Q0, 4N0, E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.108695</td>\n",
       "      <td>0.425240</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S, 11G0, 7P0, 3R1, 2A0, 14C0, 8J0, 3S1, 12T0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.794697</td>\n",
       "      <td>1.406658</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[S, 11G0, 8V0, 1W0, 2A0, 1X0, E]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5    0    1    2  \\\n",
       "0  0.042796 -1.062722  1.128918  0.146092 -0.218586 -0.077734  0.0  0.0  0.0   \n",
       "1  0.880288 -1.007871  1.128918 -0.147445 -0.218586 -2.331531  0.0  0.0  0.0   \n",
       "2 -0.033340  0.244693 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0  1.0   \n",
       "3  1.108695  0.425240 -1.224066 -0.147445 -0.218586 -0.077734  0.0  0.0  1.0   \n",
       "4 -0.794697  1.406658  1.128918 -0.147445 -0.218586 -0.077734  0.0  0.0  1.0   \n",
       "\n",
       "     3                        ...                           33   34   35   36  \\\n",
       "0  0.0                        ...                          0.0  0.0  0.0  0.0   \n",
       "1  0.0                        ...                          0.0  0.0  0.0  0.0   \n",
       "2  0.0                        ...                          0.0  0.0  0.0  0.0   \n",
       "3  0.0                        ...                          0.0  0.0  0.0  0.0   \n",
       "4  0.0                        ...                          0.0  0.0  0.0  0.0   \n",
       "\n",
       "    37   38   39   40  target  \\\n",
       "0  0.0  1.0  0.0  0.0       0   \n",
       "1  0.0  1.0  0.0  0.0       0   \n",
       "2  0.0  1.0  0.0  0.0       0   \n",
       "3  0.0  1.0  0.0  0.0       0   \n",
       "4  0.0  0.0  0.0  0.0       0   \n",
       "\n",
       "                                            new_path  \n",
       "0       [S, 6A0, 11B0, 14C0, 12D0, 1E0, 2F0, 6A0, E]  \n",
       "1                 [S, 11G0, 13H0, 4I0, 8J0, 13K1, E]  \n",
       "2        [S, 8L0, 11M0, 4N0, 13O0, 7P0, 1Q0, 4N0, E]  \n",
       "3  [S, 11G0, 7P0, 3R1, 2A0, 14C0, 8J0, 3S1, 12T0,...  \n",
       "4                   [S, 11G0, 8V0, 1W0, 2A0, 1X0, E]  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "ea07ae53-6c0d-4274-9e01-8a1a6f688384",
    "_uuid": "95ac7de0-9b20-46e1-bdbe-cd3031a9298f",
    "id": "1HKxBuPckL7K"
   },
   "outputs": [],
   "source": [
    "paths_lengths = np.array([len(xi)\n",
    "                          for xi in test_data.iloc[:,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "4140b448-b6e7-4d5f-a728-455685fbe624",
    "_uuid": "ad947422-18d4-4fe9-884c-ec318d6edc66",
    "id": "SRKD0-TPkL7P",
    "outputId": "25e10a84-cd67-4653-c31d-3d4c057dd7ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_lengths\n",
    "np.max(paths_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6eb49d83-4c9d-419e-a46a-daa3146f56c5",
    "_uuid": "29026b5f-3da8-4a57-aca7-d3cc08dc9944",
    "id": "CEu4RO1HkL8E"
   },
   "source": [
    "## Create and train FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "971f7a7f-067f-4119-bea7-1d8a108421eb",
    "_uuid": "94b7e9f8-4c0b-4566-b4eb-412565d84a17",
    "id": "PX6K6IZAkL8H"
   },
   "outputs": [],
   "source": [
    "def _create_label_model(latent_dim=25, feature_size=104):\n",
    "    input_layer = Input(shape=(feature_size,), name='ip_x')\n",
    "    hidden_layer_x1 = Dense(10, activation='relu',\n",
    "                            name='hidden_x1')(input_layer)\n",
    "    hidden_layer_x2 = Dense(10, activation='relu',\n",
    "                            name='hidden_x2')(hidden_layer_x1)\n",
    "    hidden_layer_x3 = Dense(latent_dim, activation='relu',\n",
    "                            name='hidden_x3')(hidden_layer_x2)\n",
    "    output_layer = Dense(len(np.unique(Y)), activation='sigmoid',\n",
    "                         name='op_x')(hidden_layer_x3)\n",
    "    model = Model(input_layer, output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "cf93796f-74a6-4f2d-a733-dbead6bb4f17",
    "_uuid": "907791f8-676b-419b-bd72-e4934051a487",
    "id": "Jl_AaLoBkL8N"
   },
   "outputs": [],
   "source": [
    "label_model = _create_label_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "ff2d6e53-0a98-4bdf-9307-a50312dbd29e",
    "_uuid": "1821c712-0133-4053-84f2-363a0329c391",
    "id": "25JZ_moxqxTJ",
    "outputId": "785eace3-057f-479a-e15b-91fbea4ccc94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ip_x (InputLayer)            [(None, 104)]             0         \n",
      "_________________________________________________________________\n",
      "hidden_x1 (Dense)            (None, 10)                1050      \n",
      "_________________________________________________________________\n",
      "hidden_x2 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "hidden_x3 (Dense)            (None, 25)                275       \n",
      "_________________________________________________________________\n",
      "op_x (Dense)                 (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 1,487\n",
      "Trainable params: 1,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "label_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "a6ac620a-cc28-4e74-a49b-59de18485af6",
    "_uuid": "c5ae647c-c457-41a4-8c5f-347320793c55",
    "id": "lAeZWowXoWcz",
    "outputId": "aa100345-3a45-4038-e8d8-f304d9743044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "1a48d2a3-dfb9-4f98-8f84-cd28dfd948a3",
    "_uuid": "7a55da20-e705-494e-91bb-6b209aea707d",
    "id": "ce9lF-crpV4x",
    "outputId": "cc141bfd-6cec-4b02-bf1e-7f4f4c67f48d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042796</td>\n",
       "      <td>-1.062722</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.146092</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880288</td>\n",
       "      <td>-1.007871</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-2.331531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>0.244693</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.108695</td>\n",
       "      <td>0.425240</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.794697</td>\n",
       "      <td>1.406658</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5    0    1    2   \\\n",
       "0  0.042796 -1.062722  1.128918  0.146092 -0.218586 -0.077734  0.0  0.0  0.0   \n",
       "1  0.880288 -1.007871  1.128918 -0.147445 -0.218586 -2.331531  0.0  0.0  0.0   \n",
       "2 -0.033340  0.244693 -0.439738 -0.147445 -0.218586 -0.077734  0.0  0.0  1.0   \n",
       "3  1.108695  0.425240 -1.224066 -0.147445 -0.218586 -0.077734  0.0  0.0  1.0   \n",
       "4 -0.794697  1.406658  1.128918 -0.147445 -0.218586 -0.077734  0.0  0.0  1.0   \n",
       "\n",
       "    3  ...    31   32   33   34   35   36   37   38   39   40  \n",
       "0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "1  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "ca4393e2-f834-43b1-bcd3-01da0a970560",
    "_uuid": "0fd9fbc8-330d-4324-bcbb-0836661aabf2",
    "id": "t1bEyUZHkL8T"
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "\n",
    "    y_cat = to_categorical(Y)\n",
    "\n",
    "    label_model.compile(\n",
    "        optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(y_cat)\n",
    "    label_model.fit(\n",
    "        X, y_cat, batch_size=2000, epochs=50, verbose=1, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "51a72a98-c6a4-47a1-9c74-88ba564185b8",
    "_uuid": "993d0907-ea47-4fdf-bb03-22a9428a109c",
    "id": "Y3wp5glkkL8V",
    "outputId": "423157fb-e682-4f3e-e0c5-5a558393e874"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0415 11:08:19.705371 17680 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "Train on 24129 samples, validate on 6033 samples\n",
      "Epoch 1/50\n",
      "24129/24129 [==============================] - 1s 35us/sample - loss: 0.6955 - accuracy: 0.4835 - val_loss: 0.6805 - val_accuracy: 0.6311\n",
      "Epoch 2/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.6694 - accuracy: 0.7172 - val_loss: 0.6559 - val_accuracy: 0.7743\n",
      "Epoch 3/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.6403 - accuracy: 0.7852 - val_loss: 0.6193 - val_accuracy: 0.7906\n",
      "Epoch 4/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.5939 - accuracy: 0.7966 - val_loss: 0.5595 - val_accuracy: 0.8010\n",
      "Epoch 5/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.5240 - accuracy: 0.8111 - val_loss: 0.4808 - val_accuracy: 0.8133\n",
      "Epoch 6/50\n",
      "24129/24129 [==============================] - 0s 3us/sample - loss: 0.4465 - accuracy: 0.8209 - val_loss: 0.4131 - val_accuracy: 0.8209\n",
      "Epoch 7/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3947 - accuracy: 0.8260 - val_loss: 0.3786 - val_accuracy: 0.8289\n",
      "Epoch 8/50\n",
      "24129/24129 [==============================] - 0s 5us/sample - loss: 0.3726 - accuracy: 0.8289 - val_loss: 0.3643 - val_accuracy: 0.8324\n",
      "Epoch 9/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3623 - accuracy: 0.8329 - val_loss: 0.3558 - val_accuracy: 0.8365\n",
      "Epoch 10/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3550 - accuracy: 0.8341 - val_loss: 0.3505 - val_accuracy: 0.8386\n",
      "Epoch 11/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3498 - accuracy: 0.8371 - val_loss: 0.3466 - val_accuracy: 0.8386\n",
      "Epoch 12/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3463 - accuracy: 0.8388 - val_loss: 0.3432 - val_accuracy: 0.8402\n",
      "Epoch 13/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3428 - accuracy: 0.8406 - val_loss: 0.3403 - val_accuracy: 0.8422\n",
      "Epoch 14/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3401 - accuracy: 0.8418 - val_loss: 0.3380 - val_accuracy: 0.8427\n",
      "Epoch 15/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3377 - accuracy: 0.8432 - val_loss: 0.3356 - val_accuracy: 0.8437\n",
      "Epoch 16/50\n",
      "24129/24129 [==============================] - 0s 5us/sample - loss: 0.3353 - accuracy: 0.8445 - val_loss: 0.3339 - val_accuracy: 0.8429\n",
      "Epoch 17/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3339 - accuracy: 0.8459 - val_loss: 0.3319 - val_accuracy: 0.8441\n",
      "Epoch 18/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3317 - accuracy: 0.8472 - val_loss: 0.3304 - val_accuracy: 0.8458\n",
      "Epoch 19/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3302 - accuracy: 0.8481 - val_loss: 0.3290 - val_accuracy: 0.8456\n",
      "Epoch 20/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3290 - accuracy: 0.8484 - val_loss: 0.3275 - val_accuracy: 0.8462\n",
      "Epoch 21/50\n",
      "24129/24129 [==============================] - 0s 5us/sample - loss: 0.3279 - accuracy: 0.8490 - val_loss: 0.3261 - val_accuracy: 0.8466\n",
      "Epoch 22/50\n",
      "24129/24129 [==============================] - 0s 5us/sample - loss: 0.3268 - accuracy: 0.8485 - val_loss: 0.3255 - val_accuracy: 0.8451\n",
      "Epoch 23/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3260 - accuracy: 0.8488 - val_loss: 0.3250 - val_accuracy: 0.8448\n",
      "Epoch 24/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3255 - accuracy: 0.8494 - val_loss: 0.3258 - val_accuracy: 0.8470\n",
      "Epoch 25/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3250 - accuracy: 0.8489 - val_loss: 0.3232 - val_accuracy: 0.8469\n",
      "Epoch 26/50\n",
      "24129/24129 [==============================] - 0s 5us/sample - loss: 0.3239 - accuracy: 0.8497 - val_loss: 0.3229 - val_accuracy: 0.8476\n",
      "Epoch 27/50\n",
      "24129/24129 [==============================] - 0s 5us/sample - loss: 0.3231 - accuracy: 0.8500 - val_loss: 0.3223 - val_accuracy: 0.8484\n",
      "Epoch 28/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3226 - accuracy: 0.8500 - val_loss: 0.3222 - val_accuracy: 0.8473\n",
      "Epoch 29/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3223 - accuracy: 0.8498 - val_loss: 0.3217 - val_accuracy: 0.8472\n",
      "Epoch 30/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3217 - accuracy: 0.8500 - val_loss: 0.3210 - val_accuracy: 0.8480\n",
      "Epoch 31/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3213 - accuracy: 0.8509 - val_loss: 0.3208 - val_accuracy: 0.8486\n",
      "Epoch 32/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3208 - accuracy: 0.8511 - val_loss: 0.3207 - val_accuracy: 0.8492\n",
      "Epoch 33/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3204 - accuracy: 0.8511 - val_loss: 0.3206 - val_accuracy: 0.8490\n",
      "Epoch 34/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3199 - accuracy: 0.8512 - val_loss: 0.3200 - val_accuracy: 0.8489\n",
      "Epoch 35/50\n",
      "24129/24129 [==============================] - 0s 3us/sample - loss: 0.3195 - accuracy: 0.8516 - val_loss: 0.3193 - val_accuracy: 0.8490\n",
      "Epoch 36/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3197 - accuracy: 0.8504 - val_loss: 0.3203 - val_accuracy: 0.8459\n",
      "Epoch 37/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3192 - accuracy: 0.8505 - val_loss: 0.3199 - val_accuracy: 0.8489\n",
      "Epoch 38/50\n",
      "24129/24129 [==============================] - 0s 3us/sample - loss: 0.3190 - accuracy: 0.8515 - val_loss: 0.3200 - val_accuracy: 0.8465\n",
      "Epoch 39/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3192 - accuracy: 0.8511 - val_loss: 0.3195 - val_accuracy: 0.8501\n",
      "Epoch 40/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3184 - accuracy: 0.8504 - val_loss: 0.3190 - val_accuracy: 0.8487\n",
      "Epoch 41/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3183 - accuracy: 0.8506 - val_loss: 0.3192 - val_accuracy: 0.8478\n",
      "Epoch 42/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3182 - accuracy: 0.8502 - val_loss: 0.3192 - val_accuracy: 0.8483\n",
      "Epoch 43/50\n",
      "24129/24129 [==============================] - 0s 3us/sample - loss: 0.3178 - accuracy: 0.8512 - val_loss: 0.3193 - val_accuracy: 0.8505\n",
      "Epoch 44/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3175 - accuracy: 0.8518 - val_loss: 0.3182 - val_accuracy: 0.8496\n",
      "Epoch 45/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3173 - accuracy: 0.8521 - val_loss: 0.3188 - val_accuracy: 0.8475\n",
      "Epoch 46/50\n",
      "24129/24129 [==============================] - 0s 3us/sample - loss: 0.3172 - accuracy: 0.8508 - val_loss: 0.3184 - val_accuracy: 0.8500\n",
      "Epoch 47/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3167 - accuracy: 0.8516 - val_loss: 0.3180 - val_accuracy: 0.8493\n",
      "Epoch 48/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3165 - accuracy: 0.8512 - val_loss: 0.3183 - val_accuracy: 0.8499\n",
      "Epoch 49/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3164 - accuracy: 0.8518 - val_loss: 0.3196 - val_accuracy: 0.8461\n",
      "Epoch 50/50\n",
      "24129/24129 [==============================] - 0s 4us/sample - loss: 0.3170 - accuracy: 0.8513 - val_loss: 0.3181 - val_accuracy: 0.8514\n"
     ]
    }
   ],
   "source": [
    "fit_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "539a8c4d-db26-47b2-b104-c0c4e610f5c9",
    "_uuid": "e3d0eed5-2193-4798-abf0-a7d1ef3cd393",
    "id": "2PjhS6zGkL8v"
   },
   "source": [
    "## Path invariance trials using rpart -- generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "3c44f6e3-2df7-459e-be2d-ab9783d13d75",
    "_uuid": "dfc3db2d-285a-4cb6-888b-52cec33404a1",
    "id": "6rG1t4nvkL8w"
   },
   "outputs": [],
   "source": [
    "## Import nnum, vnum, nodes, csplit, split_df,\n",
    "## frame\n",
    "\n",
    "splits = pd.read_csv('../../data/raw/splits.csv', delimiter=\",\", index_col=0)\n",
    "csplit = pd.read_csv('../../data/raw/csplit.csv', delimiter=\",\")\n",
    "frame = pd.read_csv('../../data/raw/frame.csv', delimiter=\",\",index_col=0)\n",
    "\n",
    "# frame = frame.drop([\"Unnamed: 0\"], axis=1)\n",
    "frame = frame.rename(columns={\"var\": \"variable\"})\n",
    "# bin_labels = bin_labels.rename(columns={\"Unnamed: 0\": \"label\", \"label_list\": \"bins\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "8338a5eb-64d3-4adf-924c-34c91e21d93c",
    "_uuid": "8be60d42-56b0-4fb5-80af-db21d1be320e",
    "id": "bakroygYkL8x",
    "outputId": "7a19ec8d-9242-4e75-8b01-75b0b21b3a36"
   },
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "cec1a9ac-be8e-4107-8e80-e8f01ed54f09",
    "_uuid": "7bc0138e-9cf6-41ba-b95c-8a6e478235bd",
    "id": "VgZOVYbOkL80",
    "outputId": "14465b0d-2276-4489-dd11-582baaa6215d"
   },
   "outputs": [],
   "source": [
    "## Generate nnum, vnum, nodes(split_df and csplit - 2L if necessary)\n",
    "\n",
    "temp_frame = frame\n",
    "\n",
    "nc = temp_frame[[\"ncompete\", \"nsurrogate\"]]\n",
    "\n",
    "index = np.cumsum((frame[[\"variable\"]]!=\"<leaf>\").values + nc[[\"ncompete\"]].values + nc[[\"nsurrogate\"]].values)\n",
    "\n",
    "index_df = pd.DataFrame((np.insert(index,0,0)+1)[:-1], columns=[\"i\"], index=frame.index)\n",
    "\n",
    "temp_frame = pd.concat([temp_frame, index_df], axis=1)\n",
    "\n",
    "# temp_frame[temp_frame[[\"var\"]]==\"<leaf>\"]\n",
    "# temp_frame.where(temp_frame[[\"var\"]]==\"<leaf>\")\n",
    "# temp_frame.loc[temp_frame[[\"variable\"]]==\"<leaf>\", \"index\"] = 0\n",
    "temp_frame.i[temp_frame.variable == \"<leaf>\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "33d68c3f-156e-4555-bdea-51a7c1956953",
    "_uuid": "6cf624a2-6185-40d6-97d5-2fbfefc65bf9",
    "id": "9dvHbQijkL82",
    "outputId": "5175a204-1e5f-4ce8-c6ac-ce75ef2a04ce"
   },
   "outputs": [],
   "source": [
    "temp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "8d23631f-20c1-4f89-bb6e-33aa2b525c45",
    "_uuid": "fcdd6cba-1ebc-419e-a871-6271d4a12fb7",
    "id": "HSwQ-WbBkL85"
   },
   "outputs": [],
   "source": [
    "nodes = temp_frame[[\"n\", \"ncompete\", \"nsurrogate\", \"i\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "c2b62e99-377b-401f-b1bb-ac5a8e763773",
    "_uuid": "1146e881-22bb-4d72-9903-4ca75c366c1a",
    "id": "HqwUhv_6kL88",
    "outputId": "9c1675e1-9a7b-49d5-ceaf-0b2fcde567eb"
   },
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "5ead3abd-1179-472d-942a-a9743bf8e2b3",
    "_uuid": "28fd8b77-ebdc-4199-98f0-a3e594a2db18",
    "id": "JKb9GYXFkL8-"
   },
   "outputs": [],
   "source": [
    "def load_tree_details(index): # Returns nnum, nodes, vnum, splits, temp_frame\n",
    "    splits_dir = '../../data/raw/local_dt_df/splits'+'_'+str(index)+'.csv'\n",
    "    frame_dir = '../../data/raw/local_dt_df/frame'+'_'+str(index)+'.csv'\n",
    "    splits = pd.read_csv(splits_dir, delimiter=\",\", index_col=0)\n",
    "    frame = pd.read_csv(frame_dir, delimiter=\",\",index_col=0)\n",
    "    \n",
    "    frame = frame.rename(columns={\"var\": \"variable\"})\n",
    "    \n",
    "    temp_frame = frame\n",
    "\n",
    "    nc = temp_frame[[\"ncompete\", \"nsurrogate\"]]\n",
    "\n",
    "    index = np.cumsum((frame[[\"variable\"]]!=\"<leaf>\").values + nc[[\"ncompete\"]].values + nc[[\"nsurrogate\"]].values)\n",
    "\n",
    "    index_df = pd.DataFrame((np.insert(index,0,0)+1)[:-1], columns=[\"i\"], index=frame.index)\n",
    "\n",
    "    temp_frame = pd.concat([temp_frame, index_df], axis=1)\n",
    "\n",
    "    temp_frame.i[temp_frame.variable == \"<leaf>\"] = 0\n",
    "    \n",
    "    nodes = temp_frame[[\"n\", \"ncompete\", \"nsurrogate\", \"i\"]]\n",
    "    \n",
    "    nnum = list(temp_frame.index)\n",
    "\n",
    "    feature_names = [\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]\n",
    "\n",
    "    vnum = list(map(feature_names.index, splits.index))\n",
    "    \n",
    "    return nnum, nodes, vnum, splits, temp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "649d761f-5fd8-4930-b2c5-d6c67246e8e3",
    "_uuid": "825e2318-eb7a-4b86-9df2-1a5e686a931b",
    "id": "bl__ofFAkL9A"
   },
   "outputs": [],
   "source": [
    "nnum = list(temp_frame.index) # row names of temp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "98fdbaa9-ff5f-495b-8d25-050c3dfaf1b3",
    "_uuid": "04080f7c-2621-41c8-b862-c7c968f0513a",
    "id": "O1faDbeUkL9D",
    "outputId": "fe24f2d6-f4c3-4212-84b9-d70e4b79039e"
   },
   "outputs": [],
   "source": [
    "nnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "8985592d-64aa-4c07-89ea-e384faf7bc58",
    "_uuid": "0978b424-0d18-4aa5-91e8-0797d4026c9d",
    "id": "SOXS6qOXkL9E"
   },
   "outputs": [],
   "source": [
    "feature_names = [\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]\n",
    "\n",
    "vnum = list(map(feature_names.index, splits.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "dc94a1a1-956c-404c-a4cd-40975d4132bf",
    "_uuid": "48588eb6-3f56-44fe-9ba5-a016a1b7c688",
    "id": "ccT5PRH5kL9H",
    "outputId": "ced20285-2281-47e9-c619-3811e195138e"
   },
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "b97c5a29-6ea1-44fb-a3b7-73601fc80ace",
    "_uuid": "62747078-4085-4518-be31-b047fe15abc1",
    "id": "TXQzKfhwkL9K"
   },
   "outputs": [],
   "source": [
    "sample_path = ['S', '3A0', '4C1', '2AD1', 'E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "fda8a3aa-5903-4d6e-a2d5-5f4e8da0d11b",
    "_uuid": "3147fd0c-2c31-417f-b4f2-5d60d3ebe46f",
    "id": "pT_l9p5ukL9T"
   },
   "outputs": [],
   "source": [
    "def return_yval(path, index): # [1,0,0,0]\n",
    "    nnum, nodes, vnum, splits, temp_frame = load_tree_details(index)\n",
    "    path = path[1:-1]\n",
    "    node = 0\n",
    "    nspl = 1\n",
    "    i = 0\n",
    "    while nspl != 0:\n",
    "        npos = nnum[node] # i)0, \n",
    "        nspl = nodes.iloc[npos-1][3] # i)1\n",
    "        var = vnum[nspl]\n",
    "        # ncat\n",
    "        temp = splits.iloc[nspl][3]\n",
    "        if nspl > 0:\n",
    "            print(\"nspl succeeded\")\n",
    "            if  int(path[i][0]) != var:\n",
    "                print(\"Wrong feature -- \", path[i][0], var)\n",
    "                return False\n",
    "                break\n",
    "            elif int(path[i][-1]) == 0: # i)1\n",
    "                direction = -1\n",
    "                i+=1\n",
    "            else:\n",
    "                direction = 1\n",
    "                i+=1\n",
    "\n",
    "            if direction == -1:\n",
    "                print(node)\n",
    "                if node == 0:\n",
    "                    node = 1\n",
    "                node = 2 * node\n",
    "            else:\n",
    "                print(node)\n",
    "                if node == 0:\n",
    "                    node = 1\n",
    "                node = 2 * node + 1\n",
    "            if len(path) == 1:\n",
    "                nspl = 0\n",
    "        else:\n",
    "            print('nspl failed')\n",
    "            print(\"leaf node -- \", node)\n",
    "            yval = temp_frame.iloc[node][4]\n",
    "    return temp_frame.iloc[node][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "cab8ebe4-81a2-4c62-944d-54f82472325b",
    "_uuid": "73654a03-225e-452a-abf8-7cd031599336",
    "id": "E5wGX7Q4kL9X",
    "outputId": "24456aab-d7a1-48eb-be02-3c8151f41597"
   },
   "outputs": [],
   "source": [
    "\n",
    "path = [1,1,0,1]\n",
    "a = [1,0,0,0]\n",
    "b = [1,1,1]\n",
    "c = [0]\n",
    "d = [1,1,1,1,1,1,0]\n",
    "e = [1,0,1,0,0]\n",
    "return_yval(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "b7c36c08-2cdd-4f00-875c-4a886100791c",
    "_uuid": "b0ac2cf4-443a-4562-aefb-e9834dc29dac",
    "id": "JEdr0lMfkL9b",
    "outputId": "7ae3200a-c291-4f45-e36f-3624934bb69f"
   },
   "outputs": [],
   "source": [
    "return_yval(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "56832ab1-79a1-4610-8d55-f41381dc9bd0",
    "_uuid": "efa30638-7414-4388-a283-fb1c63479770",
    "id": "F5Oq1MrjkL9d",
    "outputId": "d8083160-0507-442b-bc42-5a9d26ee00dc"
   },
   "outputs": [],
   "source": [
    "temp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "92518eca-550d-4ea0-9dae-6f7a2f8049e2",
    "_uuid": "0958b5d6-18d6-4fd7-a2fd-ce4c107fcc27",
    "id": "hiLp1rxlkL9i",
    "outputId": "50bab2f9-b5d2-4f83-8479-fb6608b846e3"
   },
   "outputs": [],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "37096fd3-8fc4-479f-8a7c-0a2803a58126",
    "_uuid": "886b5c5b-e3db-46da-912c-3f6edc91e39c",
    "id": "THzEK4KskL9l",
    "outputId": "7001c3e7-b7c9-4dcf-8587-8724488ebb22"
   },
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a97f678e-3521-4f41-8470-3ecfce0d6164",
    "_uuid": "0e13ea31-b171-4cd1-a243-0490072689c0",
    "id": "gDR4XAFAkL9o"
   },
   "source": [
    "## Bin reduction(EMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "0fea3707-7d6f-4d8b-b146-6d4639e07bec",
    "_uuid": "e0d5e33e-19df-412c-8bd8-6a347200b2d2",
    "id": "8EZihS7QkL-w"
   },
   "outputs": [],
   "source": [
    "## Pyemd approach -- categorical var\n",
    "'''\n",
    "Max levels = 3; (a,b,c)\n",
    "actual_bins = [(a), (b,c), (a,c), (b), (c)]\n",
    "actual_freq = [10.0, 3.0, 4.0, 1.0, 5.0]\n",
    "possible_out = [(a), (b), (c), (a,b), (a,c), (b,c)]\n",
    "'''\n",
    "\n",
    "actual_bins = [['a'], ['b','c'], ['a','c'], ['a','b'], ['c']]\n",
    "possible_out = [['a'], ['b','c'], ['a','c'], ['a','b'], ['b'], ['c']]\n",
    "\n",
    "\n",
    "dist_list = []\n",
    "emd_trials = {}\n",
    "for index in range(1000):\n",
    "    ext_bins = np.random.choice(actual_bins, 3, replace=False).tolist()\n",
    "    ext_freq = []\n",
    "    # actual_freq = [10.0, 3.0, 4.0, 1.0, 5.0]\n",
    "    actual_freq = [10.0, 3.0, 4.0, 1.0, 5.0]\n",
    "    actual_freq_norm = normalize([actual_freq], norm='l1').reshape(5,)\n",
    "    for i, x in enumerate(ext_bins):\n",
    "        new_freq = []\n",
    "        for j, b in enumerate(actual_bins):\n",
    "            c = 1/(np.sqrt(2*np.pi))\n",
    "            # dist = 1 - get_j_coeff(b, x) # Change distance metric\n",
    "            dist = distance.levenshtein(b,x)\n",
    "            dist = -((np.power(dist,2))/2)\n",
    "            d = np.exp(dist)\n",
    "            w = c * d\n",
    "            new_freq.append(w * actual_freq[j])\n",
    "        ext_freq.append(sum(new_freq))\n",
    "\n",
    "    combined_bins = copy(actual_bins)\n",
    "    for _, val in enumerate(ext_bins):\n",
    "        combined_bins.append(val)\n",
    "\n",
    "    dist_matrix = np.zeros((8,8), dtype='float64')\n",
    "    ## Distance\n",
    "    for i, val in enumerate(combined_bins):\n",
    "        for j, val_2 in enumerate(combined_bins):\n",
    "            # dist_matrix[i,j] = distance.euclidean(combined_bins[i], combined_bins[j])\n",
    "            # dist_matrix[i,j] = get_j_coeff(combined_bins[i], combined_bins[j])\n",
    "            dist_matrix[i,j] = distance.levenshtein(combined_bins[i], combined_bins[j])\n",
    "    \n",
    "    ext_freq_norm = normalize([ext_freq], norm='l1').reshape(3,)\n",
    "    \n",
    "    for i in range(len(actual_freq)):\n",
    "        # ext_freq.insert(0, 0.0)\n",
    "        ext_freq_norm = np.insert(ext_freq_norm, 0, 0.0)\n",
    "\n",
    "    for i in range(len(ext_bins)):\n",
    "        # actual_freq.append(0.0)\n",
    "        actual_freq_norm = np.append(actual_freq_norm, 0.0)\n",
    "\n",
    "    # ext_freq = np.array(ext_freq)    \n",
    "    # actual_freq = np.array(actual_freq)\n",
    "    \n",
    "    emd_val, min_cost_flow = pyemd.emd_with_flow(actual_freq_norm, ext_freq_norm, dist_matrix)\n",
    "    dist_list.append(emd_val)\n",
    "    emd_trials.update({index:{'distance':emd_val, 'flow_matrix':min_cost_flow,\n",
    "                             'actual_bins':actual_bins, 'actual_freq_norm':actual_freq_norm,\n",
    "                             'ext_bins':ext_bins, 'ext_freq_norm':ext_freq_norm,\n",
    "                             'dist_matrix': dist_matrix}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "c3c51295-f5af-4759-b318-1c2b27ff1220",
    "_uuid": "daba0414-0777-49cf-9584-39f0f210fd7a",
    "id": "kQljd7h_kL-8",
    "outputId": "87e2099d-eae9-450a-eb07-e5355c6b6c53"
   },
   "outputs": [],
   "source": [
    "dist_list.index(max(dist_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "54fa4b72-a3bc-4dce-900d-a7d816fdd21e",
    "_uuid": "c79916b7-3a96-41d7-9fac-1b9b0fdc4567",
    "id": "hsymjqZ3kL--",
    "outputId": "127932b2-879e-4a30-e178-e09cedc6ab4a"
   },
   "outputs": [],
   "source": [
    "min(dist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "63aad899-210f-4b4d-9883-d99f2c23537f",
    "_uuid": "8ac45ce1-a6bf-4f35-9641-6c1efc62498a",
    "id": "VRbT78J0kL-_",
    "outputId": "24c15be2-4736-4ee1-8795-bc11e887aea2"
   },
   "outputs": [],
   "source": [
    "max(dist_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1f972e3-1dc0-472d-ad5a-b98e41044b04",
    "_uuid": "5e11f85b-5a2f-4c96-967d-2f27a6e1f581",
    "id": "wvXfnCn0kL_R"
   },
   "source": [
    "### Path and bin conversions for dag_arch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "51d5a18c-59ee-49cc-8132-49888756d511",
    "_uuid": "cf07fd7c-71b1-48de-be42-b022050b0ce4",
    "id": "YFuDAXe2kL_R",
    "outputId": "e55f0149-9d55-4988-e272-57760591b9e3"
   },
   "outputs": [],
   "source": [
    "bin_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "ff3074de-cfb3-4621-b366-b8a711868d31",
    "_uuid": "5ced035d-ef9a-419f-b36a-feff24e31713",
    "id": "dy_WcgPbkL_U",
    "outputId": "740d3232-9670-45bf-9afc-0c765cf2308a"
   },
   "outputs": [],
   "source": [
    "path_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "6df86c88-46ab-404d-a7d2-02bbcdb79f6f",
    "_uuid": "c4c53158-20f1-45d3-bcbb-9c51e9749cc5",
    "id": "HtVDgzqNkL_V",
    "outputId": "bd65fd59-e0e0-42a7-f621-04c20c92983a"
   },
   "outputs": [],
   "source": [
    "bin_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "326f786d-ed15-433d-b14a-a57722a82ce0",
    "_uuid": "ec2d4955-8261-408f-967a-fd0f780c6962",
    "id": "NZ5fOixWkL_W",
    "outputId": "33cd95e5-356b-4d4e-b199-93285330671d"
   },
   "outputs": [],
   "source": [
    "test_var = path_df['paths'][1].split(',')[1]\n",
    "temp = re.compile(\"(\\d+)(\\w+)(\\d+)\") \n",
    "res = temp.match(test_var).groups()\n",
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "3c92c8d8-1028-455a-92f0-94da352132a0",
    "_uuid": "7bedb592-9546-4b83-b65f-930475406beb",
    "id": "vUxYnk1MkL_Z",
    "outputId": "6880faf3-355c-4fc9-add0-8d4e9b9a8988"
   },
   "outputs": [],
   "source": [
    "test_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "d6002cd0-c0ce-4e16-9768-f2d9fab27d19",
    "_uuid": "f25587e9-1ba6-4c5d-88b3-64d25c37a02c",
    "id": "xqZMPCh8kL_a"
   },
   "outputs": [],
   "source": [
    "bin_freq = {}\n",
    "bin_labels['freq'] = 0\n",
    "for i, val in path_df.iterrows():\n",
    "    label_list = val['paths'].split(',')\n",
    "    for j, val2 in enumerate(label_list):\n",
    "        temp = re.compile(\"(\\d+)(\\w+)(\\d+)\") \n",
    "        res = temp.match(val2).groups()\n",
    "        bin_labels.loc[bin_labels['label'] == res[1], 'freq'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "c8796b9c-9322-4e61-88fd-cdec0d12dbc7",
    "_uuid": "608bb1fb-8b5f-43e8-9e0f-396d5f18ff3b",
    "id": "B9-hIcLlkL_c",
    "outputId": "af5ea0ff-3c20-4630-80b6-e743f6ebb963"
   },
   "outputs": [],
   "source": [
    "bin_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "435884c0-149e-42a1-8ef4-bce9a77b0809",
    "_uuid": "b9fa979e-017d-48fd-9c1e-54cecaacdb49",
    "id": "m2-EdxO2kL_d",
    "outputId": "5fd6335e-17ea-41a1-d674-86c8911034f6"
   },
   "outputs": [],
   "source": [
    "bin_labels.loc[bin_labels['freq']!=0,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "da0ef06f-7d38-44d6-a307-80f77fb695b5",
    "_uuid": "036df452-7d1c-4d42-ae6e-6d6588f482a6",
    "id": "yxQvXF8HkL_f",
    "outputId": "8865ad42-8b5f-455b-ef91-f9a525717e76"
   },
   "outputs": [],
   "source": [
    "bin_labels = bin_labels.sort_values(by=['x']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "2d6dde86-2995-46f7-a853-56037e836c72",
    "_uuid": "500d83fa-bef3-4b2c-bb5a-e430ebee5b3d",
    "id": "6uelnzxlkL_g"
   },
   "outputs": [],
   "source": [
    "bin_labels = bin_labels.loc[bin_labels['freq'] != 0].reset_index(drop=True) ## Try fixing at R level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "aa2eb33a-6629-4b22-8f3c-9cd4c94d786c",
    "_uuid": "d4d012fb-801d-49e6-9111-60ef6c69f2e6",
    "id": "7XvR-N9SkL_h",
    "outputId": "5a845570-64d5-4102-fed4-7af32b4a8e27"
   },
   "outputs": [],
   "source": [
    "bin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "b6805e38-9412-4e09-8b29-4b26eee8abb8",
    "_uuid": "a49fab14-33e1-45f6-a6f4-8d85cadb490e",
    "id": "FvtykqBjkL_k"
   },
   "outputs": [],
   "source": [
    "actual_bins = bin_labels['x'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "1deeabfb-1e73-4786-8870-f210f0996871",
    "_uuid": "efa86758-41eb-402d-8570-85f0f126bda7",
    "id": "02DqJ7WJkL_k",
    "outputId": "ac700a21-a90f-4f8a-b63e-a8f6a2886941"
   },
   "outputs": [],
   "source": [
    "len(actual_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "fb1ab005-29ce-45a3-8f35-1af75008b15c",
    "_uuid": "f63ce0dd-bd4c-4e85-94fb-07e6c5b4daae",
    "id": "olXBA7cukL_n"
   },
   "outputs": [],
   "source": [
    "import pyemd\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial import distance as scipy_distance\n",
    "from copy import copy\n",
    "import numpy as np\n",
    "\n",
    "dist_list = []\n",
    "emd_trials = {}\n",
    "for index in range(1000):\n",
    "    ext_bins = sorted(np.random.uniform(actual_bins[0],actual_bins[-1], 20))\n",
    "    ext_freq = []\n",
    "    # actual_freq = [10.0, 3.0, 4.0, 1.0, 5.0]\n",
    "    actual_freq = bin_labels['freq'].tolist()\n",
    "    actual_freq_norm = normalize([actual_freq], norm='l1').reshape(29,)\n",
    "    for i, x in enumerate(ext_bins):\n",
    "        new_freq = []\n",
    "        for j, b in enumerate(actual_bins):\n",
    "            c = 1/(np.sqrt(2*np.pi))\n",
    "            # dist = -(((x-b)**2)/2)\n",
    "            dist = -((np.power((x-b),2))/2)\n",
    "            d = np.exp(dist)\n",
    "            w = c * d\n",
    "            new_freq.append(w * actual_freq[j])\n",
    "        ext_freq.append(sum(new_freq))\n",
    "\n",
    "    combined_bins = copy(actual_bins)\n",
    "    for _, val in enumerate(ext_bins):\n",
    "        combined_bins.append(val)\n",
    "\n",
    "    # dist_matrix = np.zeros((112,112), dtype='float64')\n",
    "    dist_matrix = np.zeros((49,49), dtype='float64')\n",
    "    ## Distance\n",
    "    for i, val in enumerate(combined_bins):\n",
    "        for j, val_2 in enumerate(combined_bins):\n",
    "            dist_matrix[i,j] = scipy_distance.euclidean(combined_bins[i], combined_bins[j])\n",
    "    \n",
    "    ext_freq_norm = normalize([ext_freq], norm='l1').reshape(20,)\n",
    "    \n",
    "    for i in range(len(actual_freq)):\n",
    "        # ext_freq.insert(0, 0.0)\n",
    "        ext_freq_norm = np.insert(ext_freq_norm, 0, 0.0)\n",
    "\n",
    "    for i in range(len(ext_bins)):\n",
    "        # actual_freq.append(0.0)\n",
    "        actual_freq_norm = np.append(actual_freq_norm, 0.0)\n",
    "\n",
    "    # ext_freq = np.array(ext_freq)    \n",
    "    # actual_freq = np.array(actual_freq)\n",
    "    \n",
    "    emd_val, min_cost_flow = pyemd.emd_with_flow(actual_freq_norm, ext_freq_norm, dist_matrix)\n",
    "    dist_list.append(emd_val)\n",
    "    emd_trials.update({index:{'distance':emd_val, 'flow_matrix':min_cost_flow,\n",
    "                             'actual_bins':actual_bins, 'actual_freq_norm':actual_freq_norm,\n",
    "                             'ext_bins':ext_bins, 'ext_freq_norm':ext_freq_norm,\n",
    "                             'dist_matrix': dist_matrix}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "d92f32ea-af17-48e7-b5c0-521e23e9e3d0",
    "_uuid": "ea4b09c4-1ea9-4015-8f35-a93acd9723a0",
    "id": "IudW1ncSkL_p",
    "outputId": "159c2182-558f-4df0-b8eb-64ba71274f62"
   },
   "outputs": [],
   "source": [
    "dist_list.index(min(dist_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "175d78fa-5137-4efc-aec6-f94844ee6d20",
    "_uuid": "7a0ce389-1cbc-42c6-87a9-a0ccdf94ea38",
    "id": "CWHSg8X2kL_q",
    "outputId": "273b2912-cb5f-4474-ac42-eb0b1293abf4"
   },
   "outputs": [],
   "source": [
    "min(dist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "3a74dbfc-efa3-4886-8812-91622865cd4f",
    "_uuid": "4c57ed88-7019-41b4-ab19-7d097038b807",
    "id": "PCC7-IxLkL_r"
   },
   "outputs": [],
   "source": [
    "reduced_bins = emd_trials[200]['ext_bins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "efa36a79-5e6a-4bf6-9564-fb9abe943f25",
    "_uuid": "583086ab-3474-43e1-8fc7-7b5b2e1561aa",
    "id": "jcsReRTNkL_s",
    "outputId": "4d963fb3-4167-4892-def7-b4f07ae9defa"
   },
   "outputs": [],
   "source": [
    "len(reduced_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "f9a35c20-f972-4a01-9bdb-ecb976a868f6",
    "_uuid": "a18b83d7-3a73-40f6-a121-9d7d6d6a3761",
    "id": "5k9PA0jjkL_u",
    "outputId": "615dd4a3-2a36-4fdf-de40-4512479fd7f1"
   },
   "outputs": [],
   "source": [
    "np.array(emd_trials[15]['flow_matrix']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "0f991178-6946-48d3-b6ad-c54cc05d47ab",
    "_uuid": "bfeed48e-4398-4584-8d9f-fa4d2855e457",
    "id": "DcgQkKVYkL_v"
   },
   "outputs": [],
   "source": [
    "def get_bin_mappings(flow_matrix_dim, emd_index):\n",
    "    # mapping_list = []\n",
    "    mapping_dict = {}\n",
    "    for i in range(flow_matrix_dim):\n",
    "        for j in range(flow_matrix_dim):\n",
    "            if emd_trials[emd_index]['flow_matrix'][i][j] != 0.0:\n",
    "                # mapping_list.append([emd_trials[emd_index]['flow_matrix'][i][j], (i,j)])\n",
    "                deep_set(mapping_dict, [i, j], emd_trials[emd_index]['flow_matrix'][i][j])\n",
    "                \n",
    "    return mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "418ae4bf-53bf-4f39-aeb8-9d31fef991e7",
    "_uuid": "a9e38d30-7fae-41b4-bc39-0ff347cc86f7",
    "id": "JknXBj9LkL_x"
   },
   "outputs": [],
   "source": [
    "from dict_deep import deep_set\n",
    "bin_mappings = get_bin_mappings(49, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "8f3015e8-1a64-4d5a-9e05-2d0151a86439",
    "_uuid": "800e0dd9-0979-480e-a4e1-d510033a0b82",
    "id": "2j5PabyekL_z",
    "outputId": "9bdd716f-488c-4c63-ae96-6c1a23d255ca"
   },
   "outputs": [],
   "source": [
    "bin_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "07880348-6822-426b-924d-ba278e01453e",
    "_uuid": "d568c836-6a85-4a59-9849-d93f7ffad8c0",
    "id": "IlArXXQbkL_1"
   },
   "outputs": [],
   "source": [
    "from string import ascii_uppercase\n",
    "labels = []\n",
    "for i in range(len(ascii_uppercase)):\n",
    "    labels.append(ascii_uppercase[i])\n",
    "    \n",
    "for i in range(len(ascii_uppercase)):\n",
    "    if len(labels) >= 41:\n",
    "        break\n",
    "    for j in range(len(ascii_uppercase)):\n",
    "        labels.append(\"\".join([ascii_uppercase[i],ascii_uppercase[j]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "ecec5487-199c-4692-ab24-28a152ba8e85",
    "_uuid": "fb78d80a-806d-4c69-886d-b0fd2685d80b",
    "id": "nk9UXV9MkL_3",
    "outputId": "aa6a81e4-7a6a-475f-949d-9289eee86030"
   },
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "c0125be1-4855-45da-b301-85971afb4db6",
    "_uuid": "2bd2ac38-e4d6-4637-9063-2d327ad5cc01",
    "id": "oFUHOzKykL_4"
   },
   "outputs": [],
   "source": [
    "bin_labels['new_bins'] = 0\n",
    "bin_labels['new_index'] = 0\n",
    "bin_labels['new_labels'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "40df722a-07f3-4ea6-b928-96e83afc80a6",
    "_uuid": "bc0efd1a-19cc-4b31-b062-d6038b725c2b",
    "id": "hw0Z64-pkMAE",
    "outputId": "d58cbe54-df46-4ce5-ed55-a773e579ad5e"
   },
   "outputs": [],
   "source": [
    "bin_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "5de08c21-2aad-41fb-a2bb-047db86d6e2b",
    "_uuid": "4b46353a-d415-400b-8afd-d0e64efc7479",
    "id": "UqEe4oKrkMAF",
    "outputId": "0d1e7074-2850-4ab2-8d4f-2583bfaa57f7"
   },
   "outputs": [],
   "source": [
    "len(reduced_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "11e7e62d-3a17-41f6-8af4-b3ec373718d6",
    "_uuid": "45c6edb9-8479-4911-8ee9-cfd33168e140",
    "id": "j_3bt2AFkMAH"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "for i, (k,val) in enumerate(bin_mappings.items()):\n",
    "    reduced_bin_index = max(val.items(), key=operator.itemgetter(1))[0] - 29\n",
    "    bin_labels.loc[k,'new_index'] = reduced_bin_index\n",
    "    bin_labels.loc[k,'new_bins'] = reduced_bins[reduced_bin_index]\n",
    "    bin_labels.loc[k,'new_labels'] = labels[reduced_bin_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "d79fd69d-e09e-441a-8444-7a02e07e6919",
    "_uuid": "f0942a61-f50a-41f2-b6e1-6e87bdab4729",
    "id": "L34EtJbQkMAI",
    "outputId": "573bff71-7cc2-4652-d7af-5aafd5c42985"
   },
   "outputs": [],
   "source": [
    "bin_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "42703c7e-6f3e-4106-97bc-322371c9c0ea",
    "_uuid": "f75bd025-86bb-47ab-8206-da53e8372f8f",
    "id": "Dl8JfnqUkMAO"
   },
   "source": [
    "### Updated paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "0b8ff0e0-8142-4837-9999-f4ebd7a7454e",
    "_uuid": "08e42f98-211c-4a0c-97b6-e669eb0ccab1",
    "id": "xKHQWmnqkMAP",
    "outputId": "d1dc0ae9-012c-4db4-9990-6e4c9232c98e"
   },
   "outputs": [],
   "source": [
    "path_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "3fb3c6e3-fbac-4b2b-9659-c4068103249e",
    "_uuid": "dd6dc805-3e56-4f8b-84d7-bc439085fd3a",
    "id": "qyVZaZXNkMAQ"
   },
   "outputs": [],
   "source": [
    "path_df['updated_path'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "4cdc84d4-5c9b-40a0-b58d-f3f426697b72",
    "_uuid": "2a313e3d-e3ce-46cc-8630-5c2afdbdef18",
    "id": "V5qznv1skMAR",
    "outputId": "e7a6b2ad-5a4d-4cb6-a33c-512b205a33dc"
   },
   "outputs": [],
   "source": [
    "path_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "c2164447-6bcb-4a4d-b383-49fbb44427e8",
    "_uuid": "fd110adc-3757-47ac-ae60-aae1b3d5eee9",
    "id": "zrVDVEeGkMAT",
    "outputId": "9b3a60b6-6092-4a59-9037-0f88de28bf4e"
   },
   "outputs": [],
   "source": [
    "bin_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "dca35069-cf23-4762-8173-4dac4e2d35a7",
    "_uuid": "e2729800-ef50-4fa5-9591-03195724f151",
    "id": "nhtoap7xkMAU"
   },
   "outputs": [],
   "source": [
    "for i, val in path_df.iterrows():\n",
    "    label_list = val['new_col'].split(',')\n",
    "    updated_list = []\n",
    "    for j, val2 in enumerate(label_list):\n",
    "        # bin_labels.loc[bin_labels['label'] == val2[1:-1], 'freq'] += 1\n",
    "        new_label = bin_labels.loc[bin_labels['label'] == val2[1:-1]]['new_labels'].values[0]\n",
    "        updated_list.append(val2[0] + new_label + val2[-1])\n",
    "        if len(updated_list)>1:\n",
    "            path_df.loc[i,'updated_path'] = (',').join(updated_list)\n",
    "        else:\n",
    "            path_df.loc[i,'updated_path'] = updated_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "ca93207d-6538-4e4c-b8bc-677b4afbec08",
    "_uuid": "7a6f7e0c-774c-4dd0-88da-0e47a2bdde7e",
    "id": "F2loSF_CkMAW",
    "outputId": "4602ce9f-d811-4a6d-9459-3180f242e4a3"
   },
   "outputs": [],
   "source": [
    "path_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "7b1d7d62-1434-4a7d-985c-69bf8e265342",
    "_uuid": "436b8232-a69f-409c-82a6-5c1ab5ed7b83",
    "id": "cwv_9pzpkMAX",
    "outputId": "89c4e894-5c67-4f66-89c9-8a2f0b5a2dd1"
   },
   "outputs": [],
   "source": [
    "bin_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "14bbbf56-69be-4779-b290-dedfb5dcdbca",
    "_uuid": "ee72d6ad-6d5f-4d81-8361-1133e463fcc9",
    "id": "IWYgm2tJkMAY",
    "outputId": "018ac848-0cf2-4315-94f8-abada446c164"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "0d0bc451-a2f6-4358-aa73-25a9c0aa9703",
    "_uuid": "f31376ee-f1a5-45ce-b2ca-87446a05738e",
    "id": "Q3LCfenPkMAa",
    "outputId": "38daf706-d593-4d0e-a148-de97287c53dc"
   },
   "outputs": [],
   "source": [
    "path_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "cffa8783-11c6-44c5-8204-e65c24d9e270",
    "_uuid": "80147d85-0d22-4b91-a89c-cdf60802d01b",
    "id": "C8PO5wZgkMAb"
   },
   "outputs": [],
   "source": [
    "test_data = test_data.drop([\"new_col\"], axis=1)\n",
    "# test_data = test_data.drop([\"updated_path\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "3bd5fa81-b3c0-4f2c-8a1c-eae244eec69f",
    "_uuid": "92e6ea4d-eb22-4b85-9392-a547b8ba2ca7",
    "id": "jF6bs9XbkMAd",
    "outputId": "2ba68170-9694-4116-8b2b-ad16dfa97170"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "b8cb35bc-a5f8-493e-9124-385a80c3266f",
    "_uuid": "7ca5b0fe-905e-43a2-b72f-2d861f4d4c02",
    "id": "91UTqYsJkMAf",
    "outputId": "d29b6189-ca53-4cfb-b4a0-aed335af0005"
   },
   "outputs": [],
   "source": [
    "paths_lengths.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "1f17ad14-4174-4c2d-aa99-fcb4b8bfe4cb",
    "_uuid": "60aa8e52-e856-411e-a611-f50258cb8604",
    "id": "hk6RT23WkMAg",
    "outputId": "f8d204f3-db0f-440d-d83e-ccf68a7f695c"
   },
   "outputs": [],
   "source": [
    "test_data.iloc[52,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "edd278ca-a087-44b9-a5bb-28523879c4c8",
    "_uuid": "21fab33d-0480-436b-9a49-361d28c5bde7",
    "id": "65ol55kdkMAi"
   },
   "outputs": [],
   "source": [
    "### Move to bottom trials\n",
    "\n",
    "test_data = pd.concat([test_data, path_df.loc[:,'updated_path']], axis=1)\n",
    "updated_path = []\n",
    "for i, val in test_data.iterrows():\n",
    "    updated_path.append(val['updated_path'].split(sep=\",\"))\n",
    "\n",
    "_ = [x.insert(0, 'S') for x in updated_path]\n",
    "_ = [x.append('E') for x in updated_path]\n",
    "\n",
    "test_data['updated_path'] = updated_path\n",
    "\n",
    "# test_data = test_data.drop([\"updated_path\"], axis=1)\n",
    "\n",
    "paths_lengths = np.array([len(xi) for xi in test_data.iloc[:,-1]])\n",
    "\n",
    "label_char = []\n",
    "for _, i in enumerate(np.unique(test_data['updated_path'])):\n",
    "    for _, j in enumerate(i):\n",
    "        if j not in label_char:\n",
    "            label_char.append(j)\n",
    "\n",
    "label_indices = { j : i for i, j in enumerate(label_char) }\n",
    "indices_label = { i : j for i, j in enumerate(label_char) }\n",
    "\n",
    "input_path_sequence = []\n",
    "next_chars = []\n",
    "features = []\n",
    "paths_maxlen = np.max(paths_lengths)\n",
    "# path_vocab_size = len(bin_labels) # How is this working? Validate!\n",
    "path_vocab_size = len(indices_label) # Temporary test for local trees\n",
    "feature_size = 4\n",
    "for i in range(0, len(test_data)):\n",
    "    # get the feature\n",
    "    curr_feat = np.array([test_data.iloc[i, 0:4]])\n",
    "    curr_path = test_data.iloc[i, -1]\n",
    "    curr_path_len = len(curr_path)\n",
    "    # curr_label = y[i]\n",
    "    # curr_dec_feat = df.iloc[i, 6]\n",
    "    for j in range(1, curr_path_len):\n",
    "        features.append(curr_feat)\n",
    "        input_path_sequence.append(curr_path[0:j])\n",
    "        next_chars.append(curr_path[j])\n",
    "\n",
    "## Vectorize inputs        \n",
    "\n",
    "x_path = np.zeros(\n",
    "    (len(input_path_sequence), paths_maxlen, path_vocab_size), dtype=np.bool)\n",
    "\n",
    "path_latent_input = np.zeros(\n",
    "    (len(input_path_sequence), feature_size), dtype=np.float)\n",
    "\n",
    "y_path = np.zeros(\n",
    "    (len(input_path_sequence), path_vocab_size), dtype=np.bool)\n",
    "\n",
    "# print(input_path_sequence)\n",
    "# print(len(input_path_sequence))\n",
    "for i, sentence in enumerate(input_path_sequence):\n",
    "    for t, char in enumerate(sentence):\n",
    "        # x_path[i, t, self.char_indices[char]] = 1\n",
    "        # print(bin_labels.index[bin_labels['label'] == char[1]])\n",
    "        # index = bin_labels.index[bin_labels['label'] == char[1]].tolist()[0]\n",
    "        x_path[i, t, label_indices[char]] = 1\n",
    "    # y_path[i, char_indices[next_chars[i]]] = 1\n",
    "    # index = bin_labels.index[bin_labels['label'] == next_chars[i][1]].tolist()[0]\n",
    "    # y_path[i, index] = 1\n",
    "    y_path[i, label_indices[next_chars[i]]] = 1\n",
    "    path_latent_input[i, :] = features[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "08369baf-e586-47e6-a997-bfc9df88dc86",
    "_uuid": "a31b6704-e036-4284-a9a7-9b8c83cc72af",
    "id": "NVoabUEWkMAk",
    "outputId": "b9b97cc5-3b47-4942-aa31-3301adbf3107"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bb5589ae-bcc7-4bbc-847f-8aefe10818e2",
    "_uuid": "553af908-f817-402e-ac0e-b7e2c486824d",
    "id": "yEi33U3TkMB9"
   },
   "source": [
    "## RNN architecture changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d81fbf45-65d3-4e98-a26b-d3931ef971bc",
    "_uuid": "9ade61e2-81cc-4c2a-8b51-ea6ab85d707a",
    "id": "Mp0jqBAEkMB9",
    "outputId": "72de28d1-08ac-4651-f8cd-fa9cbcab8ffd"
   },
   "outputs": [],
   "source": [
    "path_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5aa8d3d6-b77c-4bc4-bb2a-9a3b386d6f8a",
    "_uuid": "c3860c2f-1e30-46ab-82f6-e86dad59b213",
    "id": "NT8aMpL_kMB_"
   },
   "outputs": [],
   "source": [
    "label_freq = {}\n",
    "count = 0\n",
    "for i in (path_df.loc[:,'paths']):\n",
    "    for j in i.split(','):\n",
    "        try:\n",
    "            label_freq.update({j:label_freq[j]+1})\n",
    "        except KeyError:\n",
    "            label_freq.update({j:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ea2f719a-bcde-4c51-8249-77a059cdd23b",
    "_uuid": "893b3abf-3427-418f-ae25-21d2479d0ad8",
    "id": "DVH5R_nHkMCA",
    "outputId": "450b5fe1-334c-426c-fd2a-44806a286c75"
   },
   "outputs": [],
   "source": [
    "len(label_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "d7ccffaa-e4fe-4abf-b7ae-882fb3e707d4",
    "_uuid": "47d06ae4-bbee-48f0-8475-ee45416fce29",
    "id": "Un6br1izkMCB",
    "outputId": "e785e7f4-2185-41d9-f362-fb23af66d587"
   },
   "outputs": [],
   "source": [
    "path_df.loc[:, 'updated_path'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "1ed12cfc-ed18-4b2b-bbff-74578224ba60",
    "_uuid": "5392b7f2-0668-43c5-acfe-6e4f0f1b8950",
    "id": "HtNIRbUYkMCD"
   },
   "outputs": [],
   "source": [
    "label_freq = {}\n",
    "count = 0\n",
    "for i in (path_df.loc[:,'paths']):\n",
    "    for j in i.split(','):\n",
    "        try:\n",
    "            label_freq.update({j[1:-1]:label_freq[j[1:-1]]+1})\n",
    "        except KeyError:\n",
    "            label_freq.update({j[1:-1]:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "f85633fc-3121-45fc-ae4a-b6f0413ee2f6",
    "_uuid": "d07e47ba-7738-4153-9e36-60729988c54d",
    "id": "W6JOLohokMCE",
    "outputId": "c4fc2b87-2500-4fe8-84f0-00414d6be922"
   },
   "outputs": [],
   "source": [
    "len(label_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "b068056c-bbc5-494f-ad80-2783827c81b4",
    "_uuid": "94c50e42-c658-4ac7-a579-0c396a390e34",
    "id": "S42vsfqtkMCF"
   },
   "outputs": [],
   "source": [
    "label_freq = {}\n",
    "count = 0\n",
    "for i in (path_df.loc[:,'paths']):\n",
    "    for j in i.split(','):\n",
    "        try:\n",
    "            label_freq.update({j[1:-1]:label_freq[j[1:-1]]+1})\n",
    "        except KeyError:\n",
    "            label_freq.update({j[1:-1]:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "d0a07017-2c83-40b2-9d10-126c29811d18",
    "_uuid": "0aa6f9a4-0fbd-4b83-8a28-620ee32c9407",
    "id": "wrNheXNakMCH",
    "outputId": "188fd008-6395-45a8-e9c4-b663987edb93"
   },
   "outputs": [],
   "source": [
    "label_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "1d4e2bbd-b8b5-4e30-9cf6-c91f42e43279",
    "_uuid": "642a5f54-bb23-42a9-a711-9e988ee485f3",
    "id": "a5U-uwuVkMCJ",
    "outputId": "c7c1b0ac-07fb-4121-bad8-89834782dcc8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(label_freq.keys(), label_freq.values(), 2, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "5ce6873c-aff7-42d1-bf49-c55de8540e1a",
    "_uuid": "9c503a20-0c8d-44fc-9f34-a57d826c58fe",
    "id": "WeaUJXHlkMCK",
    "outputId": "523fbfad-cbbd-4ea5-a830-c4ed17fa9253"
   },
   "outputs": [],
   "source": [
    "bin_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "424b80fd-4b6b-4789-87c8-0c169e121fab",
    "_uuid": "ed7c0d71-4523-4677-a06f-fefbd5337a19",
    "id": "Cl-BgSNLkMCM"
   },
   "outputs": [],
   "source": [
    "dir_indices = {\n",
    "    'S': 0,\n",
    "    'E': 1,\n",
    "    '0': 2,\n",
    "    '1': 3\n",
    "}\n",
    "bin_indices = {0:0, 1:1}\n",
    "bin_indices.update({val: index+2 for index, val in enumerate(np.unique(bin_labels['label']))})\n",
    "\n",
    "feature_indices = {'S':0, 'E': 15}\n",
    "feature_indices.update({str(val): val for val in range(1,15)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "feb3143f-0d09-4ba4-8de2-45149a3666b3",
    "_uuid": "0703f9ce-a089-48a0-980d-c6f9cb627cdc",
    "id": "zrcMU1ylkMCN",
    "outputId": "461b45b6-7cb1-42c1-c082-e87b30d50ae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': 0,\n",
       " 'E': 15,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9,\n",
       " '10': 10,\n",
       " '11': 11,\n",
       " '12': 12,\n",
       " '13': 13,\n",
       " '14': 14}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "443561dc-0998-4098-996a-dcdadc70c64f",
    "_uuid": "90d736ab-234c-4fe5-bb87-a0ccd5c12f99",
    "id": "IG4Zdfd9FwuF",
    "outputId": "2876ec1f-9303-4653-e514-0407cbc01894"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "aa3845dc-08cf-4d45-b077-b988c4963773",
    "_uuid": "916c6eaa-77d3-45c0-aa70-5e5f2bc23df8",
    "id": "YOUb1zKekMCO",
    "outputId": "cf561970-a1b5-42a7-c7ca-5a844277e763"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11937"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bin_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "f3c19877-bffc-4b54-9974-9fa6c0d8ba86",
    "_uuid": "54d3787d-333c-4c71-9a8d-70e4aadb3b08",
    "id": "u0lolYAhkMCQ",
    "outputId": "2f512748-6dbc-4048-893f-0cc3e8b30228"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'AB', 'ABC', ..., 'Y', 'YZ', 'Z'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(bin_labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "c21e9295-4d9f-4e98-9892-12010385c5e2",
    "_uuid": "93122be6-c915-4b10-b1e5-9f3a4410c7ee",
    "id": "ZspM6ZWgkMCS"
   },
   "outputs": [],
   "source": [
    "shuffle_data = test_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "dc83424f-db1e-454d-9324-369365c8698b",
    "_uuid": "b73d60b5-b31a-4b11-a8fa-c0f1495798c5",
    "id": "gpDQWLmiVkdW",
    "outputId": "a5bc169a-97bb-4f7e-c857-649f8b4b804d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S', '8A0', '11B0', '14C0', '13D0', '7A0', '12E0', '3F1', '9G0', '2H0', 'E']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.iloc[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 106)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "72967ca4-06bc-4b5c-b583-d4d67e1ffb47",
    "_uuid": "31c40df1-ea4c-4001-a17a-5daec09581ca",
    "id": "HHzWgXhCkMCT"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-db59d4d30f9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# for i in range(0, len(shuffle_data[:140])):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# get the feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mcurr_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m104\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mcurr_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mcurr_path_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_vocab_size = len(feature_indices)\n",
    "bin_vocab_size = len(bin_indices)\n",
    "dir_vocab_size = len(dir_indices)\n",
    "latent_dim = 25\n",
    "\n",
    "input_path_sequence = []\n",
    "next_chars = []\n",
    "features = []\n",
    "paths_maxlen = np.max(paths_lengths)\n",
    "# path_vocab_size = len(bin_labels) # How is this working? Validate!\n",
    "# path_vocab_size = len(indices_label) # Temporary test for local trees\n",
    "feature_size = 104\n",
    "for i in range(0, len(test_data)):\n",
    "# for i in range(0, len(shuffle_data[:140])):\n",
    "    # get the feature\n",
    "    curr_feat = np.array([test_data.iloc[i, 0:104]])\n",
    "    curr_path = test_data.iloc[i, -1]\n",
    "    curr_path_len = len(curr_path)\n",
    "    for j in range(1, curr_path_len):\n",
    "        features.append(curr_feat)\n",
    "        input_path_sequence.append(curr_path[0:j])\n",
    "        next_chars.append(curr_path[j])\n",
    "\n",
    "# x_path = np.zeros((len(input_path_sequence), paths_maxlen, path_vocab_size), dtype=np.bool)\n",
    "\n",
    "x_feat = np.zeros((len(input_path_sequence), paths_maxlen, feature_vocab_size), dtype=np.bool)\n",
    "\n",
    "x_bin = np.zeros((len(input_path_sequence), paths_maxlen, bin_vocab_size), dtype=np.bool)\n",
    "\n",
    "x_dir = np.zeros((len(input_path_sequence), paths_maxlen, dir_vocab_size), dtype=np.bool)\n",
    "\n",
    "\n",
    "\n",
    "path_latent_input = np.zeros((len(input_path_sequence), feature_size), dtype=np.float)\n",
    "\n",
    "# y_path = np.zeros((len(input_path_sequence), path_vocab_size), dtype=np.bool)\n",
    "\n",
    "y_feat = np.zeros((len(input_path_sequence), feature_vocab_size), dtype=np.bool)\n",
    "\n",
    "y_bin = np.zeros((len(input_path_sequence), bin_vocab_size), dtype=np.bool)\n",
    "\n",
    "y_dir = np.zeros((len(input_path_sequence), dir_vocab_size), dtype=np.bool)\n",
    "\n",
    "# for i, sentence in enumerate(input_path_sequence):\n",
    "#     for t, char in enumerate(sentence):\n",
    "#         if char == 'S':\n",
    "#             x_feat[i, t, feature_indices[char]] = 1\n",
    "#             x_bin[i, t, 0] = 1\n",
    "#             x_dir[i, t, 0] = 1\n",
    "#         else:\n",
    "#             temp = re.compile(\"(\\d+)(\\w+)(\\d+)\") \n",
    "#             res = temp.match(char).groups()\n",
    "#             x_feat[i, t, feature_indices[res[0]]] = 1\n",
    "#             x_bin[i, t, bin_indices[res[1]]] = 1\n",
    "#             x_dir[i, t, dir_indices[res[2]]] = 1\n",
    "#     if next_chars[i] == 'E':\n",
    "#         y_feat[i, feature_indices[next_chars[i]]] = 1\n",
    "#         y_bin[i, 1] = 1 ## Cross check\n",
    "#         y_dir[i, 1] = 1 ## Cross check\n",
    "#     else:\n",
    "#         temp = re.compile(\"(\\d+)(\\w+)(\\d+)\") \n",
    "#         res = temp.match(next_chars[i]).groups()\n",
    "#         y_feat[i, feature_indices[res[0]]] = 1\n",
    "#         y_bin[i, bin_indices[res[1]]] = 1\n",
    "#         y_dir[i, dir_indices[res[2]]] = 1\n",
    "#     # y_path[i, label_indices[next_chars[i]]] = 1\n",
    "#     path_latent_input[i, :] = features[i]\n",
    "    \n",
    "## Trouble with \"S\" and \"E\" index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17239"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_path_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "73e14f7d-1d84-408c-83a0-ea9dc0bd928c",
    "_uuid": "98e74d7c-863f-48c7-acfd-e95af038eeb1",
    "id": "ppFOtRVQkMCV",
    "outputId": "951345fc-da2e-49dc-d7c8-a3e2477656a7"
   },
   "outputs": [],
   "source": [
    "y_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a807132e-eaac-40f7-a135-97e76b19a699",
    "_uuid": "6f8cf49b-e4aa-43ad-b033-34029a284b0f",
    "id": "wsEPVzbbGSwK",
    "outputId": "412bb05e-db0a-4572-ba74-a7cefed4b92c"
   },
   "outputs": [],
   "source": [
    "x_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "39c55d8b-1165-42ee-b619-3f24e47f6d40",
    "_uuid": "479e2e2c-3dbb-44f3-990b-05d5f88e1dc5",
    "id": "Caqb-tgukMCV",
    "outputId": "4eb20235-564a-4228-cb06-81bc76e8e398"
   },
   "outputs": [],
   "source": [
    "x_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2e285f45-3949-4c97-982d-8cda3c915bb5",
    "_uuid": "40eef761-2165-484b-8ffc-d2b18363b371",
    "id": "JzFWjkYXkMCX",
    "outputId": "43de4a05-16d9-4f79-bc4e-e8e3f0017804"
   },
   "outputs": [],
   "source": [
    "path_latent_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bd6b0daa-a336-4d15-90da-ef105a0563d7",
    "_uuid": "61a95df0-5dea-4f9b-a493-070dc9c75fba",
    "id": "3hQr_6iDkMCY",
    "outputId": "04d5a0f5-1779-4d61-cf71-a08858f9d6fa"
   },
   "outputs": [],
   "source": [
    "path_latent_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "432cf9a7-e6e0-4f54-8d3f-aafbda355ee1",
    "_uuid": "44568102-06d3-455c-bd83-eb9f5093e4a4",
    "id": "ywqiHm05pT0z",
    "outputId": "89fda0d0-6ca0-41a6-e5fb-13e2d5d1f85d"
   },
   "outputs": [],
   "source": [
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "6a1d1716-10bf-425f-aba1-6133b00a322d",
    "_uuid": "f086e6b9-8327-4944-9439-7706cdac39c9",
    "id": "Lxbi1rnRkMCb",
    "outputId": "38ab6f57-3777-424f-e952-c8f26422428c"
   },
   "outputs": [],
   "source": [
    "## Approach 2 -- linking 3 subsequent rnns\n",
    "from tensorflow.keras.layers import Reshape, Flatten\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=\"dert\")\n",
    "\n",
    "\n",
    "label_model_latent = Input(shape=(latent_dim,), name='x_ip')\n",
    "\n",
    "feature_input = Input(shape=(paths_maxlen, feature_vocab_size), name='feat_ip')\n",
    "\n",
    "bin_input = Input(shape=(paths_maxlen, bin_vocab_size), name='bin_ip')\n",
    "\n",
    "direction_input = Input(shape=(paths_maxlen, dir_vocab_size), name='dir_ip')\n",
    "\n",
    "# masked_bin_input = Masking(mask_value=x_bin[0])(bin_input)\n",
    "\n",
    "# masked_direction_input = Masking(mask_value=x_dir[0])(direction_input)\n",
    "\n",
    "# if rnn_cell == 'gru':\n",
    "#     RNN = GRU\n",
    "# else:\n",
    "RNN = GRU\n",
    "\n",
    "decoder_1 = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_1',\n",
    "                reset_after=True, recurrent_activation='sigmoid', activation= 'tanh',\n",
    "                recurrent_dropout = 0, unroll = False, use_bias = True, )\n",
    "\n",
    "decoder_1_outputs = decoder_1(feature_input, initial_state=label_model_latent)\n",
    "\n",
    "decoder_1b_outputs = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_1b', reset_after=True, recurrent_activation='sigmoid')(decoder_1_outputs)\n",
    "\n",
    "decoder_1c_outputs = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_1c', reset_after=True, recurrent_activation='sigmoid')(decoder_1b_outputs)\n",
    "\n",
    "decoder_1d_outputs = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_1d', reset_after=True, recurrent_activation='sigmoid')(decoder_1c_outputs)\n",
    "\n",
    "decoder_1e_outputs = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_1e', reset_after=True, recurrent_activation='sigmoid')(decoder_1d_outputs)\n",
    "\n",
    "\n",
    "decoder_1f_outputs = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_1f', reset_after=True, recurrent_activation='sigmoid')(decoder_1e_outputs)\n",
    "\n",
    "decoder_1g_outputs = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_1g', reset_after=True, recurrent_activation='sigmoid')(decoder_1f_outputs)\n",
    "\n",
    "decoder_1h_outputs = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_1h', reset_after=True, recurrent_activation='sigmoid')(decoder_1g_outputs)\n",
    "\n",
    "decoder_1i_outputs = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_1i', reset_after=True, recurrent_activation='sigmoid')(decoder_1h_outputs)\n",
    "\n",
    "decoder_2 = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_2', reset_after=True, recurrent_activation='sigmoid')\n",
    "\n",
    "concat_gru_1_2 = concatenate([bin_input, decoder_1i_outputs], name='gru_1_2')\n",
    "\n",
    "decoder_2_outputs = decoder_2(concat_gru_1_2, initial_state=label_model_latent)\n",
    "\n",
    "decoder_2b_outputs = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_2b', reset_after=True, recurrent_activation='sigmoid')(decoder_2_outputs)\n",
    "\n",
    "decoder_2c_outputs = RNN(latent_dim, return_state=False, return_sequences=True, name='gru_2c', reset_after=True, recurrent_activation='sigmoid')(decoder_2b_outputs)\n",
    "\n",
    "decoder_3 = RNN(latent_dim, return_state=False, return_sequences=False, name='gru_3', reset_after=True, recurrent_activation='sigmoid')\n",
    "\n",
    "concat_gru_1_2_3 = concatenate([direction_input, decoder_1_outputs, decoder_2_outputs], name='gru_1_2_3')\n",
    "\n",
    "decoder_3_outputs = decoder_3(concat_gru_1_2_3, initial_state=label_model_latent)\n",
    "\n",
    "flatten_gru_1 = Flatten()(decoder_1i_outputs)\n",
    "merge_layer_1 = concatenate([label_model_latent, flatten_gru_1], name='merge_1')\n",
    "\n",
    "flatten_gru_2 = Flatten()(decoder_2c_outputs)\n",
    "merge_layer_2 = concatenate([label_model_latent, flatten_gru_2], name='merge_2')\n",
    "\n",
    "merge_layer_3 = concatenate([label_model_latent, decoder_3_outputs], name='merge_3')\n",
    "\n",
    "output_feature = Dense(feature_vocab_size, activation='softmax', name='op_feat')(merge_layer_1)\n",
    "\n",
    "output_bin = Dense(bin_vocab_size, activation='softmax', name='op_bin')(merge_layer_2)\n",
    "\n",
    "# test_layer = Flatten()(decoder_3)\n",
    "\n",
    "output_dir = Dense(dir_vocab_size, activation='softmax', name='op_dir')(merge_layer_3)\n",
    "\n",
    "model = Model([label_model_latent, feature_input, bin_input, direction_input], [output_feature, output_bin, output_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "d1757cd1-f96c-414a-91f3-359484c815f8",
    "_uuid": "373ee761-b938-4a25-81a8-994daa7b96a6",
    "id": "Kp4_pah-L7Za",
    "outputId": "12688fa8-da00-4933-81f0-a3a552261b7e"
   },
   "outputs": [],
   "source": [
    "## Approach 3 -- single rnn, multi output model\n",
    "from tensorflow.keras.layers import Reshape, Flatten\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=\"dert\")\n",
    "\n",
    "\n",
    "label_model_latent = Input(shape=(latent_dim,), name='x_ip')\n",
    "\n",
    "feature_input = Input(shape=(paths_maxlen, feature_vocab_size), name='feat_ip')\n",
    "\n",
    "bin_input = Input(shape=(paths_maxlen, bin_vocab_size), name='bin_ip')\n",
    "\n",
    "direction_input = Input(shape=(paths_maxlen, dir_vocab_size), name='dir_ip')\n",
    "\n",
    "RNN = GRU\n",
    "\n",
    "merge_input = concatenate([feature_input, bin_input, direction_input], name='merge_ip')\n",
    "\n",
    "decoder_1 = RNN(latent_dim, return_state=False, name='gru_1',\n",
    "                reset_after=True, recurrent_activation='sigmoid', activation= 'tanh',\n",
    "                recurrent_dropout = 0, unroll = False, use_bias = True, )\n",
    "\n",
    "decoder_1_outputs = decoder_1(merge_input, initial_state=label_model_latent)\n",
    "\n",
    "output_feature = Dense(feature_vocab_size, activation='softmax', name='op_feat')(decoder_1_outputs)\n",
    "\n",
    "output_bin = Dense(bin_vocab_size, activation='softmax', name='op_bin')(decoder_1_outputs)\n",
    "\n",
    "output_dir = Dense(dir_vocab_size, activation='softmax', name='op_dir')(decoder_1_outputs)\n",
    "\n",
    "model = Model([label_model_latent, feature_input, bin_input, direction_input], [output_feature, output_bin, output_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "655a7ec4-b6e8-4336-a7df-d45e19f9966f",
    "_uuid": "f9aa2df1-1bd6-454b-89ab-8fb422114092",
    "id": "nu7bXG4ZOq_W",
    "outputId": "328463d1-b51c-4988-ba87-367d8f80259a"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "91c7905a-9950-4c2a-b707-db61ae1fc4aa",
    "_uuid": "4171da56-f53b-476d-8f54-99525429cd96",
    "id": "KcXswdjtPIo2",
    "outputId": "2b2001a5-b35e-479d-f150-0c9c99d96b3f"
   },
   "outputs": [],
   "source": [
    "## Single RNN, multi-op approach\n",
    "x_latent = get_hidden_x(path_latent_input, model=label_model)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit([x_latent, x_feat, x_bin, x_dir], [y_feat, y_bin, y_dir],batch_size=6000, epochs=20000, verbose=1,\n",
    "          callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "11f0d199-bacd-45ee-b461-7fe0de950c97",
    "_uuid": "2248adf1-2bdc-4d5f-933c-ec52c8d416fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Not authenticated.  Copy a key from https://app.wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\shakk/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/shakkeel_mlsquare/dert\" target=\"_blank\">https://app.wandb.ai/shakkeel_mlsquare/dert</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/shakkeel_mlsquare/dert/runs/3i9x8q0g\" target=\"_blank\">https://app.wandb.ai/shakkeel_mlsquare/dert/runs/3i9x8q0g</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to connect to W&B servers after 10 seconds.                    Letting user process proceed while attempting to reconnect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/shakkeel_mlsquare/dert/runs/3i9x8q0g"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error generating diff: Command '['git', 'diff', '--submodule=diff', 'HEAD']' timed out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=\"dert\", name=\"bilstm_local_gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "d41692bb-8ce9-43fc-90a7-279c6e829acb",
    "_uuid": "1e402cc4-1166-4108-b750-d3567a26f848",
    "id": "3sPpovIQ0OwA",
    "outputId": "ff49b28b-adc3-40a6-cbda-086b61d23500"
   },
   "outputs": [],
   "source": [
    "## Approach 4 -- single rnn, multi output model, multi dense\n",
    "from tensorflow.keras.layers import Reshape, Flatten\n",
    "\n",
    "label_model_latent = Input(shape=(latent_dim,), name='x_ip')\n",
    "\n",
    "feature_input = Input(shape=(paths_maxlen, feature_vocab_size), name='feat_ip')\n",
    "\n",
    "bin_input = Input(shape=(paths_maxlen, bin_vocab_size), name='bin_ip')\n",
    "\n",
    "direction_input = Input(shape=(paths_maxlen, dir_vocab_size), name='dir_ip')\n",
    "\n",
    "RNN = LSTM\n",
    "\n",
    "merge_input = concatenate([feature_input, bin_input, direction_input], name='merge_ip')\n",
    "\n",
    "decoder_1 = RNN(latent_dim, return_state=False, name='gru_1')\n",
    "\n",
    "decoder_1_outputs = decoder_1(merge_input, initial_state=[label_model_latent, label_model_latent])\n",
    "\n",
    "# decoder_2 = RNN(latent_dim, return_state=False, name='gru_2')\n",
    "\n",
    "# decoder_2_outputs = decoder_2(decoder_1_outputs, initial_state=label_model_latent)\n",
    "\n",
    "# hidden_1 = Dense(100, activation='softmax', name='h_1')(decoder_1_outputs)\n",
    "\n",
    "# hidden_2 = Dense(100, activation='softmax', name='h_2')(hidden_1)\n",
    "\n",
    "feat_hidden_1 = Dense(100, activation='softmax', name='f_1')(decoder_1_outputs)\n",
    "output_feature = Dense(feature_vocab_size, activation='softmax', name='op_feat')(feat_hidden_1)\n",
    "\n",
    "bin_hidden_1 = Dense(100, activation='softmax', name='b_1')(decoder_1_outputs)\n",
    "bin_hidden_2 = Dense(100, activation='softmax', name='b_2')(bin_hidden_1)\n",
    "output_bin = Dense(bin_vocab_size, activation='softmax', name='op_bin')(bin_hidden_2)\n",
    "\n",
    "output_dir = Dense(dir_vocab_size, activation='softmax', name='op_dir')(decoder_1_outputs)\n",
    "\n",
    "model = Model([label_model_latent, feature_input, bin_input, direction_input], [output_feature, output_bin, output_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "7af36ac6-ad28-44a2-aab4-1465432d2c18",
    "_uuid": "5dbbde7b-409c-4d83-bb91-54563ed42a3e"
   },
   "outputs": [],
   "source": [
    "## Approach 5 -- two bilstm rnn, multi output model, multi dense\n",
    "from tensorflow.keras.layers import Reshape, Flatten, Bidirectional\n",
    "\n",
    "label_model_latent = Input(shape=(latent_dim,), name='x_ip')\n",
    "\n",
    "feature_input = Input(shape=(paths_maxlen, feature_vocab_size), name='feat_ip')\n",
    "\n",
    "bin_input = Input(shape=(paths_maxlen, bin_vocab_size), name='bin_ip')\n",
    "\n",
    "direction_input = Input(shape=(paths_maxlen, dir_vocab_size), name='dir_ip')\n",
    "\n",
    "RNN = LSTM\n",
    "\n",
    "merge_input = concatenate([feature_input, bin_input, direction_input], name='merge_ip')\n",
    "\n",
    "decoder_1 = Bidirectional(RNN(latent_dim, return_state=False, return_sequences=True, name='lstm_1'))\n",
    "\n",
    "decoder_1_outputs = decoder_1(merge_input, initial_state=[label_model_latent, label_model_latent, label_model_latent, label_model_latent])\n",
    "\n",
    "decoder_2 = Bidirectional(RNN(latent_dim, return_state=False, name='lstm_2'))\n",
    "\n",
    "decoder_2_outputs = decoder_2(decoder_1_outputs, initial_state=[label_model_latent, label_model_latent, label_model_latent, label_model_latent])\n",
    "\n",
    "# hidden_1 = Dense(100, activation='softmax', name='h_1')(decoder_1_outputs)\n",
    "\n",
    "# hidden_2 = Dense(100, activation='softmax', name='h_2')(hidden_1)\n",
    "\n",
    "feat_hidden_1 = Dense(100, activation='softmax', name='f_1')(decoder_2_outputs)\n",
    "output_feature = Dense(feature_vocab_size, activation='softmax', name='op_feat')(feat_hidden_1)\n",
    "\n",
    "bin_hidden_1 = Dense(100, activation='softmax', name='b_1')(decoder_2_outputs)\n",
    "bin_hidden_2 = Dense(100, activation='softmax', name='b_2')(bin_hidden_1)\n",
    "output_bin = Dense(bin_vocab_size, activation='softmax', name='op_bin')(bin_hidden_2)\n",
    "\n",
    "output_dir = Dense(dir_vocab_size, activation='softmax', name='op_dir')(decoder_2_outputs)\n",
    "\n",
    "model = Model([label_model_latent, feature_input, bin_input, direction_input], [output_feature, output_bin, output_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "0c9fad78-83fb-439e-88f5-73e0b19a90f1",
    "_uuid": "937e50ee-b6ad-4c27-b2ae-66b0e0b69436",
    "id": "r6eud2Nn3_9d",
    "outputId": "42c27e41-35a8-4ead-b33c-4488fc45fe9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "feat_ip (InputLayer)            (None, 17, 16)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bin_ip (InputLayer)             (None, 17, 882)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dir_ip (InputLayer)             (None, 17, 4)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_ip (Concatenate)          (None, 17, 902)      0           feat_ip[0][0]                    \n",
      "                                                                 bin_ip[0][0]                     \n",
      "                                                                 dir_ip[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "x_ip (InputLayer)               (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 17, 50)       185600      merge_ip[0][0]                   \n",
      "                                                                 x_ip[0][0]                       \n",
      "                                                                 x_ip[0][0]                       \n",
      "                                                                 x_ip[0][0]                       \n",
      "                                                                 x_ip[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50)           15200       bidirectional[0][0]              \n",
      "                                                                 x_ip[0][0]                       \n",
      "                                                                 x_ip[0][0]                       \n",
      "                                                                 x_ip[0][0]                       \n",
      "                                                                 x_ip[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "b_1 (Dense)                     (None, 100)          5100        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "f_1 (Dense)                     (None, 100)          5100        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "b_2 (Dense)                     (None, 100)          10100       b_1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "op_feat (Dense)                 (None, 16)           1616        f_1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "op_bin (Dense)                  (None, 882)          89082       b_2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "op_dir (Dense)                  (None, 4)            204         bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 312,002\n",
      "Trainable params: 312,002\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_cell_guid": "c837436d-f0bd-43a6-9b1b-519e6d2d5cc8",
    "_uuid": "1deb35e6-536c-4f19-8b86-7375db8f9d15",
    "id": "SlkamAnK4jxW",
    "outputId": "a08688f7-dca4-4670-acb9-0fc7df98743b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7000\n",
      "7111/7111 [==============================] - 14s 2ms/step - loss: 7.3133 - op_feat_loss: 2.7390 - op_bin_loss: 6.7228 - op_dir_loss: 0.8553 - op_feat_acc: 0.1357 - op_bin_acc: 0.0932 - op_dir_acc: 0.7147\n",
      "Epoch 2/7000\n",
      "7111/7111 [==============================] - 7s 964us/step - loss: 7.1628 - op_feat_loss: 2.6643 - op_bin_loss: 6.6011 - op_dir_loss: 0.5771 - op_feat_acc: 0.1450 - op_bin_acc: 0.1406 - op_dir_acc: 0.7711\n",
      "Epoch 3/7000\n",
      "7111/7111 [==============================] - 7s 987us/step - loss: 7.0255 - op_feat_loss: 2.5918 - op_bin_loss: 6.4829 - op_dir_loss: 0.4846 - op_feat_acc: 0.1482 - op_bin_acc: 0.1406 - op_dir_acc: 0.8048\n",
      "Epoch 4/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 6.8904 - op_feat_loss: 2.5137 - op_bin_loss: 6.3645 - op_dir_loss: 0.4647 - op_feat_acc: 0.2261 - op_bin_acc: 0.1406 - op_dir_acc: 0.8168\n",
      "Epoch 5/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 6.7584 - op_feat_loss: 2.4568 - op_bin_loss: 6.2444 - op_dir_loss: 0.4525 - op_feat_acc: 0.2569 - op_bin_acc: 0.1406 - op_dir_acc: 0.8168\n",
      "Epoch 6/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 6.6293 - op_feat_loss: 2.4179 - op_bin_loss: 6.1237 - op_dir_loss: 0.4395 - op_feat_acc: 0.2592 - op_bin_acc: 0.1406 - op_dir_acc: 0.8290\n",
      "Epoch 7/7000\n",
      "7111/7111 [==============================] - 7s 958us/step - loss: 6.5023 - op_feat_loss: 2.3884 - op_bin_loss: 6.0033 - op_dir_loss: 0.4261 - op_feat_acc: 0.2637 - op_bin_acc: 0.1406 - op_dir_acc: 0.8335\n",
      "Epoch 8/7000\n",
      "7111/7111 [==============================] - 7s 999us/step - loss: 6.3791 - op_feat_loss: 2.3642 - op_bin_loss: 5.8853 - op_dir_loss: 0.4201 - op_feat_acc: 0.2597 - op_bin_acc: 0.1406 - op_dir_acc: 0.8370\n",
      "Epoch 9/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 6.2602 - op_feat_loss: 2.3432 - op_bin_loss: 5.7707 - op_dir_loss: 0.4172 - op_feat_acc: 0.2633 - op_bin_acc: 0.1406 - op_dir_acc: 0.8381\n",
      "Epoch 10/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 6.1457 - op_feat_loss: 2.3249 - op_bin_loss: 5.6606 - op_dir_loss: 0.4040 - op_feat_acc: 0.2621 - op_bin_acc: 0.1406 - op_dir_acc: 0.8453\n",
      "Epoch 11/7000\n",
      "7111/7111 [==============================] - 7s 942us/step - loss: 6.0369 - op_feat_loss: 2.3089 - op_bin_loss: 5.5548 - op_dir_loss: 0.4061 - op_feat_acc: 0.2621 - op_bin_acc: 0.1406 - op_dir_acc: 0.8419\n",
      "Epoch 12/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 5.9346 - op_feat_loss: 2.2962 - op_bin_loss: 5.4549 - op_dir_loss: 0.4081 - op_feat_acc: 0.2628 - op_bin_acc: 0.1406 - op_dir_acc: 0.8455\n",
      "Epoch 13/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 5.8362 - op_feat_loss: 2.2805 - op_bin_loss: 5.3609 - op_dir_loss: 0.3820 - op_feat_acc: 0.2663 - op_bin_acc: 0.1406 - op_dir_acc: 0.8571\n",
      "Epoch 14/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 5.7461 - op_feat_loss: 2.2678 - op_bin_loss: 5.2736 - op_dir_loss: 0.3798 - op_feat_acc: 0.2738 - op_bin_acc: 0.1406 - op_dir_acc: 0.8592\n",
      "Epoch 15/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 5.6619 - op_feat_loss: 2.2543 - op_bin_loss: 5.1925 - op_dir_loss: 0.3696 - op_feat_acc: 0.2768 - op_bin_acc: 0.1406 - op_dir_acc: 0.8644\n",
      "Epoch 16/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 5.5849 - op_feat_loss: 2.2443 - op_bin_loss: 5.1175 - op_dir_loss: 0.3701 - op_feat_acc: 0.2814 - op_bin_acc: 0.1406 - op_dir_acc: 0.8615\n",
      "Epoch 17/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 5.5119 - op_feat_loss: 2.2307 - op_bin_loss: 5.0478 - op_dir_loss: 0.3587 - op_feat_acc: 0.2877 - op_bin_acc: 0.1406 - op_dir_acc: 0.8661\n",
      "Epoch 18/7000\n",
      "7111/7111 [==============================] - 9s 1ms/step - loss: 5.4452 - op_feat_loss: 2.2220 - op_bin_loss: 4.9828 - op_dir_loss: 0.3601 - op_feat_acc: 0.2877 - op_bin_acc: 0.1406 - op_dir_acc: 0.8687\n",
      "Epoch 19/7000\n",
      "7111/7111 [==============================] - 9s 1ms/step - loss: 5.3822 - op_feat_loss: 2.2110 - op_bin_loss: 4.9222 - op_dir_loss: 0.3552 - op_feat_acc: 0.2971 - op_bin_acc: 0.1406 - op_dir_acc: 0.8672\n",
      "Epoch 20/7000\n",
      "7111/7111 [==============================] - 9s 1ms/step - loss: 5.3227 - op_feat_loss: 2.1984 - op_bin_loss: 4.8660 - op_dir_loss: 0.3408 - op_feat_acc: 0.3021 - op_bin_acc: 0.1406 - op_dir_acc: 0.8751\n",
      "Epoch 21/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 5.2696 - op_feat_loss: 2.1911 - op_bin_loss: 4.8144 - op_dir_loss: 0.3394 - op_feat_acc: 0.3036 - op_bin_acc: 0.1406 - op_dir_acc: 0.8791\n",
      "Epoch 22/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 5.2202 - op_feat_loss: 2.1787 - op_bin_loss: 4.7677 - op_dir_loss: 0.3359 - op_feat_acc: 0.3068 - op_bin_acc: 0.1406 - op_dir_acc: 0.8791\n",
      "Epoch 23/7000\n",
      "7111/7111 [==============================] - 7s 944us/step - loss: 5.1764 - op_feat_loss: 2.1695 - op_bin_loss: 4.7261 - op_dir_loss: 0.3288 - op_feat_acc: 0.3080 - op_bin_acc: 0.1406 - op_dir_acc: 0.8812\n",
      "Epoch 24/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 5.1383 - op_feat_loss: 2.1613 - op_bin_loss: 4.6898 - op_dir_loss: 0.3260 - op_feat_acc: 0.3064 - op_bin_acc: 0.1406 - op_dir_acc: 0.8817\n",
      "Epoch 25/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 5.1042 - op_feat_loss: 2.1507 - op_bin_loss: 4.6581 - op_dir_loss: 0.3176 - op_feat_acc: 0.3128 - op_bin_acc: 0.1406 - op_dir_acc: 0.8862\n",
      "Epoch 26/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 5.0749 - op_feat_loss: 2.1406 - op_bin_loss: 4.6311 - op_dir_loss: 0.3141 - op_feat_acc: 0.3175 - op_bin_acc: 0.1406 - op_dir_acc: 0.8864\n",
      "Epoch 27/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 5.0502 - op_feat_loss: 2.1344 - op_bin_loss: 4.6080 - op_dir_loss: 0.3080 - op_feat_acc: 0.3202 - op_bin_acc: 0.1406 - op_dir_acc: 0.8912\n",
      "Epoch 28/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 5.0286 - op_feat_loss: 2.1248 - op_bin_loss: 4.5883 - op_dir_loss: 0.3057 - op_feat_acc: 0.3227 - op_bin_acc: 0.1406 - op_dir_acc: 0.8883\n",
      "Epoch 29/7000\n",
      "7111/7111 [==============================] - 7s 955us/step - loss: 5.0114 - op_feat_loss: 2.1204 - op_bin_loss: 4.5717 - op_dir_loss: 0.3123 - op_feat_acc: 0.3167 - op_bin_acc: 0.1406 - op_dir_acc: 0.8847\n",
      "Epoch 30/7000\n",
      "7111/7111 [==============================] - 7s 933us/step - loss: 4.9948 - op_feat_loss: 2.1107 - op_bin_loss: 4.5578 - op_dir_loss: 0.2973 - op_feat_acc: 0.3244 - op_bin_acc: 0.1406 - op_dir_acc: 0.8926\n",
      "Epoch 31/7000\n",
      "7111/7111 [==============================] - 7s 920us/step - loss: 4.9816 - op_feat_loss: 2.1024 - op_bin_loss: 4.5462 - op_dir_loss: 0.2986 - op_feat_acc: 0.3244 - op_bin_acc: 0.1406 - op_dir_acc: 0.8896\n",
      "Epoch 32/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.9709 - op_feat_loss: 2.0970 - op_bin_loss: 4.5365 - op_dir_loss: 0.2996 - op_feat_acc: 0.3226 - op_bin_acc: 0.1406 - op_dir_acc: 0.8910\n",
      "Epoch 33/7000\n",
      "7111/7111 [==============================] - 7s 937us/step - loss: 4.9603 - op_feat_loss: 2.0878 - op_bin_loss: 4.5285 - op_dir_loss: 0.2852 - op_feat_acc: 0.3298 - op_bin_acc: 0.1406 - op_dir_acc: 0.8933\n",
      "Epoch 34/7000\n",
      "7111/7111 [==============================] - 7s 997us/step - loss: 4.9532 - op_feat_loss: 2.0829 - op_bin_loss: 4.5220 - op_dir_loss: 0.2928 - op_feat_acc: 0.3323 - op_bin_acc: 0.1406 - op_dir_acc: 0.8920\n",
      "Epoch 35/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.9455 - op_feat_loss: 2.0740 - op_bin_loss: 4.5167 - op_dir_loss: 0.2816 - op_feat_acc: 0.3334 - op_bin_acc: 0.1406 - op_dir_acc: 0.8957\n",
      "Epoch 36/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.9406 - op_feat_loss: 2.0703 - op_bin_loss: 4.5124 - op_dir_loss: 0.2829 - op_feat_acc: 0.3305 - op_bin_acc: 0.1406 - op_dir_acc: 0.8931\n",
      "Epoch 37/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.9358 - op_feat_loss: 2.0641 - op_bin_loss: 4.5088 - op_dir_loss: 0.2822 - op_feat_acc: 0.3346 - op_bin_acc: 0.1406 - op_dir_acc: 0.8931\n",
      "Epoch 38/7000\n",
      "7111/7111 [==============================] - 7s 985us/step - loss: 4.9304 - op_feat_loss: 2.0541 - op_bin_loss: 4.5060 - op_dir_loss: 0.2733 - op_feat_acc: 0.3351 - op_bin_acc: 0.1406 - op_dir_acc: 0.8966\n",
      "Epoch 39/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.9272 - op_feat_loss: 2.0495 - op_bin_loss: 4.5036 - op_dir_loss: 0.2749 - op_feat_acc: 0.3400 - op_bin_acc: 0.1406 - op_dir_acc: 0.8941\n",
      "Epoch 40/7000\n",
      "7111/7111 [==============================] - 7s 980us/step - loss: 4.9228 - op_feat_loss: 2.0391 - op_bin_loss: 4.5017 - op_dir_loss: 0.2652 - op_feat_acc: 0.3391 - op_bin_acc: 0.1406 - op_dir_acc: 0.8999\n",
      "Epoch 41/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.9199 - op_feat_loss: 2.0337 - op_bin_loss: 4.5001 - op_dir_loss: 0.2620 - op_feat_acc: 0.3406 - op_bin_acc: 0.1406 - op_dir_acc: 0.9007\n",
      "Epoch 42/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.9173 - op_feat_loss: 2.0268 - op_bin_loss: 4.4988 - op_dir_loss: 0.2638 - op_feat_acc: 0.3437 - op_bin_acc: 0.1406 - op_dir_acc: 0.8987\n",
      "Epoch 43/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.9151 - op_feat_loss: 2.0222 - op_bin_loss: 4.4976 - op_dir_loss: 0.2613 - op_feat_acc: 0.3459 - op_bin_acc: 0.1406 - op_dir_acc: 0.9017\n",
      "Epoch 44/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.9127 - op_feat_loss: 2.0161 - op_bin_loss: 4.4966 - op_dir_loss: 0.2573 - op_feat_acc: 0.3465 - op_bin_acc: 0.1406 - op_dir_acc: 0.9035\n",
      "Epoch 45/7000\n",
      "7111/7111 [==============================] - 7s 918us/step - loss: 4.9104 - op_feat_loss: 2.0105 - op_bin_loss: 4.4957 - op_dir_loss: 0.2523 - op_feat_acc: 0.3448 - op_bin_acc: 0.1406 - op_dir_acc: 0.9052\n",
      "Epoch 46/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.9089 - op_feat_loss: 2.0065 - op_bin_loss: 4.4949 - op_dir_loss: 0.2538 - op_feat_acc: 0.3452 - op_bin_acc: 0.1406 - op_dir_acc: 0.9020\n",
      "Epoch 47/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.9066 - op_feat_loss: 1.9996 - op_bin_loss: 4.4942 - op_dir_loss: 0.2487 - op_feat_acc: 0.3476 - op_bin_acc: 0.1406 - op_dir_acc: 0.9059\n",
      "Epoch 48/7000\n",
      "7111/7111 [==============================] - 7s 945us/step - loss: 4.9046 - op_feat_loss: 1.9943 - op_bin_loss: 4.4935 - op_dir_loss: 0.2453 - op_feat_acc: 0.3531 - op_bin_acc: 0.1406 - op_dir_acc: 0.9100\n",
      "Epoch 49/7000\n",
      "7111/7111 [==============================] - 6s 906us/step - loss: 4.9024 - op_feat_loss: 1.9874 - op_bin_loss: 4.4929 - op_dir_loss: 0.2404 - op_feat_acc: 0.3513 - op_bin_acc: 0.1406 - op_dir_acc: 0.9094\n",
      "Epoch 50/7000\n",
      "7111/7111 [==============================] - 7s 920us/step - loss: 4.9007 - op_feat_loss: 1.9817 - op_bin_loss: 4.4924 - op_dir_loss: 0.2378 - op_feat_acc: 0.3549 - op_bin_acc: 0.1406 - op_dir_acc: 0.9103\n",
      "Epoch 51/7000\n",
      "7111/7111 [==============================] - 7s 958us/step - loss: 4.9001 - op_feat_loss: 1.9803 - op_bin_loss: 4.4919 - op_dir_loss: 0.2435 - op_feat_acc: 0.3538 - op_bin_acc: 0.1406 - op_dir_acc: 0.9066\n",
      "Epoch 52/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8979 - op_feat_loss: 1.9726 - op_bin_loss: 4.4915 - op_dir_loss: 0.2357 - op_feat_acc: 0.3486 - op_bin_acc: 0.1406 - op_dir_acc: 0.9113: 5s - loss: 5.0202 - op_feat_loss: 1.9900 - op_bin_\n",
      "Epoch 53/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.8956 - op_feat_loss: 1.9652 - op_bin_loss: 4.4912 - op_dir_loss: 0.2285 - op_feat_acc: 0.3562 - op_bin_acc: 0.1406 - op_dir_acc: 0.9152\n",
      "Epoch 54/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8946 - op_feat_loss: 1.9619 - op_bin_loss: 4.4908 - op_dir_loss: 0.2275 - op_feat_acc: 0.3554 - op_bin_acc: 0.1406 - op_dir_acc: 0.9175\n",
      "Epoch 55/7000\n",
      "7111/7111 [==============================] - 7s 980us/step - loss: 4.8941 - op_feat_loss: 1.9603 - op_bin_loss: 4.4905 - op_dir_loss: 0.2309 - op_feat_acc: 0.3547 - op_bin_acc: 0.1406 - op_dir_acc: 0.9120\n",
      "Epoch 56/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8923 - op_feat_loss: 1.9545 - op_bin_loss: 4.4901 - op_dir_loss: 0.2263 - op_feat_acc: 0.3586 - op_bin_acc: 0.1406 - op_dir_acc: 0.9139\n",
      "Epoch 57/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8900 - op_feat_loss: 1.9462 - op_bin_loss: 4.4898 - op_dir_loss: 0.2192 - op_feat_acc: 0.3608 - op_bin_acc: 0.1406 - op_dir_acc: 0.9180\n",
      "Epoch 58/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8883 - op_feat_loss: 1.9396 - op_bin_loss: 4.4896 - op_dir_loss: 0.2157 - op_feat_acc: 0.3611 - op_bin_acc: 0.1406 - op_dir_acc: 0.9193\n",
      "Epoch 59/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8872 - op_feat_loss: 1.9355 - op_bin_loss: 4.4894 - op_dir_loss: 0.2139 - op_feat_acc: 0.3617 - op_bin_acc: 0.1406 - op_dir_acc: 0.9201\n",
      "Epoch 60/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8860 - op_feat_loss: 1.9311 - op_bin_loss: 4.4892 - op_dir_loss: 0.2118 - op_feat_acc: 0.3639 - op_bin_acc: 0.1406 - op_dir_acc: 0.9231\n",
      "Epoch 61/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.8846 - op_feat_loss: 1.9272 - op_bin_loss: 4.4889 - op_dir_loss: 0.2057 - op_feat_acc: 0.3632 - op_bin_acc: 0.1406 - op_dir_acc: 0.9238\n",
      "Epoch 62/7000\n",
      "7111/7111 [==============================] - 7s 966us/step - loss: 4.8842 - op_feat_loss: 1.9251 - op_bin_loss: 4.4888 - op_dir_loss: 0.2085 - op_feat_acc: 0.3669 - op_bin_acc: 0.1406 - op_dir_acc: 0.9245\n",
      "Epoch 63/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.8824 - op_feat_loss: 1.9179 - op_bin_loss: 4.4886 - op_dir_loss: 0.2049 - op_feat_acc: 0.3653 - op_bin_acc: 0.1406 - op_dir_acc: 0.9252\n",
      "Epoch 64/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.8825 - op_feat_loss: 1.9183 - op_bin_loss: 4.4885 - op_dir_loss: 0.2067 - op_feat_acc: 0.3607 - op_bin_acc: 0.1406 - op_dir_acc: 0.9236\n",
      "Epoch 65/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8811 - op_feat_loss: 1.9128 - op_bin_loss: 4.4883 - op_dir_loss: 0.2039 - op_feat_acc: 0.3628 - op_bin_acc: 0.1406 - op_dir_acc: 0.9246\n",
      "Epoch 66/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8797 - op_feat_loss: 1.9078 - op_bin_loss: 4.4881 - op_dir_loss: 0.2004 - op_feat_acc: 0.3662 - op_bin_acc: 0.1406 - op_dir_acc: 0.9281\n",
      "Epoch 67/7000\n",
      "7111/7111 [==============================] - 7s 989us/step - loss: 4.8792 - op_feat_loss: 1.9049 - op_bin_loss: 4.4880 - op_dir_loss: 0.2039 - op_feat_acc: 0.3652 - op_bin_acc: 0.1406 - op_dir_acc: 0.9238\n",
      "Epoch 68/7000\n",
      "7111/7111 [==============================] - 7s 990us/step - loss: 4.8778 - op_feat_loss: 1.9004 - op_bin_loss: 4.4878 - op_dir_loss: 0.1982 - op_feat_acc: 0.3653 - op_bin_acc: 0.1406 - op_dir_acc: 0.9274\n",
      "Epoch 69/7000\n",
      "7111/7111 [==============================] - 7s 953us/step - loss: 4.8764 - op_feat_loss: 1.8942 - op_bin_loss: 4.4878 - op_dir_loss: 0.1952 - op_feat_acc: 0.3670 - op_bin_acc: 0.1406 - op_dir_acc: 0.9286\n",
      "Epoch 70/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8749 - op_feat_loss: 1.8890 - op_bin_loss: 4.4876 - op_dir_loss: 0.1895 - op_feat_acc: 0.3676 - op_bin_acc: 0.1406 - op_dir_acc: 0.9321\n",
      "Epoch 71/7000\n",
      "7111/7111 [==============================] - 7s 939us/step - loss: 4.8749 - op_feat_loss: 1.8883 - op_bin_loss: 4.4876 - op_dir_loss: 0.1926 - op_feat_acc: 0.3687 - op_bin_acc: 0.1406 - op_dir_acc: 0.9294\n",
      "Epoch 72/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8737 - op_feat_loss: 1.8836 - op_bin_loss: 4.4874 - op_dir_loss: 0.1913 - op_feat_acc: 0.3697 - op_bin_acc: 0.1406 - op_dir_acc: 0.9294\n",
      "Epoch 73/7000\n",
      "7111/7111 [==============================] - 7s 952us/step - loss: 4.8717 - op_feat_loss: 1.8756 - op_bin_loss: 4.4874 - op_dir_loss: 0.1848 - op_feat_acc: 0.3703 - op_bin_acc: 0.1406 - op_dir_acc: 0.9331\n",
      "Epoch 74/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8713 - op_feat_loss: 1.8741 - op_bin_loss: 4.4873 - op_dir_loss: 0.1840 - op_feat_acc: 0.3683 - op_bin_acc: 0.1406 - op_dir_acc: 0.9352\n",
      "Epoch 75/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.8700 - op_feat_loss: 1.8690 - op_bin_loss: 4.4872 - op_dir_loss: 0.1787 - op_feat_acc: 0.3713 - op_bin_acc: 0.1406 - op_dir_acc: 0.9340\n",
      "Epoch 76/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8699 - op_feat_loss: 1.8680 - op_bin_loss: 4.4872 - op_dir_loss: 0.1832 - op_feat_acc: 0.3704 - op_bin_acc: 0.1406 - op_dir_acc: 0.9333\n",
      "Epoch 77/7000\n",
      "7111/7111 [==============================] - 7s 939us/step - loss: 4.8696 - op_feat_loss: 1.8664 - op_bin_loss: 4.4870 - op_dir_loss: 0.1861 - op_feat_acc: 0.3700 - op_bin_acc: 0.1406 - op_dir_acc: 0.9317\n",
      "Epoch 78/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.8706 - op_feat_loss: 1.8708 - op_bin_loss: 4.4867 - op_dir_loss: 0.1953 - op_feat_acc: 0.3651 - op_bin_acc: 0.1406 - op_dir_acc: 0.9262\n",
      "Epoch 79/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.8659 - op_feat_loss: 1.8605 - op_bin_loss: 4.4846 - op_dir_loss: 0.1848 - op_feat_acc: 0.3693 - op_bin_acc: 0.1406 - op_dir_acc: 0.9317\n",
      "Epoch 80/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.8505 - op_feat_loss: 1.8656 - op_bin_loss: 4.4676 - op_dir_loss: 0.1943 - op_feat_acc: 0.3632 - op_bin_acc: 0.1406 - op_dir_acc: 0.9305\n",
      "Epoch 81/7000\n",
      "7111/7111 [==============================] - 7s 935us/step - loss: 4.8384 - op_feat_loss: 1.8597 - op_bin_loss: 4.4571 - op_dir_loss: 0.1866 - op_feat_acc: 0.3673 - op_bin_acc: 0.1406 - op_dir_acc: 0.9319\n",
      "Epoch 82/7000\n",
      "7111/7111 [==============================] - 7s 926us/step - loss: 4.8288 - op_feat_loss: 1.8527 - op_bin_loss: 4.4490 - op_dir_loss: 0.1851 - op_feat_acc: 0.3731 - op_bin_acc: 0.1406 - op_dir_acc: 0.9298\n",
      "Epoch 83/7000\n",
      "7111/7111 [==============================] - 7s 958us/step - loss: 4.8180 - op_feat_loss: 1.8488 - op_bin_loss: 4.4392 - op_dir_loss: 0.1815 - op_feat_acc: 0.3729 - op_bin_acc: 0.1406 - op_dir_acc: 0.9321\n",
      "Epoch 84/7000\n",
      "7111/7111 [==============================] - 7s 925us/step - loss: 4.8131 - op_feat_loss: 1.8531 - op_bin_loss: 4.4333 - op_dir_loss: 0.1846 - op_feat_acc: 0.3689 - op_bin_acc: 0.1406 - op_dir_acc: 0.9321\n",
      "Epoch 85/7000\n",
      "7111/7111 [==============================] - 7s 937us/step - loss: 4.7953 - op_feat_loss: 1.8463 - op_bin_loss: 4.4167 - op_dir_loss: 0.1864 - op_feat_acc: 0.3696 - op_bin_acc: 0.1406 - op_dir_acc: 0.9290\n",
      "Epoch 86/7000\n",
      "7111/7111 [==============================] - 7s 938us/step - loss: 4.7822 - op_feat_loss: 1.8422 - op_bin_loss: 4.4046 - op_dir_loss: 0.1833 - op_feat_acc: 0.3691 - op_bin_acc: 0.1406 - op_dir_acc: 0.9329\n",
      "Epoch 87/7000\n",
      "7111/7111 [==============================] - 7s 929us/step - loss: 4.7707 - op_feat_loss: 1.8493 - op_bin_loss: 4.3910 - op_dir_loss: 0.1973 - op_feat_acc: 0.3661 - op_bin_acc: 0.1406 - op_dir_acc: 0.9283\n",
      "Epoch 88/7000\n",
      "7111/7111 [==============================] - 7s 939us/step - loss: 4.7545 - op_feat_loss: 1.8497 - op_bin_loss: 4.3746 - op_dir_loss: 0.1991 - op_feat_acc: 0.3690 - op_bin_acc: 0.1406 - op_dir_acc: 0.9210\n",
      "Epoch 89/7000\n",
      "7111/7111 [==============================] - 7s 933us/step - loss: 4.7535 - op_feat_loss: 1.8732 - op_bin_loss: 4.3665 - op_dir_loss: 0.2471 - op_feat_acc: 0.3592 - op_bin_acc: 0.1406 - op_dir_acc: 0.9096\n",
      "Epoch 90/7000\n",
      "7111/7111 [==============================] - 7s 921us/step - loss: 4.7193 - op_feat_loss: 1.8606 - op_bin_loss: 4.3363 - op_dir_loss: 0.2191 - op_feat_acc: 0.3642 - op_bin_acc: 0.1418 - op_dir_acc: 0.9130\n",
      "Epoch 91/7000\n",
      "7111/7111 [==============================] - 7s 921us/step - loss: 4.7009 - op_feat_loss: 1.8641 - op_bin_loss: 4.3170 - op_dir_loss: 0.2224 - op_feat_acc: 0.3578 - op_bin_acc: 0.1432 - op_dir_acc: 0.9169\n",
      "Epoch 92/7000\n",
      "7111/7111 [==============================] - 7s 997us/step - loss: 4.6791 - op_feat_loss: 1.8568 - op_bin_loss: 4.2970 - op_dir_loss: 0.2143 - op_feat_acc: 0.3625 - op_bin_acc: 0.1495 - op_dir_acc: 0.9220\n",
      "Epoch 93/7000\n",
      "7111/7111 [==============================] - 7s 965us/step - loss: 4.6559 - op_feat_loss: 1.8472 - op_bin_loss: 4.2761 - op_dir_loss: 0.2075 - op_feat_acc: 0.3655 - op_bin_acc: 0.1558 - op_dir_acc: 0.9234\n",
      "Epoch 94/7000\n",
      "7111/7111 [==============================] - 7s 955us/step - loss: 4.6358 - op_feat_loss: 1.8425 - op_bin_loss: 4.2569 - op_dir_loss: 0.2077 - op_feat_acc: 0.3662 - op_bin_acc: 0.1572 - op_dir_acc: 0.9236\n",
      "Epoch 95/7000\n",
      "7111/7111 [==============================] - 7s 931us/step - loss: 4.6149 - op_feat_loss: 1.8408 - op_bin_loss: 4.2365 - op_dir_loss: 0.2057 - op_feat_acc: 0.3711 - op_bin_acc: 0.1614 - op_dir_acc: 0.9225\n",
      "Epoch 96/7000\n",
      "7111/7111 [==============================] - 7s 946us/step - loss: 4.6008 - op_feat_loss: 1.8421 - op_bin_loss: 4.2214 - op_dir_loss: 0.2200 - op_feat_acc: 0.3645 - op_bin_acc: 0.1638 - op_dir_acc: 0.9201\n",
      "Epoch 97/7000\n",
      "7111/7111 [==============================] - 7s 956us/step - loss: 4.5829 - op_feat_loss: 1.8400 - op_bin_loss: 4.2041 - op_dir_loss: 0.2171 - op_feat_acc: 0.3669 - op_bin_acc: 0.1683 - op_dir_acc: 0.9167\n",
      "Epoch 98/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.5513 - op_feat_loss: 1.8202 - op_bin_loss: 4.1775 - op_dir_loss: 0.1955 - op_feat_acc: 0.3779 - op_bin_acc: 0.1728 - op_dir_acc: 0.9287\n",
      "Epoch 99/7000\n",
      "7111/7111 [==============================] - 7s 959us/step - loss: 4.5405 - op_feat_loss: 1.8287 - op_bin_loss: 4.1640 - op_dir_loss: 0.2151 - op_feat_acc: 0.3698 - op_bin_acc: 0.1747 - op_dir_acc: 0.9196\n",
      "Epoch 100/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.5312 - op_feat_loss: 1.8326 - op_bin_loss: 4.1535 - op_dir_loss: 0.2247 - op_feat_acc: 0.3759 - op_bin_acc: 0.1770 - op_dir_acc: 0.9162\n",
      "Epoch 101/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 4.5012 - op_feat_loss: 1.8157 - op_bin_loss: 4.1277 - op_dir_loss: 0.2053 - op_feat_acc: 0.3731 - op_bin_acc: 0.1810 - op_dir_acc: 0.9252\n",
      "Epoch 102/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.4835 - op_feat_loss: 1.8188 - op_bin_loss: 4.1094 - op_dir_loss: 0.2068 - op_feat_acc: 0.3736 - op_bin_acc: 0.1835 - op_dir_acc: 0.9229\n",
      "Epoch 103/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.4595 - op_feat_loss: 1.7999 - op_bin_loss: 4.0896 - op_dir_loss: 0.1975 - op_feat_acc: 0.3763 - op_bin_acc: 0.1891 - op_dir_acc: 0.9288\n",
      "Epoch 104/7000\n",
      "7111/7111 [==============================] - 9s 1ms/step - loss: 4.4428 - op_feat_loss: 1.7941 - op_bin_loss: 4.0741 - op_dir_loss: 0.1982 - op_feat_acc: 0.4011 - op_bin_acc: 0.1918 - op_dir_acc: 0.9293\n",
      "Epoch 105/7000\n",
      "7111/7111 [==============================] - 25s 3ms/step - loss: 4.4286 - op_feat_loss: 1.7945 - op_bin_loss: 4.0598 - op_dir_loss: 0.1986 - op_feat_acc: 0.4247 - op_bin_acc: 0.1963 - op_dir_acc: 0.9256\n",
      "Epoch 106/7000\n",
      "2432/7111 [=========>....................] - ETA: 19s - loss: 4.4330 - op_feat_loss: 1.7716 - op_bin_loss: 4.0689 - op_dir_loss: 0.1955 - op_feat_acc: 0.4317 - op_bin_acc: 0.2085 - op_dir_acc: 0.9289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "requests_with_retry encountered retryable exception: ('Connection aborted.', OSError(\"(10051, 'WSAENETUNREACH')\",)). args: ('https://api.wandb.ai/files/shakkeel_mlsquare/dert/3i9x8q0g/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 206, 'content': ['2020-04-09T08:50:54.133728 7111/7111 [==============================] - 8s 1ms/step - loss: 4.4595 - op_feat_loss: 1.7999 - op_bin_loss: 4.0896 - op_dir_loss: 0.1975 - op_feat_acc: 0.3763 - op_bin_acc: 0.1891 - op_dir_acc: 0.9288\\n', '2020-04-09T08:50:54.134694 Epoch 104/7000\\n', '2020-04-09T08:51:02.931895 7111/7111 [==============================] - 9s 1ms/step - loss: 4.4428 - op_feat_loss: 1.7941 - op_bin_loss: 4.0741 - op_dir_loss: 0.1982 - op_feat_acc: 0.4011 - op_bin_acc: 0.1918 - op_dir_acc: 0.9293\\n', '2020-04-09T08:51:02.933218 Epoch 105/7000\\n', '2020-04-09T08:51:20.316220 5632/7111 [======================>.......] - ETA: 4s - loss: 4.4181 - op_feat_loss: 1.7891 - op_bin_loss: 4.0503 - op_dir_loss: 0.1997 - op_feat_acc: 0.4288 - op_bin_acc: 0.1994 - op_dir_acc: 0.9263\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\r']}, 'wandb-events.jsonl': {'offset': 25, 'content': ['{\"system.gpu.0.gpu\": 24.33, \"system.gpu.0.memory\": 4.8, \"system.gpu.0.memoryAllocated\": 78.74, \"system.gpu.0.temp\": 64.0, \"system.gpu.process.0.gpu\": 24.33, \"system.gpu.process.0.memory\": 4.8, \"system.gpu.process.0.memoryAllocated\": 78.74, \"system.gpu.process.0.temp\": 64.0, \"system.cpu\": 49.45, \"system.memory\": 84.3, \"system.disk\": 35.0, \"system.proc.memory.availableMB\": 1262.38, \"system.proc.memory.rssMB\": 645.35, \"system.proc.memory.percent\": 8.02, \"system.proc.cpu.threads\": 46.0, \"system.network.sent\": 20422915, \"system.network.recv\": 12081105, \"_wandb\": true, \"_timestamp\": 1586422253, \"_runtime\": 816}\\n']}, 'wandb-history.jsonl': {'offset': 102, 'content': ['{\"epoch\": 102, \"loss\": 4.459480583709666, \"op_feat_loss\": 1.799901471143365, \"op_bin_loss\": 4.089623342299994, \"op_dir_loss\": 0.19753873116053738, \"op_feat_acc\": 0.37631837986152966, \"op_bin_acc\": 0.18914358036634774, \"op_dir_acc\": 0.92884263832548, \"_runtime\": 777.6400320529938, \"_timestamp\": 1586422253.7260916, \"_step\": 102}\\n', '{\"epoch\": 103, \"loss\": 4.44281813693003, \"op_feat_loss\": 1.7940758127080558, \"op_bin_loss\": 4.07409134308106, \"op_dir_loss\": 0.19823263821731285, \"op_feat_acc\": 0.4010687666156593, \"op_bin_acc\": 0.19181549711504695, \"op_dir_acc\": 0.9292645198084134, \"_runtime\": 786.6403806209564, \"_timestamp\": 1586422262.7264402, \"_step\": 103}\\n']}, 'wandb-summary.json': {'offset': 0, 'content': ['{\"graph\": {\"_type\": \"graph-file\", \"path\": \"media/graph/graph_summary_122264e4.graph.json\", \"sha256\": \"122264e49047553ba95ef7c227a4082c953bfbec3f4d054bae88621781b4669d\", \"size\": 2065}, \"_timestamp\": 1586422262.7264402, \"op_bin_acc\": 0.19181549711504695, \"epoch\": 103, \"loss\": 4.44281813693003, \"_runtime\": 786.6403806209564, \"op_dir_loss\": 0.19823263821731285, \"_step\": 103, \"op_dir_acc\": 0.9292645198084134, \"op_feat_loss\": 1.7940758127080558, \"op_feat_acc\": 0.4010687666156593, \"op_bin_loss\": 4.07409134308106}\\n']}}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2944/7111 [===========>..................] - ETA: 17s - loss: 4.4049 - op_feat_loss: 1.7668 - op_bin_loss: 4.0419 - op_dir_loss: 0.1929 - op_feat_acc: 0.4351 - op_bin_acc: 0.2096 - op_dir_acc: 0.9307"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/shakkeel_mlsquare/dert/3i9x8q0g/file_stream (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000021E94F2A518>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',)). args: ('https://api.wandb.ai/files/shakkeel_mlsquare/dert/3i9x8q0g/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 206, 'content': ['2020-04-09T08:50:54.133728 7111/7111 [==============================] - 8s 1ms/step - loss: 4.4595 - op_feat_loss: 1.7999 - op_bin_loss: 4.0896 - op_dir_loss: 0.1975 - op_feat_acc: 0.3763 - op_bin_acc: 0.1891 - op_dir_acc: 0.9288\\n', '2020-04-09T08:50:54.134694 Epoch 104/7000\\n', '2020-04-09T08:51:02.931895 7111/7111 [==============================] - 9s 1ms/step - loss: 4.4428 - op_feat_loss: 1.7941 - op_bin_loss: 4.0741 - op_dir_loss: 0.1982 - op_feat_acc: 0.4011 - op_bin_acc: 0.1918 - op_dir_acc: 0.9293\\n', '2020-04-09T08:51:02.933218 Epoch 105/7000\\n', '2020-04-09T08:51:20.316220 5632/7111 [======================>.......] - ETA: 4s - loss: 4.4181 - op_feat_loss: 1.7891 - op_bin_loss: 4.0503 - op_dir_loss: 0.1997 - op_feat_acc: 0.4288 - op_bin_acc: 0.1994 - op_dir_acc: 0.9263\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\r']}, 'wandb-events.jsonl': {'offset': 25, 'content': ['{\"system.gpu.0.gpu\": 24.33, \"system.gpu.0.memory\": 4.8, \"system.gpu.0.memoryAllocated\": 78.74, \"system.gpu.0.temp\": 64.0, \"system.gpu.process.0.gpu\": 24.33, \"system.gpu.process.0.memory\": 4.8, \"system.gpu.process.0.memoryAllocated\": 78.74, \"system.gpu.process.0.temp\": 64.0, \"system.cpu\": 49.45, \"system.memory\": 84.3, \"system.disk\": 35.0, \"system.proc.memory.availableMB\": 1262.38, \"system.proc.memory.rssMB\": 645.35, \"system.proc.memory.percent\": 8.02, \"system.proc.cpu.threads\": 46.0, \"system.network.sent\": 20422915, \"system.network.recv\": 12081105, \"_wandb\": true, \"_timestamp\": 1586422253, \"_runtime\": 816}\\n']}, 'wandb-history.jsonl': {'offset': 102, 'content': ['{\"epoch\": 102, \"loss\": 4.459480583709666, \"op_feat_loss\": 1.799901471143365, \"op_bin_loss\": 4.089623342299994, \"op_dir_loss\": 0.19753873116053738, \"op_feat_acc\": 0.37631837986152966, \"op_bin_acc\": 0.18914358036634774, \"op_dir_acc\": 0.92884263832548, \"_runtime\": 777.6400320529938, \"_timestamp\": 1586422253.7260916, \"_step\": 102}\\n', '{\"epoch\": 103, \"loss\": 4.44281813693003, \"op_feat_loss\": 1.7940758127080558, \"op_bin_loss\": 4.07409134308106, \"op_dir_loss\": 0.19823263821731285, \"op_feat_acc\": 0.4010687666156593, \"op_bin_acc\": 0.19181549711504695, \"op_dir_acc\": 0.9292645198084134, \"_runtime\": 786.6403806209564, \"_timestamp\": 1586422262.7264402, \"_step\": 103}\\n']}, 'wandb-summary.json': {'offset': 0, 'content': ['{\"graph\": {\"_type\": \"graph-file\", \"path\": \"media/graph/graph_summary_122264e4.graph.json\", \"sha256\": \"122264e49047553ba95ef7c227a4082c953bfbec3f4d054bae88621781b4669d\", \"size\": 2065}, \"_timestamp\": 1586422262.7264402, \"op_bin_acc\": 0.19181549711504695, \"epoch\": 103, \"loss\": 4.44281813693003, \"_runtime\": 786.6403806209564, \"op_dir_loss\": 0.19823263821731285, \"_step\": 103, \"op_dir_acc\": 0.9292645198084134, \"op_feat_loss\": 1.7940758127080558, \"op_feat_acc\": 0.4010687666156593, \"op_bin_loss\": 4.07409134308106}\\n']}}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7111/7111 [==============================] - 29s 4ms/step - loss: 4.4122 - op_feat_loss: 1.7852 - op_bin_loss: 4.0453 - op_dir_loss: 0.1973 - op_feat_acc: 0.4298 - op_bin_acc: 0.2014 - op_dir_acc: 0.9287\n",
      "Epoch 107/7000\n",
      "7111/7111 [==============================] - 17s 2ms/step - loss: 4.3873 - op_feat_loss: 1.7716 - op_bin_loss: 4.0238 - op_dir_loss: 0.1849 - op_feat_acc: 0.4352 - op_bin_acc: 0.2046 - op_dir_acc: 0.9333\n",
      "Epoch 108/7000\n",
      "7111/7111 [==============================] - 14s 2ms/step - loss: 4.3738 - op_feat_loss: 1.7717 - op_bin_loss: 4.0100 - op_dir_loss: 0.1899 - op_feat_acc: 0.4310 - op_bin_acc: 0.2112 - op_dir_acc: 0.9305\n",
      "Epoch 109/7000\n",
      "7111/7111 [==============================] - 12s 2ms/step - loss: 4.3644 - op_feat_loss: 1.7758 - op_bin_loss: 3.9992 - op_dir_loss: 0.2005 - op_feat_acc: 0.4271 - op_bin_acc: 0.2183 - op_dir_acc: 0.9259\n",
      "Epoch 110/7000\n",
      "7111/7111 [==============================] - 12s 2ms/step - loss: 4.3454 - op_feat_loss: 1.7718 - op_bin_loss: 3.9809 - op_dir_loss: 0.2031 - op_feat_acc: 0.4310 - op_bin_acc: 0.2209 - op_dir_acc: 0.9248\n",
      "Epoch 111/7000\n",
      "7111/7111 [==============================] - 11s 2ms/step - loss: 4.3202 - op_feat_loss: 1.7604 - op_bin_loss: 3.9584 - op_dir_loss: 0.1944 - op_feat_acc: 0.4319 - op_bin_acc: 0.2285 - op_dir_acc: 0.9265\n",
      "Epoch 112/7000\n",
      "7111/7111 [==============================] - 12s 2ms/step - loss: 4.3033 - op_feat_loss: 1.7573 - op_bin_loss: 3.9421 - op_dir_loss: 0.1957 - op_feat_acc: 0.4358 - op_bin_acc: 0.2296 - op_dir_acc: 0.9291\n",
      "Epoch 113/7000\n",
      "7111/7111 [==============================] - 10s 1ms/step - loss: 4.2888 - op_feat_loss: 1.7523 - op_bin_loss: 3.9284 - op_dir_loss: 0.1999 - op_feat_acc: 0.4350 - op_bin_acc: 0.2334 - op_dir_acc: 0.9270\n",
      "Epoch 114/7000\n",
      "7111/7111 [==============================] - 11s 2ms/step - loss: 4.2701 - op_feat_loss: 1.7470 - op_bin_loss: 3.9110 - op_dir_loss: 0.1929 - op_feat_acc: 0.4284 - op_bin_acc: 0.2384 - op_dir_acc: 0.9276\n",
      "Epoch 115/7000\n",
      "7111/7111 [==============================] - 11s 2ms/step - loss: 4.2511 - op_feat_loss: 1.7396 - op_bin_loss: 3.8937 - op_dir_loss: 0.1901 - op_feat_acc: 0.4365 - op_bin_acc: 0.2450 - op_dir_acc: 0.9308\n",
      "Epoch 116/7000\n",
      "7111/7111 [==============================] - 12s 2ms/step - loss: 4.2369 - op_feat_loss: 1.7356 - op_bin_loss: 3.8804 - op_dir_loss: 0.1883 - op_feat_acc: 0.4331 - op_bin_acc: 0.2454 - op_dir_acc: 0.9308\n",
      "Epoch 117/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.2235 - op_feat_loss: 1.7296 - op_bin_loss: 3.8679 - op_dir_loss: 0.1935 - op_feat_acc: 0.4388 - op_bin_acc: 0.2483 - op_dir_acc: 0.9302\n",
      "Epoch 118/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.2023 - op_feat_loss: 1.7070 - op_bin_loss: 3.8516 - op_dir_loss: 0.1848 - op_feat_acc: 0.4603 - op_bin_acc: 0.2523 - op_dir_acc: 0.9310\n",
      "Epoch 119/7000\n",
      "7111/7111 [==============================] - 6s 877us/step - loss: 4.1915 - op_feat_loss: 1.6990 - op_bin_loss: 3.8421 - op_dir_loss: 0.1918 - op_feat_acc: 0.4620 - op_bin_acc: 0.2520 - op_dir_acc: 0.9298\n",
      "Epoch 120/7000\n",
      "7111/7111 [==============================] - 6s 899us/step - loss: 4.1785 - op_feat_loss: 1.6912 - op_bin_loss: 3.8307 - op_dir_loss: 0.1915 - op_feat_acc: 0.4673 - op_bin_acc: 0.2524 - op_dir_acc: 0.9283\n",
      "Epoch 121/7000\n",
      "7111/7111 [==============================] - 6s 889us/step - loss: 4.1670 - op_feat_loss: 1.6789 - op_bin_loss: 3.8219 - op_dir_loss: 0.1865 - op_feat_acc: 0.4652 - op_bin_acc: 0.2503 - op_dir_acc: 0.9322\n",
      "Epoch 122/7000\n",
      "7111/7111 [==============================] - 7s 937us/step - loss: 4.1669 - op_feat_loss: 1.6781 - op_bin_loss: 3.8217 - op_dir_loss: 0.1928 - op_feat_acc: 0.4614 - op_bin_acc: 0.2554 - op_dir_acc: 0.9287\n",
      "Epoch 123/7000\n",
      "7111/7111 [==============================] - 6s 896us/step - loss: 4.1698 - op_feat_loss: 1.6816 - op_bin_loss: 3.8230 - op_dir_loss: 0.2089 - op_feat_acc: 0.4584 - op_bin_acc: 0.2489 - op_dir_acc: 0.9218\n",
      "Epoch 124/7000\n",
      "7111/7111 [==============================] - 6s 879us/step - loss: 4.1514 - op_feat_loss: 1.6656 - op_bin_loss: 3.8084 - op_dir_loss: 0.1987 - op_feat_acc: 0.4665 - op_bin_acc: 0.2502 - op_dir_acc: 0.9266\n",
      "Epoch 125/7000\n",
      "7111/7111 [==============================] - 7s 947us/step - loss: 4.1296 - op_feat_loss: 1.6529 - op_bin_loss: 3.7893 - op_dir_loss: 0.1955 - op_feat_acc: 0.4655 - op_bin_acc: 0.2551 - op_dir_acc: 0.9286\n",
      "Epoch 126/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 4.1108 - op_feat_loss: 1.6426 - op_bin_loss: 3.7728 - op_dir_loss: 0.1885 - op_feat_acc: 0.4696 - op_bin_acc: 0.2552 - op_dir_acc: 0.9311\n",
      "Epoch 127/7000\n",
      "7111/7111 [==============================] - 7s 931us/step - loss: 4.0889 - op_feat_loss: 1.6272 - op_bin_loss: 3.7543 - op_dir_loss: 0.1827 - op_feat_acc: 0.4783 - op_bin_acc: 0.2593 - op_dir_acc: 0.9339\n",
      "Epoch 128/7000\n",
      "7111/7111 [==============================] - 7s 949us/step - loss: 4.0729 - op_feat_loss: 1.6149 - op_bin_loss: 3.7410 - op_dir_loss: 0.1770 - op_feat_acc: 0.4811 - op_bin_acc: 0.2589 - op_dir_acc: 0.9356\n",
      "Epoch 129/7000\n",
      "7111/7111 [==============================] - 6s 900us/step - loss: 4.0610 - op_feat_loss: 1.6071 - op_bin_loss: 3.7306 - op_dir_loss: 0.1794 - op_feat_acc: 0.4829 - op_bin_acc: 0.2620 - op_dir_acc: 0.9340\n",
      "Epoch 130/7000\n",
      "7111/7111 [==============================] - 6s 893us/step - loss: 4.0512 - op_feat_loss: 1.6016 - op_bin_loss: 3.7220 - op_dir_loss: 0.1784 - op_feat_acc: 0.4828 - op_bin_acc: 0.2613 - op_dir_acc: 0.9357\n",
      "Epoch 131/7000\n",
      "7111/7111 [==============================] - 6s 887us/step - loss: 4.0465 - op_feat_loss: 1.6021 - op_bin_loss: 3.7170 - op_dir_loss: 0.1822 - op_feat_acc: 0.4804 - op_bin_acc: 0.2600 - op_dir_acc: 0.9339\n",
      "Epoch 132/7000\n",
      "7111/7111 [==============================] - 6s 903us/step - loss: 4.0318 - op_feat_loss: 1.5887 - op_bin_loss: 3.7053 - op_dir_loss: 0.1745 - op_feat_acc: 0.4850 - op_bin_acc: 0.2648 - op_dir_acc: 0.9364\n",
      "Epoch 133/7000\n",
      "7111/7111 [==============================] - 7s 984us/step - loss: 4.0264 - op_feat_loss: 1.5849 - op_bin_loss: 3.7006 - op_dir_loss: 0.1766 - op_feat_acc: 0.4866 - op_bin_acc: 0.2611 - op_dir_acc: 0.9356\n",
      "Epoch 134/7000\n",
      "7111/7111 [==============================] - 6s 891us/step - loss: 4.0170 - op_feat_loss: 1.5756 - op_bin_loss: 3.6932 - op_dir_loss: 0.1735 - op_feat_acc: 0.4926 - op_bin_acc: 0.2645 - op_dir_acc: 0.9376\n",
      "Epoch 135/7000\n",
      "7111/7111 [==============================] - 6s 894us/step - loss: 3.9999 - op_feat_loss: 1.5650 - op_bin_loss: 3.6784 - op_dir_loss: 0.1691 - op_feat_acc: 0.4942 - op_bin_acc: 0.2651 - op_dir_acc: 0.9412\n",
      "Epoch 136/7000\n",
      "7111/7111 [==============================] - 6s 891us/step - loss: 4.0063 - op_feat_loss: 1.5708 - op_bin_loss: 3.6832 - op_dir_loss: 0.1787 - op_feat_acc: 0.4928 - op_bin_acc: 0.2611 - op_dir_acc: 0.9349\n",
      "Epoch 137/7000\n",
      "7111/7111 [==============================] - 6s 907us/step - loss: 4.0056 - op_feat_loss: 1.5716 - op_bin_loss: 3.6823 - op_dir_loss: 0.1783 - op_feat_acc: 0.4870 - op_bin_acc: 0.2609 - op_dir_acc: 0.9363\n",
      "Epoch 138/7000\n",
      "7111/7111 [==============================] - 6s 912us/step - loss: 3.9796 - op_feat_loss: 1.5570 - op_bin_loss: 3.6597 - op_dir_loss: 0.1705 - op_feat_acc: 0.4970 - op_bin_acc: 0.2659 - op_dir_acc: 0.9384\n",
      "Epoch 139/7000\n",
      "7111/7111 [==============================] - 7s 947us/step - loss: 3.9635 - op_feat_loss: 1.5448 - op_bin_loss: 3.6461 - op_dir_loss: 0.1682 - op_feat_acc: 0.4989 - op_bin_acc: 0.2668 - op_dir_acc: 0.9405\n",
      "Epoch 140/7000\n",
      "7111/7111 [==============================] - 6s 884us/step - loss: 3.9550 - op_feat_loss: 1.5388 - op_bin_loss: 3.6388 - op_dir_loss: 0.1673 - op_feat_acc: 0.4967 - op_bin_acc: 0.2652 - op_dir_acc: 0.9402\n",
      "Epoch 141/7000\n",
      "7111/7111 [==============================] - 6s 895us/step - loss: 3.9531 - op_feat_loss: 1.5405 - op_bin_loss: 3.6365 - op_dir_loss: 0.1704 - op_feat_acc: 0.4942 - op_bin_acc: 0.2692 - op_dir_acc: 0.9388\n",
      "Epoch 142/7000\n",
      "7111/7111 [==============================] - 7s 966us/step - loss: 3.9428 - op_feat_loss: 1.5316 - op_bin_loss: 3.6280 - op_dir_loss: 0.1699 - op_feat_acc: 0.5037 - op_bin_acc: 0.2739 - op_dir_acc: 0.9392\n",
      "Epoch 143/7000\n",
      " 128/7111 [..............................] - ETA: 6s - loss: 3.6988 - op_feat_loss: 1.3742 - op_bin_loss: 3.4182 - op_dir_loss: 0.1142 - op_feat_acc: 0.5391 - op_bin_acc: 0.3125 - op_dir_acc: 0.9766"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "requests_with_retry encountered retryable exception: ('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",)). args: ('https://api.wandb.ai/files/shakkeel_mlsquare/dert/3i9x8q0g/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 278, 'content': ['2020-04-09T08:56:25.253306 7111/7111 [==============================] - 6s 912us/step - loss: 3.9796 - op_feat_loss: 1.5570 - op_bin_loss: 3.6597 - op_dir_loss: 0.1705 - op_feat_acc: 0.4970 - op_bin_acc: 0.2659 - op_dir_acc: 0.9384\\n', '2020-04-09T08:56:25.253306 Epoch 139/7000\\n', '2020-04-09T08:56:31.990803 7111/7111 [==============================] - 7s 947us/step - loss: 3.9635 - op_feat_loss: 1.5448 - op_bin_loss: 3.6461 - op_dir_loss: 0.1682 - op_feat_acc: 0.4989 - op_bin_acc: 0.2668 - op_dir_acc: 0.9405\\n', '2020-04-09T08:56:31.990803 Epoch 140/7000\\n', '2020-04-09T08:56:38.277492 7111/7111 [==============================] - 6s 884us/step - loss: 3.9550 - op_feat_loss: 1.5388 - op_bin_loss: 3.6388 - op_dir_loss: 0.1673 - op_feat_acc: 0.4967 - op_bin_acc: 0.2652 - op_dir_acc: 0.9402\\n', '2020-04-09T08:56:38.277492 Epoch 141/7000\\n', '2020-04-09T08:56:44.642479 7111/7111 [==============================] - 6s 895us/step - loss: 3.9531 - op_feat_loss: 1.5405 - op_bin_loss: 3.6365 - op_dir_loss: 0.1704 - op_feat_acc: 0.4942 - op_bin_acc: 0.2692 - op_dir_acc: 0.9388\\n', '2020-04-09T08:56:44.642479 Epoch 142/7000\\n', '2020-04-09T08:56:51.514540 7111/7111 [==============================] - 7s 966us/step - loss: 3.9428 - op_feat_loss: 1.5316 - op_bin_loss: 3.6280 - op_dir_loss: 0.1699 - op_feat_acc: 0.5037 - op_bin_acc: 0.2739 - op_dir_acc: 0.9392\\n', '2020-04-09T08:56:51.514540 Epoch 143/7000\\n', '2020-04-09T08:56:51.630379 \\r']}, 'wandb-events.jsonl': {'offset': 36, 'content': ['{\"system.gpu.0.gpu\": 29.53, \"system.gpu.0.memory\": 6.13, \"system.gpu.0.memoryAllocated\": 78.74, \"system.gpu.0.temp\": 64.0, \"system.gpu.process.0.gpu\": 29.53, \"system.gpu.process.0.memory\": 6.13, \"system.gpu.process.0.memoryAllocated\": 78.74, \"system.gpu.process.0.temp\": 64.0, \"system.cpu\": 37.14, \"system.memory\": 78.9, \"system.disk\": 35.0, \"system.proc.memory.availableMB\": 1696.9, \"system.proc.memory.rssMB\": 424.02, \"system.proc.memory.percent\": 5.27, \"system.proc.cpu.threads\": 46.0, \"system.network.sent\": 20970695, \"system.network.recv\": 13086781, \"_wandb\": true, \"_timestamp\": 1586422610, \"_runtime\": 1173}\\n']}, 'wandb-history.jsonl': {'offset': 137, 'content': ['{\"epoch\": 137, \"loss\": 3.979622826933643, \"op_feat_loss\": 1.5570157415302572, \"op_bin_loss\": 3.6596940024092537, \"op_dir_loss\": 0.1705136307263874, \"op_feat_acc\": 0.49697651534187126, \"op_bin_acc\": 0.2659260301906136, \"op_dir_acc\": 0.9384052877418771, \"_runtime\": 1109.1203002929688, \"_timestamp\": 1586422585.2063599, \"_step\": 137}\\n', '{\"epoch\": 138, \"loss\": 3.963456650890725, \"op_feat_loss\": 1.544754914033096, \"op_bin_loss\": 3.646097096020856, \"op_dir_loss\": 0.16817118858858562, \"op_feat_acc\": 0.49894529612502575, \"op_bin_acc\": 0.26676979329478406, \"op_dir_acc\": 0.9405146954834436, \"_runtime\": 1115.6570582389832, \"_timestamp\": 1586422591.7431178, \"_step\": 138}\\n', '{\"epoch\": 139, \"loss\": 3.9549841275950754, \"op_feat_loss\": 1.53884523128796, \"op_bin_loss\": 3.63884902238477, \"op_dir_loss\": 0.16732127846519482, \"op_feat_acc\": 0.4966952605700798, \"op_bin_acc\": 0.2652228940658103, \"op_dir_acc\": 0.940233440929585, \"_runtime\": 1122.1379234790802, \"_timestamp\": 1586422598.223983, \"_step\": 139}\\n', '{\"epoch\": 140, \"loss\": 3.953095827134848, \"op_feat_loss\": 1.5404971658454265, \"op_bin_loss\": 3.6364768600852795, \"op_dir_loss\": 0.17039038941857182, \"op_feat_acc\": 0.4941639713078607, \"op_bin_acc\": 0.2691604554896247, \"op_dir_acc\": 0.9388271692248106, \"_runtime\": 1128.4938523769379, \"_timestamp\": 1586422604.579912, \"_step\": 140}\\n', '{\"epoch\": 141, \"loss\": 3.942775159826964, \"op_feat_loss\": 1.5316092601524527, \"op_bin_loss\": 3.627960459422569, \"op_dir_loss\": 0.16985650815938264, \"op_feat_acc\": 0.5037266204853699, \"op_bin_acc\": 0.27394178037803696, \"op_dir_acc\": 0.9392490508167104, \"_runtime\": 1134.9107630252838, \"_timestamp\": 1586422610.9968226, \"_step\": 141}\\n']}, 'wandb-summary.json': {'offset': 0, 'content': ['{\"graph\": {\"_type\": \"graph-file\", \"path\": \"media/graph/graph_summary_122264e4.graph.json\", \"sha256\": \"122264e49047553ba95ef7c227a4082c953bfbec3f4d054bae88621781b4669d\", \"size\": 2065}, \"_timestamp\": 1586422604.579912, \"op_bin_acc\": 0.2691604554896247, \"epoch\": 140, \"loss\": 3.953095827134848, \"_runtime\": 1128.4938523769379, \"op_dir_loss\": 0.17039038941857182, \"_step\": 140, \"op_dir_acc\": 0.9388271692248106, \"op_feat_loss\": 1.5404971658454265, \"op_feat_acc\": 0.4941639713078607, \"op_bin_loss\": 3.6364768600852795}\\n']}}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7111/7111 [==============================] - 6s 902us/step - loss: 3.9337 - op_feat_loss: 1.5268 - op_bin_loss: 3.6199 - op_dir_loss: 0.1693 - op_feat_acc: 0.5016 - op_bin_acc: 0.2731 - op_dir_acc: 0.9408\n",
      "Epoch 144/7000\n",
      "7111/7111 [==============================] - 6s 902us/step - loss: 3.9269 - op_feat_loss: 1.5211 - op_bin_loss: 3.6142 - op_dir_loss: 0.1696 - op_feat_acc: 0.5027 - op_bin_acc: 0.2751 - op_dir_acc: 0.9407\n",
      "Epoch 145/7000\n",
      "7111/7111 [==============================] - 6s 900us/step - loss: 3.9216 - op_feat_loss: 1.5147 - op_bin_loss: 3.6103 - op_dir_loss: 0.1668 - op_feat_acc: 0.5043 - op_bin_acc: 0.2751 - op_dir_acc: 0.9397\n",
      "Epoch 146/7000\n",
      "7111/7111 [==============================] - 7s 919us/step - loss: 3.9065 - op_feat_loss: 1.5061 - op_bin_loss: 3.5969 - op_dir_loss: 0.1670 - op_feat_acc: 0.5030 - op_bin_acc: 0.2765 - op_dir_acc: 0.9391\n",
      "Epoch 147/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 3.9104 - op_feat_loss: 1.5103 - op_bin_loss: 3.5994 - op_dir_loss: 0.1773 - op_feat_acc: 0.5043 - op_bin_acc: 0.2769 - op_dir_acc: 0.9378\n",
      "Epoch 148/7000\n",
      "7111/7111 [==============================] - 6s 890us/step - loss: 3.9370 - op_feat_loss: 1.5294 - op_bin_loss: 3.6213 - op_dir_loss: 0.1952 - op_feat_acc: 0.4966 - op_bin_acc: 0.2725 - op_dir_acc: 0.9300\n",
      "Epoch 149/7000\n",
      "7111/7111 [==============================] - 6s 896us/step - loss: 3.9001 - op_feat_loss: 1.4996 - op_bin_loss: 3.5914 - op_dir_loss: 0.1747 - op_feat_acc: 0.5044 - op_bin_acc: 0.2766 - op_dir_acc: 0.9376\n",
      "Epoch 150/7000\n",
      "7111/7111 [==============================] - 7s 965us/step - loss: 3.8895 - op_feat_loss: 1.4917 - op_bin_loss: 3.5827 - op_dir_loss: 0.1683 - op_feat_acc: 0.5088 - op_bin_acc: 0.2746 - op_dir_acc: 0.9392\n",
      "Epoch 151/7000\n",
      "7111/7111 [==============================] - 6s 888us/step - loss: 3.8999 - op_feat_loss: 1.5016 - op_bin_loss: 3.5903 - op_dir_loss: 0.1855 - op_feat_acc: 0.5056 - op_bin_acc: 0.2756 - op_dir_acc: 0.9362\n",
      "Epoch 152/7000\n",
      "7111/7111 [==============================] - 7s 955us/step - loss: 3.9877 - op_feat_loss: 1.5635 - op_bin_loss: 3.6636 - op_dir_loss: 0.2276 - op_feat_acc: 0.4826 - op_bin_acc: 0.2586 - op_dir_acc: 0.9151\n",
      "Epoch 153/7000\n",
      "7111/7111 [==============================] - 6s 886us/step - loss: 3.9081 - op_feat_loss: 1.5099 - op_bin_loss: 3.5966 - op_dir_loss: 0.1895 - op_feat_acc: 0.4985 - op_bin_acc: 0.2704 - op_dir_acc: 0.9314\n",
      "Epoch 154/7000\n",
      "7111/7111 [==============================] - 6s 895us/step - loss: 3.8946 - op_feat_loss: 1.4966 - op_bin_loss: 3.5861 - op_dir_loss: 0.1850 - op_feat_acc: 0.5018 - op_bin_acc: 0.2721 - op_dir_acc: 0.9312\n",
      "Epoch 155/7000\n",
      "7111/7111 [==============================] - 6s 893us/step - loss: 3.8690 - op_feat_loss: 1.4736 - op_bin_loss: 3.5657 - op_dir_loss: 0.1717 - op_feat_acc: 0.5126 - op_bin_acc: 0.2741 - op_dir_acc: 0.9405\n",
      "Epoch 156/7000\n",
      "7111/7111 [==============================] - 6s 893us/step - loss: 3.8503 - op_feat_loss: 1.4597 - op_bin_loss: 3.5499 - op_dir_loss: 0.1694 - op_feat_acc: 0.5160 - op_bin_acc: 0.2787 - op_dir_acc: 0.9397\n",
      "Epoch 157/7000\n",
      "7111/7111 [==============================] - 6s 898us/step - loss: 3.8463 - op_feat_loss: 1.4570 - op_bin_loss: 3.5464 - op_dir_loss: 0.1702 - op_feat_acc: 0.5179 - op_bin_acc: 0.2772 - op_dir_acc: 0.9404\n",
      "Epoch 158/7000\n",
      "7111/7111 [==============================] - 6s 886us/step - loss: 3.8298 - op_feat_loss: 1.4481 - op_bin_loss: 3.5319 - op_dir_loss: 0.1658 - op_feat_acc: 0.5236 - op_bin_acc: 0.2801 - op_dir_acc: 0.9407\n",
      "Epoch 159/7000\n",
      "7111/7111 [==============================] - 6s 897us/step - loss: 3.8255 - op_feat_loss: 1.4408 - op_bin_loss: 3.5291 - op_dir_loss: 0.1650 - op_feat_acc: 0.5236 - op_bin_acc: 0.2796 - op_dir_acc: 0.9409\n",
      "Epoch 160/7000\n",
      "7111/7111 [==============================] - 6s 884us/step - loss: 3.8204 - op_feat_loss: 1.4374 - op_bin_loss: 3.5247 - op_dir_loss: 0.1647 - op_feat_acc: 0.5261 - op_bin_acc: 0.2797 - op_dir_acc: 0.9412\n",
      "Epoch 161/7000\n",
      "7111/7111 [==============================] - 7s 933us/step - loss: 3.8185 - op_feat_loss: 1.4364 - op_bin_loss: 3.5229 - op_dir_loss: 0.1660 - op_feat_acc: 0.5224 - op_bin_acc: 0.2791 - op_dir_acc: 0.9401\n",
      "Epoch 162/7000\n",
      "7111/7111 [==============================] - 6s 889us/step - loss: 3.8103 - op_feat_loss: 1.4287 - op_bin_loss: 3.5164 - op_dir_loss: 0.1644 - op_feat_acc: 0.5265 - op_bin_acc: 0.2811 - op_dir_acc: 0.9401\n",
      "Epoch 163/7000\n",
      "7111/7111 [==============================] - 6s 896us/step - loss: 3.7995 - op_feat_loss: 1.4215 - op_bin_loss: 3.5070 - op_dir_loss: 0.1629 - op_feat_acc: 0.5304 - op_bin_acc: 0.2821 - op_dir_acc: 0.9412\n",
      "Epoch 164/7000\n",
      "7111/7111 [==============================] - 7s 939us/step - loss: 3.8011 - op_feat_loss: 1.4209 - op_bin_loss: 3.5086 - op_dir_loss: 0.1648 - op_feat_acc: 0.5302 - op_bin_acc: 0.2780 - op_dir_acc: 0.9395\n",
      "Epoch 165/7000\n",
      "7111/7111 [==============================] - 6s 882us/step - loss: 3.8200 - op_feat_loss: 1.4330 - op_bin_loss: 3.5250 - op_dir_loss: 0.1687 - op_feat_acc: 0.5259 - op_bin_acc: 0.2777 - op_dir_acc: 0.9404\n",
      "Epoch 166/7000\n",
      "7111/7111 [==============================] - 6s 899us/step - loss: 3.7951 - op_feat_loss: 1.4202 - op_bin_loss: 3.5027 - op_dir_loss: 0.1667 - op_feat_acc: 0.5300 - op_bin_acc: 0.2815 - op_dir_acc: 0.9392\n",
      "Epoch 167/7000\n",
      "7111/7111 [==============================] - 6s 889us/step - loss: 3.7933 - op_feat_loss: 1.4174 - op_bin_loss: 3.5016 - op_dir_loss: 0.1655 - op_feat_acc: 0.5265 - op_bin_acc: 0.2807 - op_dir_acc: 0.9404\n",
      "Epoch 168/7000\n",
      "7111/7111 [==============================] - 6s 902us/step - loss: 3.7806 - op_feat_loss: 1.4064 - op_bin_loss: 3.4911 - op_dir_loss: 0.1646 - op_feat_acc: 0.5337 - op_bin_acc: 0.2818 - op_dir_acc: 0.9384\n",
      "Epoch 169/7000\n",
      "7111/7111 [==============================] - 6s 892us/step - loss: 3.7788 - op_feat_loss: 1.4059 - op_bin_loss: 3.4896 - op_dir_loss: 0.1616 - op_feat_acc: 0.5352 - op_bin_acc: 0.2786 - op_dir_acc: 0.9411\n",
      "Epoch 170/7000\n",
      "7111/7111 [==============================] - 6s 912us/step - loss: 3.7749 - op_feat_loss: 1.4041 - op_bin_loss: 3.4860 - op_dir_loss: 0.1610 - op_feat_acc: 0.5319 - op_bin_acc: 0.2801 - op_dir_acc: 0.9404\n",
      "Epoch 171/7000\n",
      "7111/7111 [==============================] - 6s 902us/step - loss: 3.7730 - op_feat_loss: 1.4028 - op_bin_loss: 3.4842 - op_dir_loss: 0.1651 - op_feat_acc: 0.5316 - op_bin_acc: 0.2796 - op_dir_acc: 0.9388\n",
      "Epoch 172/7000\n",
      "7111/7111 [==============================] - 7s 946us/step - loss: 3.7678 - op_feat_loss: 1.3946 - op_bin_loss: 3.4807 - op_dir_loss: 0.1642 - op_feat_acc: 0.5368 - op_bin_acc: 0.2820 - op_dir_acc: 0.9416\n",
      "Epoch 173/7000\n",
      "6784/7111 [===========================>..] - ETA: 0s - loss: 3.7583 - op_feat_loss: 1.3872 - op_bin_loss: 3.4727 - op_dir_loss: 0.1623 - op_feat_acc: 0.5385 - op_bin_acc: 0.2810 - op_dir_acc: 0.9399"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "requests_with_retry encountered retryable exception: ('Connection aborted.', OSError(\"(10060, 'WSAETIMEDOUT')\",)). args: ('https://api.wandb.ai/files/shakkeel_mlsquare/dert/3i9x8q0g/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 335, 'content': ['2020-04-09T08:59:26.583745 7111/7111 [==============================] - 6s 899us/step - loss: 3.7951 - op_feat_loss: 1.4202 - op_bin_loss: 3.5027 - op_dir_loss: 0.1667 - op_feat_acc: 0.5300 - op_bin_acc: 0.2815 - op_dir_acc: 0.9392\\n', '2020-04-09T08:59:26.583745 Epoch 167/7000\\n', '2020-04-09T08:59:32.904819 7111/7111 [==============================] - 6s 889us/step - loss: 3.7933 - op_feat_loss: 1.4174 - op_bin_loss: 3.5016 - op_dir_loss: 0.1655 - op_feat_acc: 0.5265 - op_bin_acc: 0.2807 - op_dir_acc: 0.9404\\n', '2020-04-09T08:59:32.904819 Epoch 168/7000\\n', '2020-04-09T08:59:39.320488 7111/7111 [==============================] - 6s 902us/step - loss: 3.7806 - op_feat_loss: 1.4064 - op_bin_loss: 3.4911 - op_dir_loss: 0.1646 - op_feat_acc: 0.5337 - op_bin_acc: 0.2818 - op_dir_acc: 0.9384\\n', '2020-04-09T08:59:39.320488 Epoch 169/7000\\n', '2020-04-09T08:59:45.666412 7111/7111 [==============================] - 6s 892us/step - loss: 3.7788 - op_feat_loss: 1.4059 - op_bin_loss: 3.4896 - op_dir_loss: 0.1616 - op_feat_acc: 0.5352 - op_bin_acc: 0.2786 - op_dir_acc: 0.9411\\n', '2020-04-09T08:59:45.666412 Epoch 170/7000\\n', '2020-04-09T08:59:52.150780 7111/7111 [==============================] - 6s 912us/step - loss: 3.7749 - op_feat_loss: 1.4041 - op_bin_loss: 3.4860 - op_dir_loss: 0.1610 - op_feat_acc: 0.5319 - op_bin_acc: 0.2801 - op_dir_acc: 0.9404\\n']}, 'wandb-events.jsonl': {'offset': 41, 'content': ['{\"system.gpu.0.gpu\": 30.4, \"system.gpu.0.memory\": 6.33, \"system.gpu.0.memoryAllocated\": 78.74, \"system.gpu.0.temp\": 64.53, \"system.gpu.process.0.gpu\": 30.4, \"system.gpu.process.0.memory\": 6.33, \"system.gpu.process.0.memoryAllocated\": 78.74, \"system.gpu.process.0.temp\": 64.53, \"system.cpu\": 35.0, \"system.memory\": 76.75, \"system.disk\": 35.0, \"system.proc.memory.availableMB\": 1871.09, \"system.proc.memory.rssMB\": 325.4, \"system.proc.memory.percent\": 4.04, \"system.proc.cpu.threads\": 46.0, \"system.network.sent\": 21076456, \"system.network.recv\": 13157786, \"_wandb\": true, \"_timestamp\": 1586422767, \"_runtime\": 1330}\\n']}, 'wandb-history.jsonl': {'offset': 165, 'content': ['{\"epoch\": 165, \"loss\": 3.7950560516520504, \"op_feat_loss\": 1.4201834707919965, \"op_bin_loss\": 3.5026844389712553, \"op_dir_loss\": 0.16669889552681913, \"op_feat_acc\": 0.5300239065481027, \"op_bin_acc\": 0.28153564887297605, \"op_dir_acc\": 0.9392490505484853, \"_runtime\": 1290.4506874084473, \"_timestamp\": 1586422766.536747, \"_step\": 165}\\n', '{\"epoch\": 166, \"loss\": 3.7933139436909826, \"op_feat_loss\": 1.4174055276147057, \"op_bin_loss\": 3.501557177220563, \"op_dir_loss\": 0.16551325791345806, \"op_feat_acc\": 0.5265082266658959, \"op_bin_acc\": 0.2806918857185134, \"op_dir_acc\": 0.940374068613043, \"_runtime\": 1296.780962228775, \"_timestamp\": 1586422772.8670218, \"_step\": 166}\\n', '{\"epoch\": 167, \"loss\": 3.780647360512416, \"op_feat_loss\": 1.406359751169867, \"op_bin_loss\": 3.491143453441379, \"op_dir_loss\": 0.16463928724907737, \"op_feat_acc\": 0.5336802137281937, \"op_bin_acc\": 0.28181690326757597, \"op_dir_acc\": 0.9384052874149778, \"_runtime\": 1303.1808264255524, \"_timestamp\": 1586422779.266886, \"_step\": 167}\\n', '{\"epoch\": 168, \"loss\": 3.778844569138779, \"op_feat_loss\": 1.4058933524102404, \"op_bin_loss\": 3.489585156749864, \"op_dir_loss\": 0.1616145601911797, \"op_feat_acc\": 0.5352271128984933, \"op_bin_acc\": 0.2785824779476098, \"op_dir_acc\": 0.9410772042726434, \"_runtime\": 1309.511218547821, \"_timestamp\": 1586422785.597278, \"_step\": 168}\\n']}, 'wandb-summary.json': {'offset': 0, 'content': ['{\"graph\": {\"_type\": \"graph-file\", \"path\": \"media/graph/graph_summary_122264e4.graph.json\", \"sha256\": \"122264e49047553ba95ef7c227a4082c953bfbec3f4d054bae88621781b4669d\", \"size\": 2065}, \"_timestamp\": 1586422785.597278, \"op_bin_acc\": 0.2785824779476098, \"epoch\": 168, \"loss\": 3.778844569138779, \"_runtime\": 1309.511218547821, \"op_dir_loss\": 0.1616145601911797, \"_step\": 168, \"op_dir_acc\": 0.9410772042726434, \"op_feat_loss\": 1.4058933524102404, \"op_feat_acc\": 0.5352271128984933, \"op_bin_loss\": 3.489585156749864}\\n']}}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7111/7111 [==============================] - 6s 905us/step - loss: 3.7569 - op_feat_loss: 1.3874 - op_bin_loss: 3.4714 - op_dir_loss: 0.1612 - op_feat_acc: 0.5392 - op_bin_acc: 0.2820 - op_dir_acc: 0.9404\n",
      "Epoch 174/7000\n",
      "2176/7111 [========>.....................] - ETA: 4s - loss: 3.7433 - op_feat_loss: 1.3936 - op_bin_loss: 3.4572 - op_dir_loss: 0.1488 - op_feat_acc: 0.5427 - op_bin_acc: 0.2711 - op_dir_acc: 0.9476"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/shakkeel_mlsquare/dert/3i9x8q0g/file_stream (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000021E94F2AF98>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',)). args: ('https://api.wandb.ai/files/shakkeel_mlsquare/dert/3i9x8q0g/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 335, 'content': ['2020-04-09T08:59:26.583745 7111/7111 [==============================] - 6s 899us/step - loss: 3.7951 - op_feat_loss: 1.4202 - op_bin_loss: 3.5027 - op_dir_loss: 0.1667 - op_feat_acc: 0.5300 - op_bin_acc: 0.2815 - op_dir_acc: 0.9392\\n', '2020-04-09T08:59:26.583745 Epoch 167/7000\\n', '2020-04-09T08:59:32.904819 7111/7111 [==============================] - 6s 889us/step - loss: 3.7933 - op_feat_loss: 1.4174 - op_bin_loss: 3.5016 - op_dir_loss: 0.1655 - op_feat_acc: 0.5265 - op_bin_acc: 0.2807 - op_dir_acc: 0.9404\\n', '2020-04-09T08:59:32.904819 Epoch 168/7000\\n', '2020-04-09T08:59:39.320488 7111/7111 [==============================] - 6s 902us/step - loss: 3.7806 - op_feat_loss: 1.4064 - op_bin_loss: 3.4911 - op_dir_loss: 0.1646 - op_feat_acc: 0.5337 - op_bin_acc: 0.2818 - op_dir_acc: 0.9384\\n', '2020-04-09T08:59:39.320488 Epoch 169/7000\\n', '2020-04-09T08:59:45.666412 7111/7111 [==============================] - 6s 892us/step - loss: 3.7788 - op_feat_loss: 1.4059 - op_bin_loss: 3.4896 - op_dir_loss: 0.1616 - op_feat_acc: 0.5352 - op_bin_acc: 0.2786 - op_dir_acc: 0.9411\\n', '2020-04-09T08:59:45.666412 Epoch 170/7000\\n', '2020-04-09T08:59:52.150780 7111/7111 [==============================] - 6s 912us/step - loss: 3.7749 - op_feat_loss: 1.4041 - op_bin_loss: 3.4860 - op_dir_loss: 0.1610 - op_feat_acc: 0.5319 - op_bin_acc: 0.2801 - op_dir_acc: 0.9404\\n']}, 'wandb-events.jsonl': {'offset': 41, 'content': ['{\"system.gpu.0.gpu\": 30.4, \"system.gpu.0.memory\": 6.33, \"system.gpu.0.memoryAllocated\": 78.74, \"system.gpu.0.temp\": 64.53, \"system.gpu.process.0.gpu\": 30.4, \"system.gpu.process.0.memory\": 6.33, \"system.gpu.process.0.memoryAllocated\": 78.74, \"system.gpu.process.0.temp\": 64.53, \"system.cpu\": 35.0, \"system.memory\": 76.75, \"system.disk\": 35.0, \"system.proc.memory.availableMB\": 1871.09, \"system.proc.memory.rssMB\": 325.4, \"system.proc.memory.percent\": 4.04, \"system.proc.cpu.threads\": 46.0, \"system.network.sent\": 21076456, \"system.network.recv\": 13157786, \"_wandb\": true, \"_timestamp\": 1586422767, \"_runtime\": 1330}\\n']}, 'wandb-history.jsonl': {'offset': 165, 'content': ['{\"epoch\": 165, \"loss\": 3.7950560516520504, \"op_feat_loss\": 1.4201834707919965, \"op_bin_loss\": 3.5026844389712553, \"op_dir_loss\": 0.16669889552681913, \"op_feat_acc\": 0.5300239065481027, \"op_bin_acc\": 0.28153564887297605, \"op_dir_acc\": 0.9392490505484853, \"_runtime\": 1290.4506874084473, \"_timestamp\": 1586422766.536747, \"_step\": 165}\\n', '{\"epoch\": 166, \"loss\": 3.7933139436909826, \"op_feat_loss\": 1.4174055276147057, \"op_bin_loss\": 3.501557177220563, \"op_dir_loss\": 0.16551325791345806, \"op_feat_acc\": 0.5265082266658959, \"op_bin_acc\": 0.2806918857185134, \"op_dir_acc\": 0.940374068613043, \"_runtime\": 1296.780962228775, \"_timestamp\": 1586422772.8670218, \"_step\": 166}\\n', '{\"epoch\": 167, \"loss\": 3.780647360512416, \"op_feat_loss\": 1.406359751169867, \"op_bin_loss\": 3.491143453441379, \"op_dir_loss\": 0.16463928724907737, \"op_feat_acc\": 0.5336802137281937, \"op_bin_acc\": 0.28181690326757597, \"op_dir_acc\": 0.9384052874149778, \"_runtime\": 1303.1808264255524, \"_timestamp\": 1586422779.266886, \"_step\": 167}\\n', '{\"epoch\": 168, \"loss\": 3.778844569138779, \"op_feat_loss\": 1.4058933524102404, \"op_bin_loss\": 3.489585156749864, \"op_dir_loss\": 0.1616145601911797, \"op_feat_acc\": 0.5352271128984933, \"op_bin_acc\": 0.2785824779476098, \"op_dir_acc\": 0.9410772042726434, \"_runtime\": 1309.511218547821, \"_timestamp\": 1586422785.597278, \"_step\": 168}\\n']}, 'wandb-summary.json': {'offset': 0, 'content': ['{\"graph\": {\"_type\": \"graph-file\", \"path\": \"media/graph/graph_summary_122264e4.graph.json\", \"sha256\": \"122264e49047553ba95ef7c227a4082c953bfbec3f4d054bae88621781b4669d\", \"size\": 2065}, \"_timestamp\": 1586422785.597278, \"op_bin_acc\": 0.2785824779476098, \"epoch\": 168, \"loss\": 3.778844569138779, \"_runtime\": 1309.511218547821, \"op_dir_loss\": 0.1616145601911797, \"_step\": 168, \"op_dir_acc\": 0.9410772042726434, \"op_feat_loss\": 1.4058933524102404, \"op_feat_acc\": 0.5352271128984933, \"op_bin_loss\": 3.489585156749864}\\n']}}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7040/7111 [============================>.] - ETA: 0s - loss: 3.7587 - op_feat_loss: 1.3891 - op_bin_loss: 3.4728 - op_dir_loss: 0.1613 - op_feat_acc: 0.5401 - op_bin_acc: 0.2790 - op_dir_acc: 0.9415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/shakkeel_mlsquare/dert/3i9x8q0g/file_stream (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000021E94F2AB38>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',)). args: ('https://api.wandb.ai/files/shakkeel_mlsquare/dert/3i9x8q0g/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 335, 'content': ['2020-04-09T08:59:26.583745 7111/7111 [==============================] - 6s 899us/step - loss: 3.7951 - op_feat_loss: 1.4202 - op_bin_loss: 3.5027 - op_dir_loss: 0.1667 - op_feat_acc: 0.5300 - op_bin_acc: 0.2815 - op_dir_acc: 0.9392\\n', '2020-04-09T08:59:26.583745 Epoch 167/7000\\n', '2020-04-09T08:59:32.904819 7111/7111 [==============================] - 6s 889us/step - loss: 3.7933 - op_feat_loss: 1.4174 - op_bin_loss: 3.5016 - op_dir_loss: 0.1655 - op_feat_acc: 0.5265 - op_bin_acc: 0.2807 - op_dir_acc: 0.9404\\n', '2020-04-09T08:59:32.904819 Epoch 168/7000\\n', '2020-04-09T08:59:39.320488 7111/7111 [==============================] - 6s 902us/step - loss: 3.7806 - op_feat_loss: 1.4064 - op_bin_loss: 3.4911 - op_dir_loss: 0.1646 - op_feat_acc: 0.5337 - op_bin_acc: 0.2818 - op_dir_acc: 0.9384\\n', '2020-04-09T08:59:39.320488 Epoch 169/7000\\n', '2020-04-09T08:59:45.666412 7111/7111 [==============================] - 6s 892us/step - loss: 3.7788 - op_feat_loss: 1.4059 - op_bin_loss: 3.4896 - op_dir_loss: 0.1616 - op_feat_acc: 0.5352 - op_bin_acc: 0.2786 - op_dir_acc: 0.9411\\n', '2020-04-09T08:59:45.666412 Epoch 170/7000\\n', '2020-04-09T08:59:52.150780 7111/7111 [==============================] - 6s 912us/step - loss: 3.7749 - op_feat_loss: 1.4041 - op_bin_loss: 3.4860 - op_dir_loss: 0.1610 - op_feat_acc: 0.5319 - op_bin_acc: 0.2801 - op_dir_acc: 0.9404\\n']}, 'wandb-events.jsonl': {'offset': 41, 'content': ['{\"system.gpu.0.gpu\": 30.4, \"system.gpu.0.memory\": 6.33, \"system.gpu.0.memoryAllocated\": 78.74, \"system.gpu.0.temp\": 64.53, \"system.gpu.process.0.gpu\": 30.4, \"system.gpu.process.0.memory\": 6.33, \"system.gpu.process.0.memoryAllocated\": 78.74, \"system.gpu.process.0.temp\": 64.53, \"system.cpu\": 35.0, \"system.memory\": 76.75, \"system.disk\": 35.0, \"system.proc.memory.availableMB\": 1871.09, \"system.proc.memory.rssMB\": 325.4, \"system.proc.memory.percent\": 4.04, \"system.proc.cpu.threads\": 46.0, \"system.network.sent\": 21076456, \"system.network.recv\": 13157786, \"_wandb\": true, \"_timestamp\": 1586422767, \"_runtime\": 1330}\\n']}, 'wandb-history.jsonl': {'offset': 165, 'content': ['{\"epoch\": 165, \"loss\": 3.7950560516520504, \"op_feat_loss\": 1.4201834707919965, \"op_bin_loss\": 3.5026844389712553, \"op_dir_loss\": 0.16669889552681913, \"op_feat_acc\": 0.5300239065481027, \"op_bin_acc\": 0.28153564887297605, \"op_dir_acc\": 0.9392490505484853, \"_runtime\": 1290.4506874084473, \"_timestamp\": 1586422766.536747, \"_step\": 165}\\n', '{\"epoch\": 166, \"loss\": 3.7933139436909826, \"op_feat_loss\": 1.4174055276147057, \"op_bin_loss\": 3.501557177220563, \"op_dir_loss\": 0.16551325791345806, \"op_feat_acc\": 0.5265082266658959, \"op_bin_acc\": 0.2806918857185134, \"op_dir_acc\": 0.940374068613043, \"_runtime\": 1296.780962228775, \"_timestamp\": 1586422772.8670218, \"_step\": 166}\\n', '{\"epoch\": 167, \"loss\": 3.780647360512416, \"op_feat_loss\": 1.406359751169867, \"op_bin_loss\": 3.491143453441379, \"op_dir_loss\": 0.16463928724907737, \"op_feat_acc\": 0.5336802137281937, \"op_bin_acc\": 0.28181690326757597, \"op_dir_acc\": 0.9384052874149778, \"_runtime\": 1303.1808264255524, \"_timestamp\": 1586422779.266886, \"_step\": 167}\\n', '{\"epoch\": 168, \"loss\": 3.778844569138779, \"op_feat_loss\": 1.4058933524102404, \"op_bin_loss\": 3.489585156749864, \"op_dir_loss\": 0.1616145601911797, \"op_feat_acc\": 0.5352271128984933, \"op_bin_acc\": 0.2785824779476098, \"op_dir_acc\": 0.9410772042726434, \"_runtime\": 1309.511218547821, \"_timestamp\": 1586422785.597278, \"_step\": 168}\\n']}, 'wandb-summary.json': {'offset': 0, 'content': ['{\"graph\": {\"_type\": \"graph-file\", \"path\": \"media/graph/graph_summary_122264e4.graph.json\", \"sha256\": \"122264e49047553ba95ef7c227a4082c953bfbec3f4d054bae88621781b4669d\", \"size\": 2065}, \"_timestamp\": 1586422785.597278, \"op_bin_acc\": 0.2785824779476098, \"epoch\": 168, \"loss\": 3.778844569138779, \"_runtime\": 1309.511218547821, \"op_dir_loss\": 0.1616145601911797, \"_step\": 168, \"op_dir_acc\": 0.9410772042726434, \"op_feat_loss\": 1.4058933524102404, \"op_feat_acc\": 0.5352271128984933, \"op_bin_loss\": 3.489585156749864}\\n']}}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7111/7111 [==============================] - 6s 907us/step - loss: 3.7587 - op_feat_loss: 1.3893 - op_bin_loss: 3.4728 - op_dir_loss: 0.1613 - op_feat_acc: 0.5394 - op_bin_acc: 0.2787 - op_dir_acc: 0.9415\n",
      "Epoch 175/7000\n",
      "7111/7111 [==============================] - 7s 993us/step - loss: 3.8387 - op_feat_loss: 1.4419 - op_bin_loss: 3.5402 - op_dir_loss: 0.2016 - op_feat_acc: 0.5219 - op_bin_acc: 0.2685 - op_dir_acc: 0.9253\n",
      "Epoch 176/7000\n",
      "7111/7111 [==============================] - 7s 956us/step - loss: 3.7703 - op_feat_loss: 1.3958 - op_bin_loss: 3.4827 - op_dir_loss: 0.1695 - op_feat_acc: 0.5368 - op_bin_acc: 0.2773 - op_dir_acc: 0.9378\n",
      "Epoch 177/7000\n",
      "7111/7111 [==============================] - 7s 921us/step - loss: 3.7559 - op_feat_loss: 1.3838 - op_bin_loss: 3.4710 - op_dir_loss: 0.1630 - op_feat_acc: 0.5437 - op_bin_acc: 0.2793 - op_dir_acc: 0.9408\n",
      "Epoch 178/7000\n",
      "7111/7111 [==============================] - 6s 896us/step - loss: 3.7398 - op_feat_loss: 1.3706 - op_bin_loss: 3.4578 - op_dir_loss: 0.1583 - op_feat_acc: 0.5462 - op_bin_acc: 0.2770 - op_dir_acc: 0.9405\n",
      "Epoch 179/7000\n",
      "7111/7111 [==============================] - 6s 893us/step - loss: 3.7284 - op_feat_loss: 1.3626 - op_bin_loss: 3.4479 - op_dir_loss: 0.1583 - op_feat_acc: 0.5529 - op_bin_acc: 0.2825 - op_dir_acc: 0.9423\n",
      "Epoch 180/7000\n",
      "7111/7111 [==============================] - 6s 898us/step - loss: 3.7168 - op_feat_loss: 1.3546 - op_bin_loss: 3.4381 - op_dir_loss: 0.1557 - op_feat_acc: 0.5497 - op_bin_acc: 0.2832 - op_dir_acc: 0.9443\n",
      "Epoch 181/7000\n",
      "7111/7111 [==============================] - 6s 899us/step - loss: 3.7108 - op_feat_loss: 1.3515 - op_bin_loss: 3.4327 - op_dir_loss: 0.1555 - op_feat_acc: 0.5573 - op_bin_acc: 0.2820 - op_dir_acc: 0.94333s - loss: 3.7288 - op_feat_loss: 1.3511 - op_bin_loss: 3.4508 - op_dir_loss: 0.1562 - op_fe\n",
      "Epoch 182/7000\n",
      "7111/7111 [==============================] - 6s 893us/step - loss: 3.7100 - op_feat_loss: 1.3518 - op_bin_loss: 3.4318 - op_dir_loss: 0.1561 - op_feat_acc: 0.5552 - op_bin_acc: 0.2824 - op_dir_acc: 0.9428\n",
      "Epoch 183/7000\n",
      "7111/7111 [==============================] - 6s 898us/step - loss: 3.7130 - op_feat_loss: 1.3517 - op_bin_loss: 3.4349 - op_dir_loss: 0.1560 - op_feat_acc: 0.5524 - op_bin_acc: 0.2797 - op_dir_acc: 0.9418\n",
      "Epoch 184/7000\n",
      "7111/7111 [==============================] - 6s 888us/step - loss: 3.7123 - op_feat_loss: 1.3523 - op_bin_loss: 3.4339 - op_dir_loss: 0.1585 - op_feat_acc: 0.5518 - op_bin_acc: 0.2789 - op_dir_acc: 0.9421\n",
      "Epoch 185/7000\n",
      "7111/7111 [==============================] - 6s 895us/step - loss: 3.7128 - op_feat_loss: 1.3529 - op_bin_loss: 3.4342 - op_dir_loss: 0.1599 - op_feat_acc: 0.5439 - op_bin_acc: 0.2818 - op_dir_acc: 0.9394\n",
      "Epoch 186/7000\n",
      "7111/7111 [==============================] - 6s 893us/step - loss: 3.7041 - op_feat_loss: 1.3474 - op_bin_loss: 3.4267 - op_dir_loss: 0.1568 - op_feat_acc: 0.5553 - op_bin_acc: 0.2824 - op_dir_acc: 0.9412\n",
      "Epoch 187/7000\n",
      "7111/7111 [==============================] - 6s 891us/step - loss: 3.6949 - op_feat_loss: 1.3396 - op_bin_loss: 3.4191 - op_dir_loss: 0.1560 - op_feat_acc: 0.5579 - op_bin_acc: 0.2822 - op_dir_acc: 0.94262s - loss: 3.6945 - op_feat_loss: 1.3470 - op_bin_loss: 3.4172 - op_dir_loss: 0.1567 - op_feat_acc\n",
      "Epoch 188/7000\n",
      "7111/7111 [==============================] - 7s 980us/step - loss: 3.6875 - op_feat_loss: 1.3340 - op_bin_loss: 3.4130 - op_dir_loss: 0.1539 - op_feat_acc: 0.5610 - op_bin_acc: 0.2838 - op_dir_acc: 0.9457\n",
      "Epoch 189/7000\n",
      "7111/7111 [==============================] - 6s 895us/step - loss: 3.6885 - op_feat_loss: 1.3378 - op_bin_loss: 3.4132 - op_dir_loss: 0.1553 - op_feat_acc: 0.5541 - op_bin_acc: 0.2811 - op_dir_acc: 0.9442\n",
      "Epoch 190/7000\n",
      "7111/7111 [==============================] - 6s 886us/step - loss: 3.6809 - op_feat_loss: 1.3266 - op_bin_loss: 3.4080 - op_dir_loss: 0.1529 - op_feat_acc: 0.5597 - op_bin_acc: 0.2818 - op_dir_acc: 0.9442\n",
      "Epoch 191/7000\n",
      "7111/7111 [==============================] - 6s 906us/step - loss: 3.6734 - op_feat_loss: 1.3220 - op_bin_loss: 3.4014 - op_dir_loss: 0.1533 - op_feat_acc: 0.5622 - op_bin_acc: 0.2827 - op_dir_acc: 0.9457\n",
      "Epoch 192/7000\n",
      "7111/7111 [==============================] - 6s 893us/step - loss: 3.6777 - op_feat_loss: 1.3266 - op_bin_loss: 3.4046 - op_dir_loss: 0.1555 - op_feat_acc: 0.5601 - op_bin_acc: 0.2842 - op_dir_acc: 0.94334s - loss: 3.6516 - op_feat_loss: 1.3253 - op_bin_loss: 3.37\n",
      "Epoch 193/7000\n",
      "7111/7111 [==============================] - 7s 921us/step - loss: 3.6960 - op_feat_loss: 1.3374 - op_bin_loss: 3.4206 - op_dir_loss: 0.1576 - op_feat_acc: 0.5473 - op_bin_acc: 0.2789 - op_dir_acc: 0.9436\n",
      "Epoch 194/7000\n",
      "7111/7111 [==============================] - 6s 888us/step - loss: 3.6833 - op_feat_loss: 1.3265 - op_bin_loss: 3.4102 - op_dir_loss: 0.1560 - op_feat_acc: 0.5610 - op_bin_acc: 0.2793 - op_dir_acc: 0.9423\n",
      "Epoch 195/7000\n",
      "7111/7111 [==============================] - 6s 884us/step - loss: 3.6657 - op_feat_loss: 1.3159 - op_bin_loss: 3.3949 - op_dir_loss: 0.1529 - op_feat_acc: 0.5659 - op_bin_acc: 0.2797 - op_dir_acc: 0.9454\n",
      "Epoch 196/7000\n",
      "7111/7111 [==============================] - 7s 916us/step - loss: 3.6664 - op_feat_loss: 1.3150 - op_bin_loss: 3.3956 - op_dir_loss: 0.1553 - op_feat_acc: 0.5618 - op_bin_acc: 0.2804 - op_dir_acc: 0.9428\n",
      "Epoch 197/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.6592 - op_feat_loss: 1.3129 - op_bin_loss: 3.3888 - op_dir_loss: 0.1549 - op_feat_acc: 0.5653 - op_bin_acc: 0.2822 - op_dir_acc: 0.9430\n",
      "Epoch 198/7000\n",
      "7111/7111 [==============================] - 6s 893us/step - loss: 3.6917 - op_feat_loss: 1.3378 - op_bin_loss: 3.4160 - op_dir_loss: 0.1624 - op_feat_acc: 0.5542 - op_bin_acc: 0.2817 - op_dir_acc: 0.9390\n",
      "Epoch 199/7000\n",
      "7111/7111 [==============================] - 6s 898us/step - loss: 3.6678 - op_feat_loss: 1.3160 - op_bin_loss: 3.3966 - op_dir_loss: 0.1587 - op_feat_acc: 0.5635 - op_bin_acc: 0.2775 - op_dir_acc: 0.9398\n",
      "Epoch 200/7000\n",
      "7111/7111 [==============================] - 6s 897us/step - loss: 3.6685 - op_feat_loss: 1.3189 - op_bin_loss: 3.3967 - op_dir_loss: 0.1611 - op_feat_acc: 0.5596 - op_bin_acc: 0.2798 - op_dir_acc: 0.9392\n",
      "Epoch 201/7000\n",
      "7111/7111 [==============================] - 6s 890us/step - loss: 3.6516 - op_feat_loss: 1.3064 - op_bin_loss: 3.3825 - op_dir_loss: 0.1558 - op_feat_acc: 0.5615 - op_bin_acc: 0.2824 - op_dir_acc: 0.9425\n",
      "Epoch 202/7000\n",
      "7111/7111 [==============================] - 7s 945us/step - loss: 3.6420 - op_feat_loss: 1.2993 - op_bin_loss: 3.3745 - op_dir_loss: 0.1531 - op_feat_acc: 0.5674 - op_bin_acc: 0.2818 - op_dir_acc: 0.9439\n",
      "Epoch 203/7000\n",
      "7111/7111 [==============================] - 6s 890us/step - loss: 3.6324 - op_feat_loss: 1.2904 - op_bin_loss: 3.3667 - op_dir_loss: 0.1532 - op_feat_acc: 0.5728 - op_bin_acc: 0.2872 - op_dir_acc: 0.9442\n",
      "Epoch 204/7000\n",
      "7111/7111 [==============================] - 7s 997us/step - loss: 3.6542 - op_feat_loss: 1.3115 - op_bin_loss: 3.3841 - op_dir_loss: 0.1568 - op_feat_acc: 0.5597 - op_bin_acc: 0.2811 - op_dir_acc: 0.9402\n",
      "Epoch 205/7000\n",
      "7111/7111 [==============================] - 6s 890us/step - loss: 3.6434 - op_feat_loss: 1.3037 - op_bin_loss: 3.3748 - op_dir_loss: 0.1572 - op_feat_acc: 0.5697 - op_bin_acc: 0.2822 - op_dir_acc: 0.9405\n",
      "Epoch 206/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 3.6528 - op_feat_loss: 1.3118 - op_bin_loss: 3.3821 - op_dir_loss: 0.1672 - op_feat_acc: 0.5611 - op_bin_acc: 0.2782 - op_dir_acc: 0.9378\n",
      "Epoch 207/7000\n",
      "7111/7111 [==============================] - 7s 921us/step - loss: 3.6428 - op_feat_loss: 1.2974 - op_bin_loss: 3.3753 - op_dir_loss: 0.1622 - op_feat_acc: 0.5697 - op_bin_acc: 0.2800 - op_dir_acc: 0.9384\n",
      "Epoch 208/7000\n",
      "7111/7111 [==============================] - 7s 975us/step - loss: 3.6209 - op_feat_loss: 1.2812 - op_bin_loss: 3.3571 - op_dir_loss: 0.1514 - op_feat_acc: 0.5743 - op_bin_acc: 0.2818 - op_dir_acc: 0.9456\n",
      "Epoch 209/7000\n",
      "7111/7111 [==============================] - 7s 918us/step - loss: 3.6093 - op_feat_loss: 1.2734 - op_bin_loss: 3.3470 - op_dir_loss: 0.1513 - op_feat_acc: 0.5773 - op_bin_acc: 0.2852 - op_dir_acc: 0.9463\n",
      "Epoch 210/7000\n",
      "7111/7111 [==============================] - 7s 917us/step - loss: 3.6013 - op_feat_loss: 1.2680 - op_bin_loss: 3.3402 - op_dir_loss: 0.1502 - op_feat_acc: 0.5784 - op_bin_acc: 0.2841 - op_dir_acc: 0.9449\n",
      "Epoch 211/7000\n",
      "7111/7111 [==============================] - 7s 914us/step - loss: 3.5957 - op_feat_loss: 1.2680 - op_bin_loss: 3.3346 - op_dir_loss: 0.1506 - op_feat_acc: 0.5791 - op_bin_acc: 0.2843 - op_dir_acc: 0.9456\n",
      "Epoch 212/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.5955 - op_feat_loss: 1.2649 - op_bin_loss: 3.3351 - op_dir_loss: 0.1486 - op_feat_acc: 0.5836 - op_bin_acc: 0.2849 - op_dir_acc: 0.9460\n",
      "Epoch 213/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.6271 - op_feat_loss: 1.2798 - op_bin_loss: 3.3635 - op_dir_loss: 0.1516 - op_feat_acc: 0.5739 - op_bin_acc: 0.2807 - op_dir_acc: 0.9433\n",
      "Epoch 214/7000\n",
      "7111/7111 [==============================] - 7s 920us/step - loss: 3.5996 - op_feat_loss: 1.2679 - op_bin_loss: 3.3385 - op_dir_loss: 0.1505 - op_feat_acc: 0.5764 - op_bin_acc: 0.2832 - op_dir_acc: 0.9453\n",
      "Epoch 215/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.5870 - op_feat_loss: 1.2547 - op_bin_loss: 3.3286 - op_dir_loss: 0.1496 - op_feat_acc: 0.5853 - op_bin_acc: 0.2848 - op_dir_acc: 0.9426\n",
      "Epoch 216/7000\n",
      "7111/7111 [==============================] - ETA: 0s - loss: 3.5814 - op_feat_loss: 1.2543 - op_bin_loss: 3.3232 - op_dir_loss: 0.1468 - op_feat_acc: 0.5886 - op_bin_acc: 0.2854 - op_dir_acc: 0.94 - 6s 906us/step - loss: 3.5844 - op_feat_loss: 1.2543 - op_bin_loss: 3.3261 - op_dir_loss: 0.1478 - op_feat_acc: 0.5885 - op_bin_acc: 0.2849 - op_dir_acc: 0.9453\n",
      "Epoch 217/7000\n",
      "7111/7111 [==============================] - 7s 979us/step - loss: 3.5868 - op_feat_loss: 1.2562 - op_bin_loss: 3.3281 - op_dir_loss: 0.1489 - op_feat_acc: 0.5868 - op_bin_acc: 0.2834 - op_dir_acc: 0.9443\n",
      "Epoch 218/7000\n",
      "7111/7111 [==============================] - 6s 832us/step - loss: 3.5793 - op_feat_loss: 1.2509 - op_bin_loss: 3.3217 - op_dir_loss: 0.1495 - op_feat_acc: 0.5826 - op_bin_acc: 0.2849 - op_dir_acc: 0.9443\n",
      "Epoch 219/7000\n",
      "7111/7111 [==============================] - 6s 839us/step - loss: 3.5737 - op_feat_loss: 1.2482 - op_bin_loss: 3.3167 - op_dir_loss: 0.1478 - op_feat_acc: 0.5846 - op_bin_acc: 0.2836 - op_dir_acc: 0.9446\n",
      "Epoch 220/7000\n",
      "7111/7111 [==============================] - 6s 877us/step - loss: 3.5733 - op_feat_loss: 1.2464 - op_bin_loss: 3.3166 - op_dir_loss: 0.1487 - op_feat_acc: 0.5874 - op_bin_acc: 0.2867 - op_dir_acc: 0.94454s - loss: 3.6715 - op_feat_loss: 1.2783 - op_bin_loss: \n",
      "Epoch 221/7000\n",
      "7111/7111 [==============================] - 6s 851us/step - loss: 3.5640 - op_feat_loss: 1.2400 - op_bin_loss: 3.3086 - op_dir_loss: 0.1482 - op_feat_acc: 0.5868 - op_bin_acc: 0.2855 - op_dir_acc: 0.9454\n",
      "Epoch 222/7000\n",
      "7111/7111 [==============================] - 6s 892us/step - loss: 3.5607 - op_feat_loss: 1.2371 - op_bin_loss: 3.3059 - op_dir_loss: 0.1470 - op_feat_acc: 0.5882 - op_bin_acc: 0.2842 - op_dir_acc: 0.9446\n",
      "Epoch 223/7000\n",
      "7111/7111 [==============================] - 7s 940us/step - loss: 3.5862 - op_feat_loss: 1.2576 - op_bin_loss: 3.3266 - op_dir_loss: 0.1605 - op_feat_acc: 0.5877 - op_bin_acc: 0.2821 - op_dir_acc: 0.9423\n",
      "Epoch 224/7000\n",
      "7111/7111 [==============================] - 6s 858us/step - loss: 3.6558 - op_feat_loss: 1.2998 - op_bin_loss: 3.3875 - op_dir_loss: 0.1683 - op_feat_acc: 0.5641 - op_bin_acc: 0.2761 - op_dir_acc: 0.9367\n",
      "Epoch 225/7000\n",
      "7111/7111 [==============================] - 7s 939us/step - loss: 3.5959 - op_feat_loss: 1.2652 - op_bin_loss: 3.3352 - op_dir_loss: 0.1543 - op_feat_acc: 0.5776 - op_bin_acc: 0.2806 - op_dir_acc: 0.9414\n",
      "Epoch 226/7000\n",
      "7111/7111 [==============================] - 6s 876us/step - loss: 3.5911 - op_feat_loss: 1.2589 - op_bin_loss: 3.3317 - op_dir_loss: 0.1542 - op_feat_acc: 0.5759 - op_bin_acc: 0.2836 - op_dir_acc: 0.9426\n",
      "Epoch 227/7000\n",
      "7111/7111 [==============================] - 6s 848us/step - loss: 3.5751 - op_feat_loss: 1.2496 - op_bin_loss: 3.3176 - op_dir_loss: 0.1524 - op_feat_acc: 0.5790 - op_bin_acc: 0.2832 - op_dir_acc: 0.9428\n",
      "Epoch 228/7000\n",
      "7111/7111 [==============================] - 6s 854us/step - loss: 3.5602 - op_feat_loss: 1.2403 - op_bin_loss: 3.3046 - op_dir_loss: 0.1519 - op_feat_acc: 0.5857 - op_bin_acc: 0.2863 - op_dir_acc: 0.9426\n",
      "Epoch 229/7000\n",
      "7111/7111 [==============================] - 7s 924us/step - loss: 3.5481 - op_feat_loss: 1.2276 - op_bin_loss: 3.2951 - op_dir_loss: 0.1485 - op_feat_acc: 0.5927 - op_bin_acc: 0.2863 - op_dir_acc: 0.94453s - loss: 3.5787 - op_feat_loss: 1.2247 - op_bin_loss: 3.3267 - op_dir_loss: 0.1420 -\n",
      "Epoch 230/7000\n",
      "7111/7111 [==============================] - 7s 921us/step - loss: 3.5465 - op_feat_loss: 1.2300 - op_bin_loss: 3.2930 - op_dir_loss: 0.1490 - op_feat_acc: 0.5870 - op_bin_acc: 0.2841 - op_dir_acc: 0.9445\n",
      "Epoch 231/7000\n",
      "7111/7111 [==============================] - 6s 875us/step - loss: 3.5332 - op_feat_loss: 1.2207 - op_bin_loss: 3.2817 - op_dir_loss: 0.1465 - op_feat_acc: 0.5950 - op_bin_acc: 0.2886 - op_dir_acc: 0.9470\n",
      "Epoch 232/7000\n",
      "7111/7111 [==============================] - 7s 982us/step - loss: 3.5383 - op_feat_loss: 1.2224 - op_bin_loss: 3.2863 - op_dir_loss: 0.1491 - op_feat_acc: 0.5957 - op_bin_acc: 0.2886 - op_dir_acc: 0.9447\n",
      "Epoch 233/7000\n",
      "7111/7111 [==============================] - 6s 898us/step - loss: 3.5323 - op_feat_loss: 1.2192 - op_bin_loss: 3.2811 - op_dir_loss: 0.1472 - op_feat_acc: 0.5901 - op_bin_acc: 0.2859 - op_dir_acc: 0.9466\n",
      "Epoch 234/7000\n",
      "7111/7111 [==============================] - 7s 961us/step - loss: 3.5244 - op_feat_loss: 1.2118 - op_bin_loss: 3.2747 - op_dir_loss: 0.1459 - op_feat_acc: 0.5977 - op_bin_acc: 0.2883 - op_dir_acc: 0.9449\n",
      "Epoch 235/7000\n",
      "7111/7111 [==============================] - 7s 936us/step - loss: 3.5221 - op_feat_loss: 1.2105 - op_bin_loss: 3.2728 - op_dir_loss: 0.1450 - op_feat_acc: 0.5984 - op_bin_acc: 0.2877 - op_dir_acc: 0.9471\n",
      "Epoch 236/7000\n",
      "7111/7111 [==============================] - 7s 941us/step - loss: 3.5218 - op_feat_loss: 1.2111 - op_bin_loss: 3.2724 - op_dir_loss: 0.1445 - op_feat_acc: 0.5994 - op_bin_acc: 0.2874 - op_dir_acc: 0.9463\n",
      "Epoch 237/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.5247 - op_feat_loss: 1.2149 - op_bin_loss: 3.2744 - op_dir_loss: 0.1466 - op_feat_acc: 0.5934 - op_bin_acc: 0.2876 - op_dir_acc: 0.9447\n",
      "Epoch 238/7000\n",
      "7111/7111 [==============================] - 7s 919us/step - loss: 3.5187 - op_feat_loss: 1.2081 - op_bin_loss: 3.2697 - op_dir_loss: 0.1477 - op_feat_acc: 0.6013 - op_bin_acc: 0.2874 - op_dir_acc: 0.9453\n",
      "Epoch 239/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.5416 - op_feat_loss: 1.2219 - op_bin_loss: 3.2897 - op_dir_loss: 0.1516 - op_feat_acc: 0.5923 - op_bin_acc: 0.2824 - op_dir_acc: 0.9440\n",
      "Epoch 240/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 3.5577 - op_feat_loss: 1.2373 - op_bin_loss: 3.3025 - op_dir_loss: 0.1545 - op_feat_acc: 0.5805 - op_bin_acc: 0.2825 - op_dir_acc: 0.9426\n",
      "Epoch 241/7000\n",
      "7111/7111 [==============================] - 6s 829us/step - loss: 3.5345 - op_feat_loss: 1.2192 - op_bin_loss: 3.2831 - op_dir_loss: 0.1509 - op_feat_acc: 0.5892 - op_bin_acc: 0.2873 - op_dir_acc: 0.9436\n",
      "Epoch 242/7000\n",
      "7111/7111 [==============================] - 7s 920us/step - loss: 3.5148 - op_feat_loss: 1.2080 - op_bin_loss: 3.2658 - op_dir_loss: 0.1476 - op_feat_acc: 0.5944 - op_bin_acc: 0.2855 - op_dir_acc: 0.9452\n",
      "Epoch 243/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.5052 - op_feat_loss: 1.2032 - op_bin_loss: 3.2573 - op_dir_loss: 0.1458 - op_feat_acc: 0.5996 - op_bin_acc: 0.2883 - op_dir_acc: 0.9450\n",
      "Epoch 244/7000\n",
      "7111/7111 [==============================] - 7s 933us/step - loss: 3.5013 - op_feat_loss: 1.2007 - op_bin_loss: 3.2538 - op_dir_loss: 0.1467 - op_feat_acc: 0.6013 - op_bin_acc: 0.2912 - op_dir_acc: 0.9453\n",
      "Epoch 245/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7111/7111 [==============================] - 7s 929us/step - loss: 3.5236 - op_feat_loss: 1.2136 - op_bin_loss: 3.2734 - op_dir_loss: 0.1494 - op_feat_acc: 0.5957 - op_bin_acc: 0.2842 - op_dir_acc: 0.94401s - loss: 3.5090 - op_feat_loss: 1.2201 - op_bin_loss: 3.2575 - op_dir_loss: 0.1495 - op_feat_acc: 0.5912 - op_bin_ac\n",
      "Epoch 246/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.5649 - op_feat_loss: 1.2447 - op_bin_loss: 3.3079 - op_dir_loss: 0.1605 - op_feat_acc: 0.5859 - op_bin_acc: 0.2791 - op_dir_acc: 0.9388\n",
      "Epoch 247/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.5133 - op_feat_loss: 1.2039 - op_bin_loss: 3.2651 - op_dir_loss: 0.1478 - op_feat_acc: 0.5925 - op_bin_acc: 0.2866 - op_dir_acc: 0.9460\n",
      "Epoch 248/7000\n",
      "7111/7111 [==============================] - 6s 893us/step - loss: 3.5020 - op_feat_loss: 1.1979 - op_bin_loss: 3.2550 - op_dir_loss: 0.1477 - op_feat_acc: 0.6024 - op_bin_acc: 0.2874 - op_dir_acc: 0.9440\n",
      "Epoch 249/7000\n",
      "7111/7111 [==============================] - 6s 867us/step - loss: 3.4879 - op_feat_loss: 1.1948 - op_bin_loss: 3.2416 - op_dir_loss: 0.1477 - op_feat_acc: 0.6016 - op_bin_acc: 0.2867 - op_dir_acc: 0.9452\n",
      "Epoch 250/7000\n",
      "7111/7111 [==============================] - 7s 920us/step - loss: 3.4768 - op_feat_loss: 1.1880 - op_bin_loss: 3.2319 - op_dir_loss: 0.1458 - op_feat_acc: 0.6040 - op_bin_acc: 0.2911 - op_dir_acc: 0.94644s - loss: 3.4061 - op_feat_loss: 1.2106 - op_bin_loss: 3.1572\n",
      "Epoch 251/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 3.4696 - op_feat_loss: 1.1828 - op_bin_loss: 3.2258 - op_dir_loss: 0.1444 - op_feat_acc: 0.6086 - op_bin_acc: 0.2941 - op_dir_acc: 0.9463\n",
      "Epoch 252/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 3.4616 - op_feat_loss: 1.1785 - op_bin_loss: 3.2188 - op_dir_loss: 0.1434 - op_feat_acc: 0.6138 - op_bin_acc: 0.2907 - op_dir_acc: 0.9466\n",
      "Epoch 253/7000\n",
      "7111/7111 [==============================] - 6s 912us/step - loss: 3.4577 - op_feat_loss: 1.1799 - op_bin_loss: 3.2145 - op_dir_loss: 0.1443 - op_feat_acc: 0.6119 - op_bin_acc: 0.2873 - op_dir_acc: 0.9453\n",
      "Epoch 254/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.4543 - op_feat_loss: 1.1773 - op_bin_loss: 3.2116 - op_dir_loss: 0.1432 - op_feat_acc: 0.6109 - op_bin_acc: 0.2893 - op_dir_acc: 0.9468\n",
      "Epoch 255/7000\n",
      "7111/7111 [==============================] - 7s 987us/step - loss: 3.4470 - op_feat_loss: 1.1728 - op_bin_loss: 3.2053 - op_dir_loss: 0.1438 - op_feat_acc: 0.6131 - op_bin_acc: 0.2888 - op_dir_acc: 0.9456\n",
      "Epoch 256/7000\n",
      "7111/7111 [==============================] - 7s 990us/step - loss: 3.4537 - op_feat_loss: 1.1777 - op_bin_loss: 3.2109 - op_dir_loss: 0.1457 - op_feat_acc: 0.6081 - op_bin_acc: 0.2891 - op_dir_acc: 0.9464\n",
      "Epoch 257/7000\n",
      "7111/7111 [==============================] - 6s 848us/step - loss: 3.4497 - op_feat_loss: 1.1751 - op_bin_loss: 3.2074 - op_dir_loss: 0.1464 - op_feat_acc: 0.6060 - op_bin_acc: 0.2912 - op_dir_acc: 0.9439\n",
      "Epoch 258/7000\n",
      "7111/7111 [==============================] - 7s 939us/step - loss: 3.4482 - op_feat_loss: 1.1745 - op_bin_loss: 3.2061 - op_dir_loss: 0.1449 - op_feat_acc: 0.6069 - op_bin_acc: 0.2949 - op_dir_acc: 0.9466\n",
      "Epoch 259/7000\n",
      "7111/7111 [==============================] - 7s 937us/step - loss: 3.4429 - op_feat_loss: 1.1731 - op_bin_loss: 3.2010 - op_dir_loss: 0.1463 - op_feat_acc: 0.6124 - op_bin_acc: 0.2943 - op_dir_acc: 0.9453\n",
      "Epoch 260/7000\n",
      "7111/7111 [==============================] - 6s 888us/step - loss: 3.4353 - op_feat_loss: 1.1677 - op_bin_loss: 3.1946 - op_dir_loss: 0.1431 - op_feat_acc: 0.6112 - op_bin_acc: 0.2936 - op_dir_acc: 0.9471\n",
      "Epoch 261/7000\n",
      "7111/7111 [==============================] - 6s 842us/step - loss: 3.4342 - op_feat_loss: 1.1652 - op_bin_loss: 3.1940 - op_dir_loss: 0.1444 - op_feat_acc: 0.6151 - op_bin_acc: 0.2941 - op_dir_acc: 0.9440\n",
      "Epoch 262/7000\n",
      "7111/7111 [==============================] - 6s 895us/step - loss: 3.4313 - op_feat_loss: 1.1681 - op_bin_loss: 3.1904 - op_dir_loss: 0.1469 - op_feat_acc: 0.6109 - op_bin_acc: 0.2932 - op_dir_acc: 0.9464\n",
      "Epoch 263/7000\n",
      "7111/7111 [==============================] - 6s 880us/step - loss: 3.4662 - op_feat_loss: 1.1828 - op_bin_loss: 3.2220 - op_dir_loss: 0.1534 - op_feat_acc: 0.6058 - op_bin_acc: 0.2894 - op_dir_acc: 0.9409\n",
      "Epoch 264/7000\n",
      "7111/7111 [==============================] - 6s 860us/step - loss: 3.5042 - op_feat_loss: 1.2110 - op_bin_loss: 3.2540 - op_dir_loss: 0.1618 - op_feat_acc: 0.5891 - op_bin_acc: 0.2866 - op_dir_acc: 0.9411\n",
      "Epoch 265/7000\n",
      "7111/7111 [==============================] - 6s 832us/step - loss: 3.5118 - op_feat_loss: 1.2182 - op_bin_loss: 3.2599 - op_dir_loss: 0.1648 - op_feat_acc: 0.5925 - op_bin_acc: 0.2872 - op_dir_acc: 0.9401\n",
      "Epoch 266/7000\n",
      "7111/7111 [==============================] - 6s 836us/step - loss: 3.4991 - op_feat_loss: 1.2057 - op_bin_loss: 3.2500 - op_dir_loss: 0.1581 - op_feat_acc: 0.5908 - op_bin_acc: 0.2886 - op_dir_acc: 0.9394\n",
      "Epoch 267/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 3.4358 - op_feat_loss: 1.1735 - op_bin_loss: 3.1936 - op_dir_loss: 0.1498 - op_feat_acc: 0.6086 - op_bin_acc: 0.2941 - op_dir_acc: 0.9435\n",
      "Epoch 268/7000\n",
      "7111/7111 [==============================] - 6s 835us/step - loss: 3.4185 - op_feat_loss: 1.1631 - op_bin_loss: 3.1784 - op_dir_loss: 0.1495 - op_feat_acc: 0.6102 - op_bin_acc: 0.2981 - op_dir_acc: 0.9447\n",
      "Epoch 269/7000\n",
      "7111/7111 [==============================] - 7s 942us/step - loss: 3.4076 - op_feat_loss: 1.1582 - op_bin_loss: 3.1687 - op_dir_loss: 0.1449 - op_feat_acc: 0.6137 - op_bin_acc: 0.2971 - op_dir_acc: 0.9454\n",
      "Epoch 270/7000\n",
      "7111/7111 [==============================] - 6s 861us/step - loss: 3.3967 - op_feat_loss: 1.1485 - op_bin_loss: 3.1598 - op_dir_loss: 0.1442 - op_feat_acc: 0.6162 - op_bin_acc: 0.2995 - op_dir_acc: 0.94611s - loss: 3.3885 - op_feat_loss: 1.1345 - op_bin_loss: 3.1546 - op_dir_loss: 0.1414 - op_feat_acc: 0.6158 - op_bi\n",
      "Epoch 271/7000\n",
      "7111/7111 [==============================] - 6s 877us/step - loss: 3.3902 - op_feat_loss: 1.1480 - op_bin_loss: 3.1534 - op_dir_loss: 0.1445 - op_feat_acc: 0.6234 - op_bin_acc: 0.2988 - op_dir_acc: 0.9468\n",
      "Epoch 272/7000\n",
      "7111/7111 [==============================] - 6s 830us/step - loss: 3.3853 - op_feat_loss: 1.1438 - op_bin_loss: 3.1493 - op_dir_loss: 0.1439 - op_feat_acc: 0.6212 - op_bin_acc: 0.3012 - op_dir_acc: 0.9460\n",
      "Epoch 273/7000\n",
      "7111/7111 [==============================] - 6s 832us/step - loss: 3.3862 - op_feat_loss: 1.1451 - op_bin_loss: 3.1500 - op_dir_loss: 0.1446 - op_feat_acc: 0.6238 - op_bin_acc: 0.2967 - op_dir_acc: 0.9443\n",
      "Epoch 274/7000\n",
      "7111/7111 [==============================] - 6s 836us/step - loss: 3.3749 - op_feat_loss: 1.1384 - op_bin_loss: 3.1400 - op_dir_loss: 0.1431 - op_feat_acc: 0.6247 - op_bin_acc: 0.2994 - op_dir_acc: 0.9456\n",
      "Epoch 275/7000\n",
      "7111/7111 [==============================] - 6s 858us/step - loss: 3.3775 - op_feat_loss: 1.1402 - op_bin_loss: 3.1423 - op_dir_loss: 0.1437 - op_feat_acc: 0.6237 - op_bin_acc: 0.3026 - op_dir_acc: 0.9464\n",
      "Epoch 276/7000\n",
      "7111/7111 [==============================] - 6s 830us/step - loss: 3.3711 - op_feat_loss: 1.1396 - op_bin_loss: 3.1360 - op_dir_loss: 0.1430 - op_feat_acc: 0.6254 - op_bin_acc: 0.3090 - op_dir_acc: 0.94684s - loss: 3.3525 - op_feat_loss: 1.1455 - op_bin_loss: 3.11\n",
      "Epoch 277/7000\n",
      "7111/7111 [==============================] - 6s 827us/step - loss: 3.3665 - op_feat_loss: 1.1345 - op_bin_loss: 3.1324 - op_dir_loss: 0.1434 - op_feat_acc: 0.6249 - op_bin_acc: 0.3122 - op_dir_acc: 0.9453\n",
      "Epoch 278/7000\n",
      "7111/7111 [==============================] - 6s 858us/step - loss: 3.3654 - op_feat_loss: 1.1351 - op_bin_loss: 3.1313 - op_dir_loss: 0.1419 - op_feat_acc: 0.6269 - op_bin_acc: 0.3128 - op_dir_acc: 0.9466\n",
      "Epoch 279/7000\n",
      "7111/7111 [==============================] - 6s 833us/step - loss: 3.3620 - op_feat_loss: 1.1326 - op_bin_loss: 3.1284 - op_dir_loss: 0.1428 - op_feat_acc: 0.6269 - op_bin_acc: 0.3109 - op_dir_acc: 0.9480\n",
      "Epoch 280/7000\n",
      "7111/7111 [==============================] - 6s 840us/step - loss: 3.3880 - op_feat_loss: 1.1529 - op_bin_loss: 3.1502 - op_dir_loss: 0.1450 - op_feat_acc: 0.6172 - op_bin_acc: 0.3059 - op_dir_acc: 0.9456\n",
      "Epoch 281/7000\n",
      "7111/7111 [==============================] - 6s 812us/step - loss: 3.3714 - op_feat_loss: 1.1391 - op_bin_loss: 3.1364 - op_dir_loss: 0.1432 - op_feat_acc: 0.6213 - op_bin_acc: 0.3101 - op_dir_acc: 0.9456\n",
      "Epoch 282/7000\n",
      "7111/7111 [==============================] - 6s 816us/step - loss: 3.3621 - op_feat_loss: 1.1380 - op_bin_loss: 3.1272 - op_dir_loss: 0.1446 - op_feat_acc: 0.6213 - op_bin_acc: 0.3109 - op_dir_acc: 0.94683s - loss: 3.3972 - op_feat_loss: 1.1635 - op_bin_loss: 3.1569 - op_dir_loss\n",
      "Epoch 283/7000\n",
      "7111/7111 [==============================] - 6s 820us/step - loss: 3.3599 - op_feat_loss: 1.1369 - op_bin_loss: 3.1253 - op_dir_loss: 0.1447 - op_feat_acc: 0.6206 - op_bin_acc: 0.3112 - op_dir_acc: 0.9453\n",
      "Epoch 284/7000\n",
      "7111/7111 [==============================] - 6s 825us/step - loss: 3.3619 - op_feat_loss: 1.1347 - op_bin_loss: 3.1276 - op_dir_loss: 0.1469 - op_feat_acc: 0.6247 - op_bin_acc: 0.3101 - op_dir_acc: 0.9456\n",
      "Epoch 285/7000\n",
      "7111/7111 [==============================] - 6s 850us/step - loss: 3.3742 - op_feat_loss: 1.1384 - op_bin_loss: 3.1393 - op_dir_loss: 0.1438 - op_feat_acc: 0.6168 - op_bin_acc: 0.3087 - op_dir_acc: 0.94704s - loss: 3.4232 - op_feat_loss: 1.1759 - op_bin_loss: 3.1801 - op_\n",
      "Epoch 286/7000\n",
      "7111/7111 [==============================] - 6s 839us/step - loss: 3.3724 - op_feat_loss: 1.1404 - op_bin_loss: 3.1371 - op_dir_loss: 0.1447 - op_feat_acc: 0.6179 - op_bin_acc: 0.3119 - op_dir_acc: 0.9454\n",
      "Epoch 287/7000\n",
      "7111/7111 [==============================] - 6s 832us/step - loss: 3.3662 - op_feat_loss: 1.1349 - op_bin_loss: 3.1320 - op_dir_loss: 0.1435 - op_feat_acc: 0.6266 - op_bin_acc: 0.3125 - op_dir_acc: 0.9461\n",
      "Epoch 288/7000\n",
      "7111/7111 [==============================] - 6s 858us/step - loss: 3.3450 - op_feat_loss: 1.1282 - op_bin_loss: 3.1122 - op_dir_loss: 0.1428 - op_feat_acc: 0.6251 - op_bin_acc: 0.3189 - op_dir_acc: 0.9460\n",
      "Epoch 289/7000\n",
      "7111/7111 [==============================] - 6s 853us/step - loss: 3.3377 - op_feat_loss: 1.1242 - op_bin_loss: 3.1057 - op_dir_loss: 0.1438 - op_feat_acc: 0.6254 - op_bin_acc: 0.3180 - op_dir_acc: 0.9471\n",
      "Epoch 290/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 3.3373 - op_feat_loss: 1.1254 - op_bin_loss: 3.1050 - op_dir_loss: 0.1441 - op_feat_acc: 0.6247 - op_bin_acc: 0.3122 - op_dir_acc: 0.9457\n",
      "Epoch 291/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 3.3423 - op_feat_loss: 1.1237 - op_bin_loss: 3.1103 - op_dir_loss: 0.1454 - op_feat_acc: 0.6278 - op_bin_acc: 0.3158 - op_dir_acc: 0.9464\n",
      "Epoch 292/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 3.3550 - op_feat_loss: 1.1328 - op_bin_loss: 3.1213 - op_dir_loss: 0.1442 - op_feat_acc: 0.6221 - op_bin_acc: 0.3135 - op_dir_acc: 0.9440\n",
      "Epoch 293/7000\n",
      "7111/7111 [==============================] - 6s 833us/step - loss: 3.3298 - op_feat_loss: 1.1197 - op_bin_loss: 3.0987 - op_dir_loss: 0.1430 - op_feat_acc: 0.6307 - op_bin_acc: 0.3187 - op_dir_acc: 0.94782s - loss: 3.3271 - op_feat_loss: 1.1185 - op_bin_loss: 3.0968 - op_dir_loss: 0.1329 - op_feat_acc\n",
      "Epoch 294/7000\n",
      "7111/7111 [==============================] - 6s 824us/step - loss: 3.3287 - op_feat_loss: 1.1184 - op_bin_loss: 3.0979 - op_dir_loss: 0.1421 - op_feat_acc: 0.6300 - op_bin_acc: 0.3174 - op_dir_acc: 0.94672s - loss: 3.3459 - op_feat_loss: 1.1256 - op_bin_loss: 3.1138 - op_dir_loss: 0.1383 - op_feat_acc: 0.\n",
      "Epoch 295/7000\n",
      "7111/7111 [==============================] - 6s 850us/step - loss: 3.3273 - op_feat_loss: 1.1220 - op_bin_loss: 3.0959 - op_dir_loss: 0.1410 - op_feat_acc: 0.6279 - op_bin_acc: 0.3203 - op_dir_acc: 0.9475\n",
      "Epoch 296/7000\n",
      "7111/7111 [==============================] - 6s 837us/step - loss: 3.3116 - op_feat_loss: 1.1103 - op_bin_loss: 3.0824 - op_dir_loss: 0.1418 - op_feat_acc: 0.6306 - op_bin_acc: 0.3232 - op_dir_acc: 0.9473\n",
      "Epoch 297/7000\n",
      "7111/7111 [==============================] - 6s 850us/step - loss: 3.3127 - op_feat_loss: 1.1103 - op_bin_loss: 3.0835 - op_dir_loss: 0.1408 - op_feat_acc: 0.6310 - op_bin_acc: 0.3220 - op_dir_acc: 0.9491\n",
      "Epoch 298/7000\n",
      "7111/7111 [==============================] - 6s 822us/step - loss: 3.3081 - op_feat_loss: 1.1108 - op_bin_loss: 3.0788 - op_dir_loss: 0.1431 - op_feat_acc: 0.6299 - op_bin_acc: 0.3246 - op_dir_acc: 0.9467\n",
      "Epoch 299/7000\n",
      "7111/7111 [==============================] - 6s 908us/step - loss: 3.2954 - op_feat_loss: 1.1021 - op_bin_loss: 3.0678 - op_dir_loss: 0.1425 - op_feat_acc: 0.6373 - op_bin_acc: 0.3247 - op_dir_acc: 0.9457\n",
      "Epoch 300/7000\n",
      "7111/7111 [==============================] - 6s 843us/step - loss: 3.2937 - op_feat_loss: 1.1035 - op_bin_loss: 3.0660 - op_dir_loss: 0.1404 - op_feat_acc: 0.6349 - op_bin_acc: 0.3264 - op_dir_acc: 0.9487\n",
      "Epoch 301/7000\n",
      "7111/7111 [==============================] - 6s 833us/step - loss: 3.2893 - op_feat_loss: 1.1014 - op_bin_loss: 3.0620 - op_dir_loss: 0.1395 - op_feat_acc: 0.6328 - op_bin_acc: 0.3285 - op_dir_acc: 0.9473\n",
      "Epoch 302/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 3.2942 - op_feat_loss: 1.1041 - op_bin_loss: 3.0663 - op_dir_loss: 0.1406 - op_feat_acc: 0.6311 - op_bin_acc: 0.3275 - op_dir_acc: 0.9464\n",
      "Epoch 303/7000\n",
      "7111/7111 [==============================] - 6s 818us/step - loss: 3.2914 - op_feat_loss: 1.0990 - op_bin_loss: 3.0646 - op_dir_loss: 0.1414 - op_feat_acc: 0.6368 - op_bin_acc: 0.3213 - op_dir_acc: 0.9453\n",
      "Epoch 304/7000\n",
      "7111/7111 [==============================] - 6s 829us/step - loss: 3.2825 - op_feat_loss: 1.0971 - op_bin_loss: 3.0560 - op_dir_loss: 0.1414 - op_feat_acc: 0.6370 - op_bin_acc: 0.3271 - op_dir_acc: 0.9468\n",
      "Epoch 305/7000\n",
      "7111/7111 [==============================] - 6s 827us/step - loss: 3.2821 - op_feat_loss: 1.0969 - op_bin_loss: 3.0557 - op_dir_loss: 0.1402 - op_feat_acc: 0.6359 - op_bin_acc: 0.3241 - op_dir_acc: 0.9466\n",
      "Epoch 306/7000\n",
      "7111/7111 [==============================] - 6s 870us/step - loss: 3.2752 - op_feat_loss: 1.0951 - op_bin_loss: 3.0491 - op_dir_loss: 0.1410 - op_feat_acc: 0.6392 - op_bin_acc: 0.3261 - op_dir_acc: 0.9466\n",
      "Epoch 307/7000\n",
      "7111/7111 [==============================] - 6s 844us/step - loss: 3.2728 - op_feat_loss: 1.0924 - op_bin_loss: 3.0473 - op_dir_loss: 0.1399 - op_feat_acc: 0.6373 - op_bin_acc: 0.3271 - op_dir_acc: 0.9468\n",
      "Epoch 308/7000\n",
      "7111/7111 [==============================] - 6s 815us/step - loss: 3.2878 - op_feat_loss: 1.0972 - op_bin_loss: 3.0611 - op_dir_loss: 0.1440 - op_feat_acc: 0.6376 - op_bin_acc: 0.3219 - op_dir_acc: 0.94474s - loss: 3.3371 - op_feat_loss: 1.1006 - op_bin_loss: 3.1100 - o\n",
      "Epoch 309/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 3.2762 - op_feat_loss: 1.0926 - op_bin_loss: 3.0507 - op_dir_loss: 0.1401 - op_feat_acc: 0.6380 - op_bin_acc: 0.3291 - op_dir_acc: 0.94754s - loss: 3.2821 - op_feat_loss: 1.0840 - op_bin_loss: 3.\n",
      "Epoch 310/7000\n",
      "7111/7111 [==============================] - 6s 854us/step - loss: 3.2710 - op_feat_loss: 1.0892 - op_bin_loss: 3.0462 - op_dir_loss: 0.1400 - op_feat_acc: 0.6428 - op_bin_acc: 0.3271 - op_dir_acc: 0.9463\n",
      "Epoch 311/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 3.2602 - op_feat_loss: 1.0872 - op_bin_loss: 3.0357 - op_dir_loss: 0.1405 - op_feat_acc: 0.6389 - op_bin_acc: 0.3303 - op_dir_acc: 0.9449\n",
      "Epoch 312/7000\n",
      "7111/7111 [==============================] - 6s 851us/step - loss: 3.2743 - op_feat_loss: 1.0916 - op_bin_loss: 3.0489 - op_dir_loss: 0.1409 - op_feat_acc: 0.6375 - op_bin_acc: 0.3292 - op_dir_acc: 0.9445\n",
      "Epoch 313/7000\n",
      "7111/7111 [==============================] - 6s 841us/step - loss: 3.2994 - op_feat_loss: 1.1059 - op_bin_loss: 3.0709 - op_dir_loss: 0.1476 - op_feat_acc: 0.6304 - op_bin_acc: 0.3261 - op_dir_acc: 0.9430\n",
      "Epoch 314/7000\n",
      "7111/7111 [==============================] - 6s 900us/step - loss: 3.2877 - op_feat_loss: 1.1087 - op_bin_loss: 3.0587 - op_dir_loss: 0.1453 - op_feat_acc: 0.6300 - op_bin_acc: 0.3247 - op_dir_acc: 0.9440\n",
      "Epoch 315/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7111/7111 [==============================] - 6s 834us/step - loss: 3.2916 - op_feat_loss: 1.1068 - op_bin_loss: 3.0629 - op_dir_loss: 0.1471 - op_feat_acc: 0.6328 - op_bin_acc: 0.3261 - op_dir_acc: 0.94224s - loss: 3.2718 - op_feat_loss: 1.0870 - op_bin_loss: 3.0474 - o\n",
      "Epoch 316/7000\n",
      "7111/7111 [==============================] - 6s 820us/step - loss: 3.2712 - op_feat_loss: 1.0968 - op_bin_loss: 3.0447 - op_dir_loss: 0.1435 - op_feat_acc: 0.6369 - op_bin_acc: 0.3279 - op_dir_acc: 0.9453\n",
      "Epoch 317/7000\n",
      "7111/7111 [==============================] - 6s 850us/step - loss: 3.2755 - op_feat_loss: 1.0993 - op_bin_loss: 3.0484 - op_dir_loss: 0.1445 - op_feat_acc: 0.6348 - op_bin_acc: 0.3247 - op_dir_acc: 0.9450\n",
      "Epoch 318/7000\n",
      "7111/7111 [==============================] - 6s 844us/step - loss: 3.2587 - op_feat_loss: 1.0914 - op_bin_loss: 3.0334 - op_dir_loss: 0.1408 - op_feat_acc: 0.6382 - op_bin_acc: 0.3331 - op_dir_acc: 0.9474\n",
      "Epoch 319/7000\n",
      "7111/7111 [==============================] - 6s 854us/step - loss: 3.2752 - op_feat_loss: 1.1012 - op_bin_loss: 3.0474 - op_dir_loss: 0.1494 - op_feat_acc: 0.6349 - op_bin_acc: 0.3296 - op_dir_acc: 0.9418\n",
      "Epoch 320/7000\n",
      "7111/7111 [==============================] - 6s 822us/step - loss: 3.2676 - op_feat_loss: 1.0928 - op_bin_loss: 3.0418 - op_dir_loss: 0.1457 - op_feat_acc: 0.6351 - op_bin_acc: 0.3284 - op_dir_acc: 0.9425\n",
      "Epoch 321/7000\n",
      "7111/7111 [==============================] - 6s 829us/step - loss: 3.2502 - op_feat_loss: 1.0852 - op_bin_loss: 3.0260 - op_dir_loss: 0.1423 - op_feat_acc: 0.6359 - op_bin_acc: 0.3329 - op_dir_acc: 0.9452\n",
      "Epoch 322/7000\n",
      "7111/7111 [==============================] - 6s 827us/step - loss: 3.2671 - op_feat_loss: 1.0931 - op_bin_loss: 3.0413 - op_dir_loss: 0.1442 - op_feat_acc: 0.6358 - op_bin_acc: 0.3268 - op_dir_acc: 0.94504s - loss: 3.2007 - op_feat_loss: 1.0978 - op_bin_loss: 2.\n",
      "Epoch 323/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 3.2474 - op_feat_loss: 1.0841 - op_bin_loss: 3.0234 - op_dir_loss: 0.1442 - op_feat_acc: 0.6396 - op_bin_acc: 0.3319 - op_dir_acc: 0.9436\n",
      "Epoch 324/7000\n",
      "7111/7111 [==============================] - 6s 889us/step - loss: 3.2350 - op_feat_loss: 1.0787 - op_bin_loss: 3.0122 - op_dir_loss: 0.1409 - op_feat_acc: 0.6410 - op_bin_acc: 0.3372 - op_dir_acc: 0.9457\n",
      "Epoch 325/7000\n",
      "7111/7111 [==============================] - 6s 853us/step - loss: 3.2251 - op_feat_loss: 1.0708 - op_bin_loss: 3.0038 - op_dir_loss: 0.1424 - op_feat_acc: 0.6482 - op_bin_acc: 0.3398 - op_dir_acc: 0.9440\n",
      "Epoch 326/7000\n",
      "7111/7111 [==============================] - 6s 827us/step - loss: 3.2112 - op_feat_loss: 1.0650 - op_bin_loss: 2.9912 - op_dir_loss: 0.1410 - op_feat_acc: 0.6467 - op_bin_acc: 0.3421 - op_dir_acc: 0.9457\n",
      "Epoch 327/7000\n",
      "7111/7111 [==============================] - 6s 820us/step - loss: 3.2148 - op_feat_loss: 1.0631 - op_bin_loss: 2.9952 - op_dir_loss: 0.1393 - op_feat_acc: 0.6467 - op_bin_acc: 0.3383 - op_dir_acc: 0.9463\n",
      "Epoch 328/7000\n",
      "7111/7111 [==============================] - 6s 829us/step - loss: 3.2096 - op_feat_loss: 1.0633 - op_bin_loss: 2.9900 - op_dir_loss: 0.1405 - op_feat_acc: 0.6480 - op_bin_acc: 0.3386 - op_dir_acc: 0.94753s - loss: 3.1907 - op_feat_loss: 1.0692 - op_bin_loss: 2.9698 - op_di\n",
      "Epoch 329/7000\n",
      "7111/7111 [==============================] - 6s 830us/step - loss: 3.2095 - op_feat_loss: 1.0615 - op_bin_loss: 2.9903 - op_dir_loss: 0.1384 - op_feat_acc: 0.6532 - op_bin_acc: 0.3393 - op_dir_acc: 0.9450\n",
      "Epoch 330/7000\n",
      "7111/7111 [==============================] - 7s 935us/step - loss: 3.2106 - op_feat_loss: 1.0635 - op_bin_loss: 2.9909 - op_dir_loss: 0.1403 - op_feat_acc: 0.6524 - op_bin_acc: 0.3437 - op_dir_acc: 0.9446\n",
      "Epoch 331/7000\n",
      "7111/7111 [==============================] - 6s 830us/step - loss: 3.2035 - op_feat_loss: 1.0612 - op_bin_loss: 2.9843 - op_dir_loss: 0.1398 - op_feat_acc: 0.6510 - op_bin_acc: 0.3385 - op_dir_acc: 0.9454\n",
      "Epoch 332/7000\n",
      "7111/7111 [==============================] - 6s 818us/step - loss: 3.1966 - op_feat_loss: 1.0580 - op_bin_loss: 2.9780 - op_dir_loss: 0.1388 - op_feat_acc: 0.6553 - op_bin_acc: 0.3403 - op_dir_acc: 0.9447\n",
      "Epoch 333/7000\n",
      "7111/7111 [==============================] - 6s 817us/step - loss: 3.1916 - op_feat_loss: 1.0544 - op_bin_loss: 2.9739 - op_dir_loss: 0.1379 - op_feat_acc: 0.6542 - op_bin_acc: 0.3437 - op_dir_acc: 0.9460\n",
      "Epoch 334/7000\n",
      "7111/7111 [==============================] - 6s 846us/step - loss: 3.1977 - op_feat_loss: 1.0559 - op_bin_loss: 2.9796 - op_dir_loss: 0.1398 - op_feat_acc: 0.6534 - op_bin_acc: 0.3400 - op_dir_acc: 0.9440\n",
      "Epoch 335/7000\n",
      "7111/7111 [==============================] - 6s 829us/step - loss: 3.2092 - op_feat_loss: 1.0653 - op_bin_loss: 2.9890 - op_dir_loss: 0.1422 - op_feat_acc: 0.6497 - op_bin_acc: 0.3351 - op_dir_acc: 0.9445\n",
      "Epoch 336/7000\n",
      "7111/7111 [==============================] - 6s 813us/step - loss: 3.2052 - op_feat_loss: 1.0596 - op_bin_loss: 2.9862 - op_dir_loss: 0.1415 - op_feat_acc: 0.6527 - op_bin_acc: 0.3381 - op_dir_acc: 0.9447\n",
      "Epoch 337/7000\n",
      "7111/7111 [==============================] - 6s 816us/step - loss: 3.2344 - op_feat_loss: 1.0739 - op_bin_loss: 3.0125 - op_dir_loss: 0.1411 - op_feat_acc: 0.6414 - op_bin_acc: 0.3319 - op_dir_acc: 0.9450\n",
      "Epoch 338/7000\n",
      "7111/7111 [==============================] - 6s 832us/step - loss: 3.2156 - op_feat_loss: 1.0645 - op_bin_loss: 2.9957 - op_dir_loss: 0.1413 - op_feat_acc: 0.6446 - op_bin_acc: 0.3350 - op_dir_acc: 0.9446\n",
      "Epoch 339/7000\n",
      "7111/7111 [==============================] - 6s 879us/step - loss: 3.1964 - op_feat_loss: 1.0594 - op_bin_loss: 2.9775 - op_dir_loss: 0.1394 - op_feat_acc: 0.6479 - op_bin_acc: 0.3406 - op_dir_acc: 0.9461\n",
      "Epoch 340/7000\n",
      "7111/7111 [==============================] - 6s 858us/step - loss: 3.1938 - op_feat_loss: 1.0596 - op_bin_loss: 2.9749 - op_dir_loss: 0.1405 - op_feat_acc: 0.6498 - op_bin_acc: 0.3381 - op_dir_acc: 0.9442\n",
      "Epoch 341/7000\n",
      "7111/7111 [==============================] - 6s 818us/step - loss: 3.1808 - op_feat_loss: 1.0497 - op_bin_loss: 2.9639 - op_dir_loss: 0.1398 - op_feat_acc: 0.6517 - op_bin_acc: 0.3433 - op_dir_acc: 0.9433\n",
      "Epoch 342/7000\n",
      "7111/7111 [==============================] - 6s 826us/step - loss: 3.1681 - op_feat_loss: 1.0428 - op_bin_loss: 2.9525 - op_dir_loss: 0.1397 - op_feat_acc: 0.6577 - op_bin_acc: 0.3499 - op_dir_acc: 0.9442\n",
      "Epoch 343/7000\n",
      "7111/7111 [==============================] - 6s 832us/step - loss: 3.1778 - op_feat_loss: 1.0497 - op_bin_loss: 2.9610 - op_dir_loss: 0.1384 - op_feat_acc: 0.6534 - op_bin_acc: 0.3458 - op_dir_acc: 0.9439\n",
      "Epoch 344/7000\n",
      "7111/7111 [==============================] - 6s 828us/step - loss: 3.1700 - op_feat_loss: 1.0457 - op_bin_loss: 2.9539 - op_dir_loss: 0.1398 - op_feat_acc: 0.6549 - op_bin_acc: 0.3452 - op_dir_acc: 0.9446\n",
      "Epoch 345/7000\n",
      "7111/7111 [==============================] - 6s 825us/step - loss: 3.1607 - op_feat_loss: 1.0397 - op_bin_loss: 2.9458 - op_dir_loss: 0.1378 - op_feat_acc: 0.6574 - op_bin_acc: 0.3469 - op_dir_acc: 0.9443\n",
      "Epoch 346/7000\n",
      "7111/7111 [==============================] - 6s 826us/step - loss: 3.1523 - op_feat_loss: 1.0371 - op_bin_loss: 2.9380 - op_dir_loss: 0.1371 - op_feat_acc: 0.6557 - op_bin_acc: 0.3559 - op_dir_acc: 0.94572s - loss: 3.2118 - op_feat_loss: 1.0454 - op_bin_loss: 2.9956 - op_dir_loss: 0.1423 - op_fe\n",
      "Epoch 347/7000\n",
      "7111/7111 [==============================] - 6s 841us/step - loss: 3.1602 - op_feat_loss: 1.0402 - op_bin_loss: 2.9453 - op_dir_loss: 0.1370 - op_feat_acc: 0.6598 - op_bin_acc: 0.3458 - op_dir_acc: 0.9477\n",
      "Epoch 348/7000\n",
      "7111/7111 [==============================] - 6s 825us/step - loss: 3.1516 - op_feat_loss: 1.0360 - op_bin_loss: 2.9375 - op_dir_loss: 0.1368 - op_feat_acc: 0.6612 - op_bin_acc: 0.3478 - op_dir_acc: 0.9457\n",
      "Epoch 349/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 3.1457 - op_feat_loss: 1.0342 - op_bin_loss: 2.9320 - op_dir_loss: 0.1366 - op_feat_acc: 0.6586 - op_bin_acc: 0.3544 - op_dir_acc: 0.9464\n",
      "Epoch 350/7000\n",
      "7111/7111 [==============================] - 6s 830us/step - loss: 3.1401 - op_feat_loss: 1.0292 - op_bin_loss: 2.9274 - op_dir_loss: 0.1374 - op_feat_acc: 0.6654 - op_bin_acc: 0.3537 - op_dir_acc: 0.9454\n",
      "Epoch 351/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7111/7111 [==============================] - 6s 824us/step - loss: 3.1497 - op_feat_loss: 1.0363 - op_bin_loss: 2.9354 - op_dir_loss: 0.1398 - op_feat_acc: 0.6584 - op_bin_acc: 0.3492 - op_dir_acc: 0.94490s - loss: 3.1431 - op_feat_loss: 1.0332 - op_bin_loss: 2.9294 - op_dir_loss: 0.1414 - op_feat_acc: 0.6575 - op_bin_acc: 0.3505 - op_dir_a\n",
      "Epoch 352/7000\n",
      "7111/7111 [==============================] - 6s 823us/step - loss: 3.1505 - op_feat_loss: 1.0340 - op_bin_loss: 2.9367 - op_dir_loss: 0.1384 - op_feat_acc: 0.6590 - op_bin_acc: 0.3489 - op_dir_acc: 0.9452\n",
      "Epoch 353/7000\n",
      "7111/7111 [==============================] - 6s 824us/step - loss: 3.1849 - op_feat_loss: 1.0511 - op_bin_loss: 2.9676 - op_dir_loss: 0.1413 - op_feat_acc: 0.6453 - op_bin_acc: 0.3416 - op_dir_acc: 0.9452\n",
      "Epoch 354/7000\n",
      "7111/7111 [==============================] - 6s 820us/step - loss: 3.1643 - op_feat_loss: 1.0423 - op_bin_loss: 2.9488 - op_dir_loss: 0.1403 - op_feat_acc: 0.6519 - op_bin_acc: 0.3440 - op_dir_acc: 0.94474s - loss: 3.2511 - op_feat_loss: 1.0689 - op_bin_loss: 3.0296 - op_\n",
      "Epoch 355/7000\n",
      "7111/7111 [==============================] - 6s 816us/step - loss: 3.1540 - op_feat_loss: 1.0410 - op_bin_loss: 2.9389 - op_dir_loss: 0.1390 - op_feat_acc: 0.6549 - op_bin_acc: 0.3447 - op_dir_acc: 0.9452\n",
      "Epoch 356/7000\n",
      "7111/7111 [==============================] - 6s 865us/step - loss: 3.1643 - op_feat_loss: 1.0461 - op_bin_loss: 2.9480 - op_dir_loss: 0.1423 - op_feat_acc: 0.6545 - op_bin_acc: 0.3413 - op_dir_acc: 0.9447\n",
      "Epoch 357/7000\n",
      "7111/7111 [==============================] - 6s 867us/step - loss: 3.1912 - op_feat_loss: 1.0662 - op_bin_loss: 2.9702 - op_dir_loss: 0.1544 - op_feat_acc: 0.6393 - op_bin_acc: 0.3312 - op_dir_acc: 0.9400\n",
      "Epoch 358/7000\n",
      "7111/7111 [==============================] - 6s 903us/step - loss: 3.2056 - op_feat_loss: 1.0704 - op_bin_loss: 2.9838 - op_dir_loss: 0.1541 - op_feat_acc: 0.6469 - op_bin_acc: 0.3371 - op_dir_acc: 0.9400\n",
      "Epoch 359/7000\n",
      "7111/7111 [==============================] - 6s 866us/step - loss: 3.2323 - op_feat_loss: 1.0894 - op_bin_loss: 3.0066 - op_dir_loss: 0.1557 - op_feat_acc: 0.6338 - op_bin_acc: 0.3319 - op_dir_acc: 0.9397\n",
      "Epoch 360/7000\n",
      "7111/7111 [==============================] - 6s 887us/step - loss: 3.2438 - op_feat_loss: 1.0916 - op_bin_loss: 3.0178 - op_dir_loss: 0.1535 - op_feat_acc: 0.6359 - op_bin_acc: 0.3327 - op_dir_acc: 0.9412\n",
      "Epoch 361/7000\n",
      "7111/7111 [==============================] - 7s 950us/step - loss: 3.1792 - op_feat_loss: 1.0609 - op_bin_loss: 2.9597 - op_dir_loss: 0.1467 - op_feat_acc: 0.6441 - op_bin_acc: 0.3450 - op_dir_acc: 0.9432\n",
      "Epoch 362/7000\n",
      "7111/7111 [==============================] - 7s 946us/step - loss: 3.1384 - op_feat_loss: 1.0402 - op_bin_loss: 2.9232 - op_dir_loss: 0.1433 - op_feat_acc: 0.6573 - op_bin_acc: 0.3486 - op_dir_acc: 0.9436\n",
      "Epoch 363/7000\n",
      "7111/7111 [==============================] - 7s 954us/step - loss: 3.1202 - op_feat_loss: 1.0288 - op_bin_loss: 2.9074 - op_dir_loss: 0.1404 - op_feat_acc: 0.6618 - op_bin_acc: 0.3521 - op_dir_acc: 0.9461\n",
      "Epoch 364/7000\n",
      "7111/7111 [==============================] - 6s 888us/step - loss: 3.1114 - op_feat_loss: 1.0251 - op_bin_loss: 2.8994 - op_dir_loss: 0.1397 - op_feat_acc: 0.6660 - op_bin_acc: 0.3571 - op_dir_acc: 0.9467\n",
      "Epoch 365/7000\n",
      "7111/7111 [==============================] - 6s 853us/step - loss: 3.1036 - op_feat_loss: 1.0193 - op_bin_loss: 2.8927 - op_dir_loss: 0.1396 - op_feat_acc: 0.6650 - op_bin_acc: 0.3597 - op_dir_acc: 0.9452\n",
      "Epoch 366/7000\n",
      "7111/7111 [==============================] - 6s 853us/step - loss: 3.1083 - op_feat_loss: 1.0231 - op_bin_loss: 2.8967 - op_dir_loss: 0.1397 - op_feat_acc: 0.6669 - op_bin_acc: 0.3579 - op_dir_acc: 0.9459\n",
      "Epoch 367/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.0997 - op_feat_loss: 1.0178 - op_bin_loss: 2.8892 - op_dir_loss: 0.1385 - op_feat_acc: 0.6650 - op_bin_acc: 0.3620 - op_dir_acc: 0.9467\n",
      "Epoch 368/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.0928 - op_feat_loss: 1.0170 - op_bin_loss: 2.8825 - op_dir_loss: 0.1382 - op_feat_acc: 0.6663 - op_bin_acc: 0.3618 - op_dir_acc: 0.9457\n",
      "Epoch 369/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 3.0876 - op_feat_loss: 1.0104 - op_bin_loss: 2.8786 - op_dir_loss: 0.1382 - op_feat_acc: 0.6666 - op_bin_acc: 0.3656 - op_dir_acc: 0.9454\n",
      "Epoch 370/7000\n",
      "7111/7111 [==============================] - 7s 993us/step - loss: 3.0989 - op_feat_loss: 1.0156 - op_bin_loss: 2.8888 - op_dir_loss: 0.1400 - op_feat_acc: 0.6692 - op_bin_acc: 0.3562 - op_dir_acc: 0.9450\n",
      "Epoch 371/7000\n",
      "7111/7111 [==============================] - 7s 1000us/step - loss: 3.0858 - op_feat_loss: 1.0110 - op_bin_loss: 2.8767 - op_dir_loss: 0.1378 - op_feat_acc: 0.6680 - op_bin_acc: 0.3606 - op_dir_acc: 0.9470\n",
      "Epoch 372/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 3.0903 - op_feat_loss: 1.0082 - op_bin_loss: 2.8818 - op_dir_loss: 0.1384 - op_feat_acc: 0.6723 - op_bin_acc: 0.3616 - op_dir_acc: 0.9456\n",
      "Epoch 373/7000\n",
      "7111/7111 [==============================] - 6s 910us/step - loss: 3.0958 - op_feat_loss: 1.0150 - op_bin_loss: 2.8859 - op_dir_loss: 0.1389 - op_feat_acc: 0.6666 - op_bin_acc: 0.3589 - op_dir_acc: 0.9466\n",
      "Epoch 374/7000\n",
      "7111/7111 [==============================] - 7s 990us/step - loss: 3.1080 - op_feat_loss: 1.0203 - op_bin_loss: 2.8969 - op_dir_loss: 0.1399 - op_feat_acc: 0.6608 - op_bin_acc: 0.3547 - op_dir_acc: 0.9440\n",
      "Epoch 375/7000\n",
      "7111/7111 [==============================] - 6s 839us/step - loss: 3.0858 - op_feat_loss: 1.0082 - op_bin_loss: 2.8772 - op_dir_loss: 0.1390 - op_feat_acc: 0.6684 - op_bin_acc: 0.3637 - op_dir_acc: 0.94591s - loss: 3.0848 - op_feat_loss: 1.0122 - op_bin_loss: 2.8753 - op_dir_loss: 0.1415 - op_feat_acc: 0.6644 - op_bin_acc: 0\n",
      "Epoch 376/7000\n",
      "7111/7111 [==============================] - 6s 855us/step - loss: 3.0800 - op_feat_loss: 1.0068 - op_bin_loss: 2.8718 - op_dir_loss: 0.1384 - op_feat_acc: 0.6695 - op_bin_acc: 0.3620 - op_dir_acc: 0.94663s - loss: 3.0640 - op_feat_loss: 0.9982 - op_bin_loss: 2.8575 - op_dir_loss: 0.1376 - op_\n",
      "Epoch 377/7000\n",
      "7111/7111 [==============================] - 6s 820us/step - loss: 3.0713 - op_feat_loss: 1.0012 - op_bin_loss: 2.8642 - op_dir_loss: 0.1374 - op_feat_acc: 0.6708 - op_bin_acc: 0.3675 - op_dir_acc: 0.9454\n",
      "Epoch 378/7000\n",
      "7111/7111 [==============================] - 6s 828us/step - loss: 3.0751 - op_feat_loss: 1.0030 - op_bin_loss: 2.8676 - op_dir_loss: 0.1379 - op_feat_acc: 0.6702 - op_bin_acc: 0.3690 - op_dir_acc: 0.9464\n",
      "Epoch 379/7000\n",
      "7111/7111 [==============================] - 6s 818us/step - loss: 3.0671 - op_feat_loss: 1.0008 - op_bin_loss: 2.8601 - op_dir_loss: 0.1370 - op_feat_acc: 0.6747 - op_bin_acc: 0.3670 - op_dir_acc: 0.9470\n",
      "Epoch 380/7000\n",
      "7111/7111 [==============================] - 6s 820us/step - loss: 3.0691 - op_feat_loss: 1.0035 - op_bin_loss: 2.8616 - op_dir_loss: 0.1373 - op_feat_acc: 0.6687 - op_bin_acc: 0.3652 - op_dir_acc: 0.9474\n",
      "Epoch 381/7000\n",
      "7111/7111 [==============================] - 6s 825us/step - loss: 3.0697 - op_feat_loss: 1.0012 - op_bin_loss: 2.8625 - op_dir_loss: 0.1384 - op_feat_acc: 0.6726 - op_bin_acc: 0.3663 - op_dir_acc: 0.9450\n",
      "Epoch 382/7000\n",
      "7111/7111 [==============================] - 6s 902us/step - loss: 3.0710 - op_feat_loss: 1.0039 - op_bin_loss: 2.8634 - op_dir_loss: 0.1378 - op_feat_acc: 0.6705 - op_bin_acc: 0.3617 - op_dir_acc: 0.9457\n",
      "Epoch 383/7000\n",
      "7111/7111 [==============================] - 6s 820us/step - loss: 3.0661 - op_feat_loss: 1.0025 - op_bin_loss: 2.8588 - op_dir_loss: 0.1377 - op_feat_acc: 0.6680 - op_bin_acc: 0.3639 - op_dir_acc: 0.9442\n",
      "Epoch 384/7000\n",
      "7111/7111 [==============================] - 6s 822us/step - loss: 3.0639 - op_feat_loss: 0.9981 - op_bin_loss: 2.8574 - op_dir_loss: 0.1369 - op_feat_acc: 0.6673 - op_bin_acc: 0.3644 - op_dir_acc: 0.9466\n",
      "Epoch 385/7000\n",
      "7111/7111 [==============================] - 6s 830us/step - loss: 3.0670 - op_feat_loss: 1.0046 - op_bin_loss: 2.8592 - op_dir_loss: 0.1376 - op_feat_acc: 0.6647 - op_bin_acc: 0.3620 - op_dir_acc: 0.94644s - loss: 2.9967 - op_feat_loss: 0.9931 - op_bin_loss: \n",
      "Epoch 386/7000\n",
      "7111/7111 [==============================] - 6s 818us/step - loss: 3.0603 - op_feat_loss: 0.9966 - op_bin_loss: 2.8540 - op_dir_loss: 0.1383 - op_feat_acc: 0.6722 - op_bin_acc: 0.3675 - op_dir_acc: 0.94464s - loss: 3.0542 - op_feat_loss: 0.9653 - op_bin_loss: 2.8550 -\n",
      "Epoch 387/7000\n",
      "7111/7111 [==============================] - 6s 912us/step - loss: 3.0547 - op_feat_loss: 0.9932 - op_bin_loss: 2.8492 - op_dir_loss: 0.1366 - op_feat_acc: 0.6729 - op_bin_acc: 0.3641 - op_dir_acc: 0.9463\n",
      "Epoch 388/7000\n",
      "7111/7111 [==============================] - 6s 824us/step - loss: 3.0670 - op_feat_loss: 1.0015 - op_bin_loss: 2.8598 - op_dir_loss: 0.1364 - op_feat_acc: 0.6685 - op_bin_acc: 0.3621 - op_dir_acc: 0.9464\n",
      "Epoch 389/7000\n",
      "7111/7111 [==============================] - 6s 811us/step - loss: 3.0930 - op_feat_loss: 1.0072 - op_bin_loss: 2.8846 - op_dir_loss: 0.1398 - op_feat_acc: 0.6632 - op_bin_acc: 0.3610 - op_dir_acc: 0.9452\n",
      "Epoch 390/7000\n",
      "7111/7111 [==============================] - 6s 832us/step - loss: 3.0988 - op_feat_loss: 1.0155 - op_bin_loss: 2.8889 - op_dir_loss: 0.1370 - op_feat_acc: 0.6581 - op_bin_acc: 0.3517 - op_dir_acc: 0.94591s - loss: 3.0955 - op_feat_loss: 1.0268 - op_bin_loss: 2.8834 - op_dir_loss: 0.1358 - op_feat_acc: 0.6582 - o\n",
      "Epoch 391/7000\n",
      "7111/7111 [==============================] - 6s 846us/step - loss: 3.0641 - op_feat_loss: 1.0007 - op_bin_loss: 2.8571 - op_dir_loss: 0.1365 - op_feat_acc: 0.6646 - op_bin_acc: 0.3638 - op_dir_acc: 0.9477\n",
      "Epoch 392/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 3.0436 - op_feat_loss: 0.9902 - op_bin_loss: 2.8387 - op_dir_loss: 0.1358 - op_feat_acc: 0.6732 - op_bin_acc: 0.3665 - op_dir_acc: 0.9470\n",
      "Epoch 393/7000\n",
      "7111/7111 [==============================] - 6s 824us/step - loss: 3.0384 - op_feat_loss: 0.9908 - op_bin_loss: 2.8334 - op_dir_loss: 0.1371 - op_feat_acc: 0.6760 - op_bin_acc: 0.3701 - op_dir_acc: 0.9475\n",
      "Epoch 394/7000\n",
      "7111/7111 [==============================] - 6s 886us/step - loss: 3.0808 - op_feat_loss: 1.0173 - op_bin_loss: 2.8700 - op_dir_loss: 0.1475 - op_feat_acc: 0.6629 - op_bin_acc: 0.3628 - op_dir_acc: 0.9419\n",
      "Epoch 395/7000\n",
      "7111/7111 [==============================] - 6s 832us/step - loss: 3.0504 - op_feat_loss: 1.0009 - op_bin_loss: 2.8433 - op_dir_loss: 0.1387 - op_feat_acc: 0.6659 - op_bin_acc: 0.3658 - op_dir_acc: 0.9450\n",
      "Epoch 396/7000\n",
      "7111/7111 [==============================] - 6s 816us/step - loss: 3.0404 - op_feat_loss: 0.9942 - op_bin_loss: 2.8346 - op_dir_loss: 0.1396 - op_feat_acc: 0.6697 - op_bin_acc: 0.3700 - op_dir_acc: 0.94470s - loss: 3.0301 - op_feat_loss: 0.9925 - op_bin_loss: 2.8246 - op_dir_loss: 0.1397 - op_feat_acc: 0.6701 - op_bin_acc: 0.3737 - op_d\n",
      "Epoch 397/7000\n",
      "7111/7111 [==============================] - 6s 884us/step - loss: 3.0335 - op_feat_loss: 0.9884 - op_bin_loss: 2.8289 - op_dir_loss: 0.1377 - op_feat_acc: 0.6694 - op_bin_acc: 0.3721 - op_dir_acc: 0.9454\n",
      "Epoch 398/7000\n",
      "7111/7111 [==============================] - 7s 975us/step - loss: 3.0236 - op_feat_loss: 0.9834 - op_bin_loss: 2.8201 - op_dir_loss: 0.1364 - op_feat_acc: 0.6752 - op_bin_acc: 0.3713 - op_dir_acc: 0.9468\n",
      "Epoch 399/7000\n",
      "7111/7111 [==============================] - 6s 879us/step - loss: 3.0212 - op_feat_loss: 0.9796 - op_bin_loss: 2.8185 - op_dir_loss: 0.1362 - op_feat_acc: 0.6774 - op_bin_acc: 0.3721 - op_dir_acc: 0.9468\n",
      "Epoch 400/7000\n",
      "7111/7111 [==============================] - 6s 844us/step - loss: 3.0179 - op_feat_loss: 0.9796 - op_bin_loss: 2.8152 - op_dir_loss: 0.1366 - op_feat_acc: 0.6789 - op_bin_acc: 0.3714 - op_dir_acc: 0.9449\n",
      "Epoch 401/7000\n",
      "7111/7111 [==============================] - 6s 839us/step - loss: 3.0176 - op_feat_loss: 0.9807 - op_bin_loss: 2.8146 - op_dir_loss: 0.1365 - op_feat_acc: 0.6744 - op_bin_acc: 0.3700 - op_dir_acc: 0.9453\n",
      "Epoch 402/7000\n",
      "7111/7111 [==============================] - 7s 982us/step - loss: 3.0213 - op_feat_loss: 0.9838 - op_bin_loss: 2.8178 - op_dir_loss: 0.1352 - op_feat_acc: 0.6698 - op_bin_acc: 0.3759 - op_dir_acc: 0.94614s - loss: 3.1153 - op_feat_loss: 0.9718 - op_bin_loss: 2.9135 - op_dir_loss: 0.1479 - op_feat_acc: 0.6689 - ETA: 2s - loss: 3.0359 - op_feat_loss: 0.9865 - op_bin_loss: 2.8316 - op_dir_loss: 0.1392 - op_feat_acc: 0.6680 - op_ - ETA: 0s - loss: 3.0205 - op_feat_loss: 0.9832 - op_bin_loss: 2.8171 - op_dir_loss: 0.1370 - op_feat_acc: 0.6695 - op_bin_acc: 0.3773 - op_dir_acc\n",
      "Epoch 403/7000\n",
      "7111/7111 [==============================] - 6s 844us/step - loss: 3.0092 - op_feat_loss: 0.9766 - op_bin_loss: 2.8072 - op_dir_loss: 0.1346 - op_feat_acc: 0.6736 - op_bin_acc: 0.3736 - op_dir_acc: 0.94744s - loss: 3.0057 - op_feat_loss: 0.9730 - op_bin_lo\n",
      "Epoch 404/7000\n",
      "7111/7111 [==============================] - 6s 841us/step - loss: 3.0116 - op_feat_loss: 0.9786 - op_bin_loss: 2.8091 - op_dir_loss: 0.1353 - op_feat_acc: 0.6795 - op_bin_acc: 0.3738 - op_dir_acc: 0.9464\n",
      "Epoch 405/7000\n",
      "7111/7111 [==============================] - 6s 893us/step - loss: 3.0065 - op_feat_loss: 0.9736 - op_bin_loss: 2.8049 - op_dir_loss: 0.1361 - op_feat_acc: 0.6805 - op_bin_acc: 0.3777 - op_dir_acc: 0.94544s - loss: 3.0816 - op_feat_loss: 0.9743 - op_bin_loss\n",
      "Epoch 406/7000\n",
      "7111/7111 [==============================] - 7s 926us/step - loss: 2.9957 - op_feat_loss: 0.9697 - op_bin_loss: 2.7950 - op_dir_loss: 0.1345 - op_feat_acc: 0.6782 - op_bin_acc: 0.3781 - op_dir_acc: 0.94750s - loss: 3.0026 - op_feat_loss: 0.9711 - op_bin_loss: 2.8017 - op_dir_loss: 0.1330 - op_feat_acc: 0.6784 - op_bin_acc: 0.3763 - op_dir_acc: 0.\n",
      "Epoch 407/7000\n",
      "7111/7111 [==============================] - 6s 839us/step - loss: 2.9936 - op_feat_loss: 0.9687 - op_bin_loss: 2.7932 - op_dir_loss: 0.1348 - op_feat_acc: 0.6792 - op_bin_acc: 0.3777 - op_dir_acc: 0.9460\n",
      "Epoch 408/7000\n",
      "7111/7111 [==============================] - 6s 865us/step - loss: 2.9905 - op_feat_loss: 0.9663 - op_bin_loss: 2.7905 - op_dir_loss: 0.1352 - op_feat_acc: 0.6809 - op_bin_acc: 0.3832 - op_dir_acc: 0.9457\n",
      "Epoch 409/7000\n",
      "7111/7111 [==============================] - 6s 839us/step - loss: 2.9912 - op_feat_loss: 0.9678 - op_bin_loss: 2.7909 - op_dir_loss: 0.1351 - op_feat_acc: 0.6813 - op_bin_acc: 0.3828 - op_dir_acc: 0.9459\n",
      "Epoch 410/7000\n",
      "7111/7111 [==============================] - 6s 832us/step - loss: 2.9868 - op_feat_loss: 0.9648 - op_bin_loss: 2.7872 - op_dir_loss: 0.1340 - op_feat_acc: 0.6840 - op_bin_acc: 0.3765 - op_dir_acc: 0.9482\n",
      "Epoch 411/7000\n",
      "7111/7111 [==============================] - 6s 882us/step - loss: 2.9830 - op_feat_loss: 0.9602 - op_bin_loss: 2.7842 - op_dir_loss: 0.1350 - op_feat_acc: 0.6839 - op_bin_acc: 0.3804 - op_dir_acc: 0.94730s - loss: 2.9837 - op_feat_loss: 0.9586 - op_bin_loss: 2.7853 - op_dir_loss: 0.1336 - op_feat_acc: 0.6837 - op_bin_acc: 0.3809 - op_dir_acc: \n",
      "Epoch 412/7000\n",
      "7111/7111 [==============================] - 6s 881us/step - loss: 2.9851 - op_feat_loss: 0.9654 - op_bin_loss: 2.7853 - op_dir_loss: 0.1351 - op_feat_acc: 0.6825 - op_bin_acc: 0.3770 - op_dir_acc: 0.9470\n",
      "Epoch 413/7000\n",
      "7111/7111 [==============================] - 6s 849us/step - loss: 2.9890 - op_feat_loss: 0.9622 - op_bin_loss: 2.7898 - op_dir_loss: 0.1346 - op_feat_acc: 0.6778 - op_bin_acc: 0.3753 - op_dir_acc: 0.9460\n",
      "Epoch 414/7000\n",
      "7111/7111 [==============================] - 6s 829us/step - loss: 2.9953 - op_feat_loss: 0.9662 - op_bin_loss: 2.7952 - op_dir_loss: 0.1359 - op_feat_acc: 0.6836 - op_bin_acc: 0.3743 - op_dir_acc: 0.9463\n",
      "Epoch 415/7000\n",
      "7111/7111 [==============================] - 6s 832us/step - loss: 3.0316 - op_feat_loss: 0.9818 - op_bin_loss: 2.8283 - op_dir_loss: 0.1382 - op_feat_acc: 0.6733 - op_bin_acc: 0.3711 - op_dir_acc: 0.9459\n",
      "Epoch 416/7000\n",
      "7111/7111 [==============================] - 6s 833us/step - loss: 3.1212 - op_feat_loss: 1.0502 - op_bin_loss: 2.9031 - op_dir_loss: 0.1605 - op_feat_acc: 0.6473 - op_bin_acc: 0.3524 - op_dir_acc: 0.9377\n",
      "Epoch 417/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7111/7111 [==============================] - 6s 827us/step - loss: 3.1108 - op_feat_loss: 1.0334 - op_bin_loss: 2.8965 - op_dir_loss: 0.1522 - op_feat_acc: 0.6501 - op_bin_acc: 0.3464 - op_dir_acc: 0.9416\n",
      "Epoch 418/7000\n",
      "7111/7111 [==============================] - 6s 854us/step - loss: 3.1050 - op_feat_loss: 1.0461 - op_bin_loss: 2.8876 - op_dir_loss: 0.1633 - op_feat_acc: 0.6438 - op_bin_acc: 0.3544 - op_dir_acc: 0.9369\n",
      "Epoch 419/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 3.1769 - op_feat_loss: 1.0846 - op_bin_loss: 2.9520 - op_dir_loss: 0.1602 - op_feat_acc: 0.6317 - op_bin_acc: 0.3396 - op_dir_acc: 0.9380\n",
      "Epoch 420/7000\n",
      "7111/7111 [==============================] - 6s 874us/step - loss: 3.1183 - op_feat_loss: 1.0468 - op_bin_loss: 2.9016 - op_dir_loss: 0.1483 - op_feat_acc: 0.6421 - op_bin_acc: 0.3486 - op_dir_acc: 0.94321s - loss: 3.1153 - op_feat_loss: 1.0416 - op_bin_loss: 2.8998 - op_dir_loss: 0.1432 - op_feat_acc: 0.6460 - op_bin_acc: 0.3\n",
      "Epoch 421/7000\n",
      "7111/7111 [==============================] - 6s 815us/step - loss: 3.0591 - op_feat_loss: 1.0169 - op_bin_loss: 2.8482 - op_dir_loss: 0.1515 - op_feat_acc: 0.6590 - op_bin_acc: 0.3621 - op_dir_acc: 0.9408\n",
      "Epoch 422/7000\n",
      "7111/7111 [==============================] - 6s 858us/step - loss: 3.0101 - op_feat_loss: 0.9849 - op_bin_loss: 2.8060 - op_dir_loss: 0.1437 - op_feat_acc: 0.6666 - op_bin_acc: 0.3697 - op_dir_acc: 0.94353s - loss: 3.0423 - op_feat_loss: 0.9927 - op_bin_loss: 2.8361 - op_dir_loss\n",
      "Epoch 423/7000\n",
      "7111/7111 [==============================] - 7s 995us/step - loss: 2.9842 - op_feat_loss: 0.9683 - op_bin_loss: 2.7837 - op_dir_loss: 0.1381 - op_feat_acc: 0.6712 - op_bin_acc: 0.3770 - op_dir_acc: 0.9450\n",
      "Epoch 424/7000\n",
      "7111/7111 [==============================] - 7s 989us/step - loss: 2.9665 - op_feat_loss: 0.9565 - op_bin_loss: 2.7683 - op_dir_loss: 0.1375 - op_feat_acc: 0.6789 - op_bin_acc: 0.3839 - op_dir_acc: 0.94561s - loss: 2.9786 - op_feat_loss: 0.9628 - op_bin_loss: 2.7791 - op_dir_loss: 0.1391 - op_feat_acc: 0.6748 - op_bin_\n",
      "Epoch 425/7000\n",
      "7111/7111 [==============================] - 7s 975us/step - loss: 2.9609 - op_feat_loss: 0.9514 - op_bin_loss: 2.7638 - op_dir_loss: 0.1365 - op_feat_acc: 0.6844 - op_bin_acc: 0.3828 - op_dir_acc: 0.94560s - loss: 2.9530 - op_feat_loss: 0.9519 - op_bin_loss: 2.7557 - op_dir_loss: 0.1380 - op_feat_acc: 0.6860 - op_bin_acc: 0.3841 - op_dir_acc: \n",
      "Epoch 426/7000\n",
      "7111/7111 [==============================] - 6s 907us/step - loss: 2.9574 - op_feat_loss: 0.9504 - op_bin_loss: 2.7605 - op_dir_loss: 0.1358 - op_feat_acc: 0.6826 - op_bin_acc: 0.3833 - op_dir_acc: 0.9454\n",
      "Epoch 427/7000\n",
      "7111/7111 [==============================] - 6s 830us/step - loss: 2.9601 - op_feat_loss: 0.9533 - op_bin_loss: 2.7627 - op_dir_loss: 0.1358 - op_feat_acc: 0.6863 - op_bin_acc: 0.3836 - op_dir_acc: 0.9467\n",
      "Epoch 428/7000\n",
      "7111/7111 [==============================] - 6s 842us/step - loss: 2.9545 - op_feat_loss: 0.9493 - op_bin_loss: 2.7578 - op_dir_loss: 0.1368 - op_feat_acc: 0.6867 - op_bin_acc: 0.3853 - op_dir_acc: 0.9463\n",
      "Epoch 429/7000\n",
      "7111/7111 [==============================] - 6s 895us/step - loss: 2.9458 - op_feat_loss: 0.9425 - op_bin_loss: 2.7505 - op_dir_loss: 0.1355 - op_feat_acc: 0.6854 - op_bin_acc: 0.3877 - op_dir_acc: 0.94593s - loss: 2.9332 - op_feat_loss: 0.9409 - op_bin_loss: 2.7380 - op_dir_lo\n",
      "Epoch 430/7000\n",
      "7111/7111 [==============================] - 6s 851us/step - loss: 2.9528 - op_feat_loss: 0.9431 - op_bin_loss: 2.7574 - op_dir_loss: 0.1345 - op_feat_acc: 0.6895 - op_bin_acc: 0.3848 - op_dir_acc: 0.9467\n",
      "Epoch 431/7000\n",
      "7111/7111 [==============================] - 6s 823us/step - loss: 2.9541 - op_feat_loss: 0.9461 - op_bin_loss: 2.7581 - op_dir_loss: 0.1357 - op_feat_acc: 0.6820 - op_bin_acc: 0.3859 - op_dir_acc: 0.94642s - loss: 2.9451 - op_feat_loss: 0.9458 - op_bin_loss: 2.7490 - op_dir_loss: 0.1391 - op_feat_acc: 0.67\n",
      "Epoch 432/7000\n",
      "7111/7111 [==============================] - 7s 914us/step - loss: 2.9475 - op_feat_loss: 0.9447 - op_bin_loss: 2.7518 - op_dir_loss: 0.1353 - op_feat_acc: 0.6842 - op_bin_acc: 0.3839 - op_dir_acc: 0.9449\n",
      "Epoch 433/7000\n",
      "7111/7111 [==============================] - 6s 826us/step - loss: 2.9389 - op_feat_loss: 0.9396 - op_bin_loss: 2.7442 - op_dir_loss: 0.1357 - op_feat_acc: 0.6846 - op_bin_acc: 0.3870 - op_dir_acc: 0.9452\n",
      "Epoch 434/7000\n",
      "7111/7111 [==============================] - 6s 876us/step - loss: 2.9348 - op_feat_loss: 0.9368 - op_bin_loss: 2.7407 - op_dir_loss: 0.1342 - op_feat_acc: 0.6864 - op_bin_acc: 0.3898 - op_dir_acc: 0.94645s - loss: 2.8402 - op_feat_loss: 0.8319\n",
      "Epoch 435/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.9314 - op_feat_loss: 0.9333 - op_bin_loss: 2.7380 - op_dir_loss: 0.1333 - op_feat_acc: 0.6896 - op_bin_acc: 0.3901 - op_dir_acc: 0.9478\n",
      "Epoch 436/7000\n",
      "7111/7111 [==============================] - 6s 879us/step - loss: 2.9259 - op_feat_loss: 0.9304 - op_bin_loss: 2.7332 - op_dir_loss: 0.1334 - op_feat_acc: 0.6885 - op_bin_acc: 0.3874 - op_dir_acc: 0.9481\n",
      "Epoch 437/7000\n",
      "7111/7111 [==============================] - 7s 963us/step - loss: 2.9220 - op_feat_loss: 0.9286 - op_bin_loss: 2.7296 - op_dir_loss: 0.1339 - op_feat_acc: 0.6901 - op_bin_acc: 0.3938 - op_dir_acc: 0.9484\n",
      "Epoch 438/7000\n",
      "7111/7111 [==============================] - 6s 826us/step - loss: 2.9311 - op_feat_loss: 0.9311 - op_bin_loss: 2.7382 - op_dir_loss: 0.1337 - op_feat_acc: 0.6849 - op_bin_acc: 0.3890 - op_dir_acc: 0.9474\n",
      "Epoch 439/7000\n",
      "7111/7111 [==============================] - 7s 963us/step - loss: 2.9276 - op_feat_loss: 0.9300 - op_bin_loss: 2.7350 - op_dir_loss: 0.1334 - op_feat_acc: 0.6891 - op_bin_acc: 0.3829 - op_dir_acc: 0.9471\n",
      "Epoch 440/7000\n",
      "7111/7111 [==============================] - 7s 975us/step - loss: 2.9256 - op_feat_loss: 0.9283 - op_bin_loss: 2.7333 - op_dir_loss: 0.1344 - op_feat_acc: 0.6889 - op_bin_acc: 0.3880 - op_dir_acc: 0.9474\n",
      "Epoch 441/7000\n",
      "7111/7111 [==============================] - 7s 971us/step - loss: 2.9277 - op_feat_loss: 0.9309 - op_bin_loss: 2.7348 - op_dir_loss: 0.1347 - op_feat_acc: 0.6919 - op_bin_acc: 0.3873 - op_dir_acc: 0.9460\n",
      "Epoch 442/7000\n",
      "7111/7111 [==============================] - 7s 928us/step - loss: 2.9211 - op_feat_loss: 0.9245 - op_bin_loss: 2.7295 - op_dir_loss: 0.1333 - op_feat_acc: 0.6922 - op_bin_acc: 0.3907 - op_dir_acc: 0.9485\n",
      "Epoch 443/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.9458 - op_feat_loss: 0.9419 - op_bin_loss: 2.7508 - op_dir_loss: 0.1330 - op_feat_acc: 0.6851 - op_bin_acc: 0.3842 - op_dir_acc: 0.9478\n",
      "Epoch 444/7000\n",
      "7111/7111 [==============================] - 6s 850us/step - loss: 2.9355 - op_feat_loss: 0.9319 - op_bin_loss: 2.7424 - op_dir_loss: 0.1351 - op_feat_acc: 0.6843 - op_bin_acc: 0.3849 - op_dir_acc: 0.94681s - loss: 2.9429 - op_feat_loss: 0.9275 - op_bin_loss: 2.7504 - op_dir_loss: 0.1395 - op_feat_acc: 0.6891 - op_bin_acc: 0\n",
      "Epoch 445/7000\n",
      "7111/7111 [==============================] - 6s 852us/step - loss: 2.9219 - op_feat_loss: 0.9286 - op_bin_loss: 2.7295 - op_dir_loss: 0.1336 - op_feat_acc: 0.6882 - op_bin_acc: 0.3863 - op_dir_acc: 0.9463\n",
      "Epoch 446/7000\n",
      "7111/7111 [==============================] - 7s 968us/step - loss: 2.9109 - op_feat_loss: 0.9199 - op_bin_loss: 2.7202 - op_dir_loss: 0.1337 - op_feat_acc: 0.6926 - op_bin_acc: 0.3911 - op_dir_acc: 0.9474\n",
      "Epoch 447/7000\n",
      "7111/7111 [==============================] - 6s 808us/step - loss: 2.9050 - op_feat_loss: 0.9165 - op_bin_loss: 2.7151 - op_dir_loss: 0.1332 - op_feat_acc: 0.6932 - op_bin_acc: 0.3922 - op_dir_acc: 0.94741s - loss: 2.9290 - op_feat_loss: 0.9363 - op_bin_loss: 2.7349 - op_dir_loss: 0.1378 - op_feat_acc: 0.6882 - op_bin_acc: 0\n",
      "Epoch 448/7000\n",
      "7111/7111 [==============================] - 7s 978us/step - loss: 2.9140 - op_feat_loss: 0.9217 - op_bin_loss: 2.7229 - op_dir_loss: 0.1345 - op_feat_acc: 0.6901 - op_bin_acc: 0.3880 - op_dir_acc: 0.9470\n",
      "Epoch 449/7000\n",
      "7111/7111 [==============================] - 6s 839us/step - loss: 2.9163 - op_feat_loss: 0.9213 - op_bin_loss: 2.7254 - op_dir_loss: 0.1333 - op_feat_acc: 0.6894 - op_bin_acc: 0.3898 - op_dir_acc: 0.9475\n",
      "Epoch 450/7000\n",
      "7111/7111 [==============================] - 6s 906us/step - loss: 2.9146 - op_feat_loss: 0.9230 - op_bin_loss: 2.7232 - op_dir_loss: 0.1360 - op_feat_acc: 0.6908 - op_bin_acc: 0.3881 - op_dir_acc: 0.9464\n",
      "Epoch 451/7000\n",
      "7111/7111 [==============================] - 7s 994us/step - loss: 3.0059 - op_feat_loss: 0.9697 - op_bin_loss: 2.8048 - op_dir_loss: 0.1424 - op_feat_acc: 0.6702 - op_bin_acc: 0.3743 - op_dir_acc: 0.9447\n",
      "Epoch 452/7000\n",
      "7111/7111 [==============================] - 6s 824us/step - loss: 3.0123 - op_feat_loss: 0.9763 - op_bin_loss: 2.8099 - op_dir_loss: 0.1435 - op_feat_acc: 0.6662 - op_bin_acc: 0.3701 - op_dir_acc: 0.9439\n",
      "Epoch 453/7000\n",
      "7111/7111 [==============================] - 6s 819us/step - loss: 3.0077 - op_feat_loss: 0.9668 - op_bin_loss: 2.8070 - op_dir_loss: 0.1463 - op_feat_acc: 0.6699 - op_bin_acc: 0.3687 - op_dir_acc: 0.9419\n",
      "Epoch 454/7000\n",
      "7111/7111 [==============================] - 7s 992us/step - loss: 3.0012 - op_feat_loss: 0.9662 - op_bin_loss: 2.8008 - op_dir_loss: 0.1439 - op_feat_acc: 0.6695 - op_bin_acc: 0.3698 - op_dir_acc: 0.9440\n",
      "Epoch 455/7000\n",
      "7111/7111 [==============================] - 7s 952us/step - loss: 2.9675 - op_feat_loss: 0.9537 - op_bin_loss: 2.7697 - op_dir_loss: 0.1398 - op_feat_acc: 0.6747 - op_bin_acc: 0.3729 - op_dir_acc: 0.9449\n",
      "Epoch 456/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 2.9394 - op_feat_loss: 0.9400 - op_bin_loss: 2.7446 - op_dir_loss: 0.1363 - op_feat_acc: 0.6795 - op_bin_acc: 0.3805 - op_dir_acc: 0.9460\n",
      "Epoch 457/7000\n",
      "7111/7111 [==============================] - 6s 875us/step - loss: 2.9171 - op_feat_loss: 0.9253 - op_bin_loss: 2.7253 - op_dir_loss: 0.1353 - op_feat_acc: 0.6895 - op_bin_acc: 0.3794 - op_dir_acc: 0.9463\n",
      "Epoch 458/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 2.9028 - op_feat_loss: 0.9199 - op_bin_loss: 2.7121 - op_dir_loss: 0.1339 - op_feat_acc: 0.6892 - op_bin_acc: 0.3878 - op_dir_acc: 0.9460\n",
      "Epoch 459/7000\n",
      "7111/7111 [==============================] - 6s 820us/step - loss: 2.8881 - op_feat_loss: 0.9116 - op_bin_loss: 2.6991 - op_dir_loss: 0.1326 - op_feat_acc: 0.6960 - op_bin_acc: 0.3939 - op_dir_acc: 0.9473\n",
      "Epoch 460/7000\n",
      "7111/7111 [==============================] - 6s 834us/step - loss: 2.8832 - op_feat_loss: 0.9088 - op_bin_loss: 2.6948 - op_dir_loss: 0.1317 - op_feat_acc: 0.6960 - op_bin_acc: 0.3943 - op_dir_acc: 0.9468\n",
      "Epoch 461/7000\n",
      "7111/7111 [==============================] - 6s 836us/step - loss: 2.8778 - op_feat_loss: 0.9054 - op_bin_loss: 2.6900 - op_dir_loss: 0.1330 - op_feat_acc: 0.6958 - op_bin_acc: 0.3953 - op_dir_acc: 0.9463\n",
      "Epoch 462/7000\n",
      "7111/7111 [==============================] - 6s 837us/step - loss: 2.8891 - op_feat_loss: 0.9131 - op_bin_loss: 2.6998 - op_dir_loss: 0.1339 - op_feat_acc: 0.6971 - op_bin_acc: 0.3936 - op_dir_acc: 0.9466\n",
      "Epoch 463/7000\n",
      "7111/7111 [==============================] - 7s 961us/step - loss: 2.8792 - op_feat_loss: 0.9039 - op_bin_loss: 2.6918 - op_dir_loss: 0.1322 - op_feat_acc: 0.6964 - op_bin_acc: 0.3942 - op_dir_acc: 0.9481\n",
      "Epoch 464/7000\n",
      "7111/7111 [==============================] - 7s 945us/step - loss: 2.8731 - op_feat_loss: 0.9003 - op_bin_loss: 2.6865 - op_dir_loss: 0.1309 - op_feat_acc: 0.6974 - op_bin_acc: 0.3936 - op_dir_acc: 0.9468\n",
      "Epoch 465/7000\n",
      "7111/7111 [==============================] - 6s 852us/step - loss: 2.8727 - op_feat_loss: 0.9025 - op_bin_loss: 2.6856 - op_dir_loss: 0.1319 - op_feat_acc: 0.6978 - op_bin_acc: 0.3935 - op_dir_acc: 0.9467\n",
      "Epoch 466/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.8735 - op_feat_loss: 0.9015 - op_bin_loss: 2.6865 - op_dir_loss: 0.1328 - op_feat_acc: 0.7005 - op_bin_acc: 0.3929 - op_dir_acc: 0.9478\n",
      "Epoch 467/7000\n",
      "7111/7111 [==============================] - 6s 896us/step - loss: 2.8675 - op_feat_loss: 0.8999 - op_bin_loss: 2.6809 - op_dir_loss: 0.1315 - op_feat_acc: 0.7006 - op_bin_acc: 0.3981 - op_dir_acc: 0.9471\n",
      "Epoch 468/7000\n",
      "7111/7111 [==============================] - 6s 813us/step - loss: 2.8636 - op_feat_loss: 0.8951 - op_bin_loss: 2.6780 - op_dir_loss: 0.1319 - op_feat_acc: 0.7013 - op_bin_acc: 0.3967 - op_dir_acc: 0.9477\n",
      "Epoch 469/7000\n",
      "7111/7111 [==============================] - 6s 836us/step - loss: 2.8594 - op_feat_loss: 0.8942 - op_bin_loss: 2.6740 - op_dir_loss: 0.1306 - op_feat_acc: 0.7016 - op_bin_acc: 0.3984 - op_dir_acc: 0.94804s - loss: 2.9028 - op_feat_loss: 0.9121 - op_bin_loss\n",
      "Epoch 470/7000\n",
      "7111/7111 [==============================] - 6s 836us/step - loss: 2.8590 - op_feat_loss: 0.8953 - op_bin_loss: 2.6734 - op_dir_loss: 0.1320 - op_feat_acc: 0.6998 - op_bin_acc: 0.4002 - op_dir_acc: 0.9470\n",
      "Epoch 471/7000\n",
      "7111/7111 [==============================] - 6s 882us/step - loss: 2.8591 - op_feat_loss: 0.8946 - op_bin_loss: 2.6736 - op_dir_loss: 0.1319 - op_feat_acc: 0.7027 - op_bin_acc: 0.3983 - op_dir_acc: 0.9473\n",
      "Epoch 472/7000\n",
      "7111/7111 [==============================] - 7s 968us/step - loss: 2.8543 - op_feat_loss: 0.8915 - op_bin_loss: 2.6694 - op_dir_loss: 0.1313 - op_feat_acc: 0.7051 - op_bin_acc: 0.3991 - op_dir_acc: 0.9494\n",
      "Epoch 473/7000\n",
      "7111/7111 [==============================] - 7s 987us/step - loss: 2.8553 - op_feat_loss: 0.8899 - op_bin_loss: 2.6707 - op_dir_loss: 0.1322 - op_feat_acc: 0.7043 - op_bin_acc: 0.4001 - op_dir_acc: 0.9459\n",
      "Epoch 474/7000\n",
      "7111/7111 [==============================] - 7s 971us/step - loss: 2.8544 - op_feat_loss: 0.8911 - op_bin_loss: 2.6695 - op_dir_loss: 0.1324 - op_feat_acc: 0.7023 - op_bin_acc: 0.3991 - op_dir_acc: 0.9478\n",
      "Epoch 475/7000\n",
      "7111/7111 [==============================] - 6s 898us/step - loss: 2.8604 - op_feat_loss: 0.8911 - op_bin_loss: 2.6756 - op_dir_loss: 0.1326 - op_feat_acc: 0.7003 - op_bin_acc: 0.3957 - op_dir_acc: 0.9461\n",
      "Epoch 476/7000\n",
      "7111/7111 [==============================] - 7s 927us/step - loss: 2.8559 - op_feat_loss: 0.8897 - op_bin_loss: 2.6713 - op_dir_loss: 0.1330 - op_feat_acc: 0.7043 - op_bin_acc: 0.3949 - op_dir_acc: 0.94612s - loss: 2.8496 - op_feat_loss: 0.8796 - op_bin_loss: 2.6676 - op_dir_loss: 0.1208 - op_feat\n",
      "Epoch 477/7000\n",
      "7111/7111 [==============================] - 6s 895us/step - loss: 2.8587 - op_feat_loss: 0.8913 - op_bin_loss: 2.6738 - op_dir_loss: 0.1322 - op_feat_acc: 0.7010 - op_bin_acc: 0.4002 - op_dir_acc: 0.9457\n",
      "Epoch 478/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 2.8674 - op_feat_loss: 0.9014 - op_bin_loss: 2.6805 - op_dir_loss: 0.1331 - op_feat_acc: 0.6981 - op_bin_acc: 0.3953 - op_dir_acc: 0.9457\n",
      "Epoch 479/7000\n",
      "7111/7111 [==============================] - 7s 966us/step - loss: 2.8846 - op_feat_loss: 0.9077 - op_bin_loss: 2.6963 - op_dir_loss: 0.1351 - op_feat_acc: 0.6915 - op_bin_acc: 0.3904 - op_dir_acc: 0.9461\n",
      "Epoch 480/7000\n",
      "7111/7111 [==============================] - 7s 954us/step - loss: 2.8816 - op_feat_loss: 0.9064 - op_bin_loss: 2.6935 - op_dir_loss: 0.1355 - op_feat_acc: 0.6967 - op_bin_acc: 0.3901 - op_dir_acc: 0.9477\n",
      "Epoch 481/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 2.8651 - op_feat_loss: 0.8962 - op_bin_loss: 2.6791 - op_dir_loss: 0.1352 - op_feat_acc: 0.6971 - op_bin_acc: 0.3914 - op_dir_acc: 0.9445\n",
      "Epoch 482/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 2.8768 - op_feat_loss: 0.8991 - op_bin_loss: 2.6902 - op_dir_loss: 0.1355 - op_feat_acc: 0.6940 - op_bin_acc: 0.3905 - op_dir_acc: 0.9460\n",
      "Epoch 483/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 3.0083 - op_feat_loss: 0.9868 - op_bin_loss: 2.8034 - op_dir_loss: 0.1508 - op_feat_acc: 0.6635 - op_bin_acc: 0.3679 - op_dir_acc: 0.9397\n",
      "Epoch 484/7000\n",
      "7111/7111 [==============================] - 7s 990us/step - loss: 2.9793 - op_feat_loss: 0.9756 - op_bin_loss: 2.7767 - op_dir_loss: 0.1488 - op_feat_acc: 0.6681 - op_bin_acc: 0.3760 - op_dir_acc: 0.9435\n",
      "Epoch 485/7000\n",
      "7111/7111 [==============================] - 7s 1000us/step - loss: 2.9469 - op_feat_loss: 0.9608 - op_bin_loss: 2.7474 - op_dir_loss: 0.1480 - op_feat_acc: 0.6723 - op_bin_acc: 0.3784 - op_dir_acc: 0.9415\n",
      "Epoch 486/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7111/7111 [==============================] - 6s 897us/step - loss: 2.8797 - op_feat_loss: 0.9170 - op_bin_loss: 2.6893 - op_dir_loss: 0.1395 - op_feat_acc: 0.6849 - op_bin_acc: 0.3883 - op_dir_acc: 0.9449\n",
      "Epoch 487/7000\n",
      "7111/7111 [==============================] - 7s 923us/step - loss: 2.8481 - op_feat_loss: 0.8961 - op_bin_loss: 2.6621 - op_dir_loss: 0.1358 - op_feat_acc: 0.6974 - op_bin_acc: 0.3970 - op_dir_acc: 0.9461\n",
      "Epoch 488/7000\n",
      "7111/7111 [==============================] - 7s 935us/step - loss: 2.8296 - op_feat_loss: 0.8865 - op_bin_loss: 2.6455 - op_dir_loss: 0.1358 - op_feat_acc: 0.7006 - op_bin_acc: 0.4022 - op_dir_acc: 0.9461\n",
      "Epoch 489/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.8242 - op_feat_loss: 0.8819 - op_bin_loss: 2.6412 - op_dir_loss: 0.1338 - op_feat_acc: 0.7019 - op_bin_acc: 0.4044 - op_dir_acc: 0.9468\n",
      "Epoch 490/7000\n",
      "7111/7111 [==============================] - 7s 996us/step - loss: 2.8190 - op_feat_loss: 0.8796 - op_bin_loss: 2.6363 - op_dir_loss: 0.1343 - op_feat_acc: 0.7082 - op_bin_acc: 0.4066 - op_dir_acc: 0.9459\n",
      "Epoch 491/7000\n",
      "7111/7111 [==============================] - 7s 972us/step - loss: 2.8154 - op_feat_loss: 0.8777 - op_bin_loss: 2.6332 - op_dir_loss: 0.1333 - op_feat_acc: 0.7088 - op_bin_acc: 0.4051 - op_dir_acc: 0.9463\n",
      "Epoch 492/7000\n",
      "7111/7111 [==============================] - 7s 914us/step - loss: 2.8323 - op_feat_loss: 0.8894 - op_bin_loss: 2.6476 - op_dir_loss: 0.1357 - op_feat_acc: 0.7022 - op_bin_acc: 0.4022 - op_dir_acc: 0.9460\n",
      "Epoch 493/7000\n",
      "7111/7111 [==============================] - 7s 959us/step - loss: 2.8152 - op_feat_loss: 0.8804 - op_bin_loss: 2.6324 - op_dir_loss: 0.1336 - op_feat_acc: 0.7061 - op_bin_acc: 0.4039 - op_dir_acc: 0.9477\n",
      "Epoch 494/7000\n",
      "7111/7111 [==============================] - 6s 904us/step - loss: 2.8100 - op_feat_loss: 0.8757 - op_bin_loss: 2.6282 - op_dir_loss: 0.1328 - op_feat_acc: 0.7071 - op_bin_acc: 0.4092 - op_dir_acc: 0.9490\n",
      "Epoch 495/7000\n",
      "7111/7111 [==============================] - 7s 981us/step - loss: 2.8102 - op_feat_loss: 0.8725 - op_bin_loss: 2.6290 - op_dir_loss: 0.1337 - op_feat_acc: 0.7100 - op_bin_acc: 0.4008 - op_dir_acc: 0.9463\n",
      "Epoch 496/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.8035 - op_feat_loss: 0.8703 - op_bin_loss: 2.6228 - op_dir_loss: 0.1327 - op_feat_acc: 0.7107 - op_bin_acc: 0.4037 - op_dir_acc: 0.9471\n",
      "Epoch 497/7000\n",
      "7111/7111 [==============================] - 7s 968us/step - loss: 2.7998 - op_feat_loss: 0.8673 - op_bin_loss: 2.6197 - op_dir_loss: 0.1325 - op_feat_acc: 0.7134 - op_bin_acc: 0.4071 - op_dir_acc: 0.9475\n",
      "Epoch 498/7000\n",
      "7111/7111 [==============================] - 6s 890us/step - loss: 2.8012 - op_feat_loss: 0.8663 - op_bin_loss: 2.6213 - op_dir_loss: 0.1318 - op_feat_acc: 0.7116 - op_bin_acc: 0.4071 - op_dir_acc: 0.9487\n",
      "Epoch 499/7000\n",
      "7111/7111 [==============================] - 6s 875us/step - loss: 2.7997 - op_feat_loss: 0.8661 - op_bin_loss: 2.6199 - op_dir_loss: 0.1325 - op_feat_acc: 0.7130 - op_bin_acc: 0.4073 - op_dir_acc: 0.9482\n",
      "Epoch 500/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.8018 - op_feat_loss: 0.8685 - op_bin_loss: 2.6215 - op_dir_loss: 0.1324 - op_feat_acc: 0.7107 - op_bin_acc: 0.4077 - op_dir_acc: 0.9467\n",
      "Epoch 501/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7999 - op_feat_loss: 0.8679 - op_bin_loss: 2.6197 - op_dir_loss: 0.1326 - op_feat_acc: 0.7099 - op_bin_acc: 0.4044 - op_dir_acc: 0.9477\n",
      "Epoch 502/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 2.7938 - op_feat_loss: 0.8631 - op_bin_loss: 2.6147 - op_dir_loss: 0.1305 - op_feat_acc: 0.7116 - op_bin_acc: 0.4074 - op_dir_acc: 0.9474\n",
      "Epoch 503/7000\n",
      "7111/7111 [==============================] - 7s 974us/step - loss: 2.7868 - op_feat_loss: 0.8625 - op_bin_loss: 2.6077 - op_dir_loss: 0.1320 - op_feat_acc: 0.7126 - op_bin_acc: 0.4098 - op_dir_acc: 0.9492\n",
      "Epoch 504/7000\n",
      "7111/7111 [==============================] - 7s 924us/step - loss: 2.7907 - op_feat_loss: 0.8637 - op_bin_loss: 2.6113 - op_dir_loss: 0.1319 - op_feat_acc: 0.7126 - op_bin_acc: 0.4053 - op_dir_acc: 0.9480\n",
      "Epoch 505/7000\n",
      "7111/7111 [==============================] - 7s 986us/step - loss: 2.7956 - op_feat_loss: 0.8666 - op_bin_loss: 2.6156 - op_dir_loss: 0.1338 - op_feat_acc: 0.7112 - op_bin_acc: 0.4056 - op_dir_acc: 0.9485\n",
      "Epoch 506/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7924 - op_feat_loss: 0.8658 - op_bin_loss: 2.6126 - op_dir_loss: 0.1342 - op_feat_acc: 0.7127 - op_bin_acc: 0.4063 - op_dir_acc: 0.9470\n",
      "Epoch 507/7000\n",
      "7111/7111 [==============================] - 6s 907us/step - loss: 2.7920 - op_feat_loss: 0.8647 - op_bin_loss: 2.6125 - op_dir_loss: 0.1322 - op_feat_acc: 0.7089 - op_bin_acc: 0.4047 - op_dir_acc: 0.9463\n",
      "Epoch 508/7000\n",
      "7111/7111 [==============================] - 6s 884us/step - loss: 2.7850 - op_feat_loss: 0.8585 - op_bin_loss: 2.6067 - op_dir_loss: 0.1320 - op_feat_acc: 0.7155 - op_bin_acc: 0.4044 - op_dir_acc: 0.9474\n",
      "Epoch 509/7000\n",
      "7111/7111 [==============================] - 7s 924us/step - loss: 2.7878 - op_feat_loss: 0.8581 - op_bin_loss: 2.6096 - op_dir_loss: 0.1323 - op_feat_acc: 0.7173 - op_bin_acc: 0.4075 - op_dir_acc: 0.9497\n",
      "Epoch 510/7000\n",
      "7111/7111 [==============================] - 6s 869us/step - loss: 2.7802 - op_feat_loss: 0.8604 - op_bin_loss: 2.6015 - op_dir_loss: 0.1320 - op_feat_acc: 0.7133 - op_bin_acc: 0.4077 - op_dir_acc: 0.9473\n",
      "Epoch 511/7000\n",
      "7111/7111 [==============================] - 6s 880us/step - loss: 2.7728 - op_feat_loss: 0.8512 - op_bin_loss: 2.5960 - op_dir_loss: 0.1306 - op_feat_acc: 0.7182 - op_bin_acc: 0.4098 - op_dir_acc: 0.9481\n",
      "Epoch 512/7000\n",
      "7111/7111 [==============================] - 7s 944us/step - loss: 2.7888 - op_feat_loss: 0.8622 - op_bin_loss: 2.6097 - op_dir_loss: 0.1334 - op_feat_acc: 0.7158 - op_bin_acc: 0.4053 - op_dir_acc: 0.9467\n",
      "Epoch 513/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7828 - op_feat_loss: 0.8601 - op_bin_loss: 2.6041 - op_dir_loss: 0.1322 - op_feat_acc: 0.7149 - op_bin_acc: 0.4105 - op_dir_acc: 0.9482\n",
      "Epoch 514/7000\n",
      "7111/7111 [==============================] - 7s 955us/step - loss: 2.7744 - op_feat_loss: 0.8552 - op_bin_loss: 2.5967 - op_dir_loss: 0.1338 - op_feat_acc: 0.7157 - op_bin_acc: 0.4088 - op_dir_acc: 0.9470\n",
      "Epoch 515/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7642 - op_feat_loss: 0.8503 - op_bin_loss: 2.5875 - op_dir_loss: 0.1329 - op_feat_acc: 0.7190 - op_bin_acc: 0.4113 - op_dir_acc: 0.9466\n",
      "Epoch 516/7000\n",
      "7111/7111 [==============================] - 6s 882us/step - loss: 2.7674 - op_feat_loss: 0.8492 - op_bin_loss: 2.5910 - op_dir_loss: 0.1318 - op_feat_acc: 0.7168 - op_bin_acc: 0.4105 - op_dir_acc: 0.9485\n",
      "Epoch 517/7000\n",
      "7111/7111 [==============================] - 6s 912us/step - loss: 2.7674 - op_feat_loss: 0.8525 - op_bin_loss: 2.5902 - op_dir_loss: 0.1322 - op_feat_acc: 0.7183 - op_bin_acc: 0.4098 - op_dir_acc: 0.9484\n",
      "Epoch 518/7000\n",
      "7111/7111 [==============================] - 7s 930us/step - loss: 2.7623 - op_feat_loss: 0.8499 - op_bin_loss: 2.5856 - op_dir_loss: 0.1324 - op_feat_acc: 0.7185 - op_bin_acc: 0.4118 - op_dir_acc: 0.9471\n",
      "Epoch 519/7000\n",
      "7111/7111 [==============================] - 7s 945us/step - loss: 2.7685 - op_feat_loss: 0.8510 - op_bin_loss: 2.5917 - op_dir_loss: 0.1321 - op_feat_acc: 0.7165 - op_bin_acc: 0.4104 - op_dir_acc: 0.9490\n",
      "Epoch 520/7000\n",
      "7111/7111 [==============================] - 7s 972us/step - loss: 2.7834 - op_feat_loss: 0.8604 - op_bin_loss: 2.6046 - op_dir_loss: 0.1347 - op_feat_acc: 0.7102 - op_bin_acc: 0.4070 - op_dir_acc: 0.9474\n",
      "Epoch 521/7000\n",
      "7111/7111 [==============================] - 7s 938us/step - loss: 2.7763 - op_feat_loss: 0.8557 - op_bin_loss: 2.5986 - op_dir_loss: 0.1322 - op_feat_acc: 0.7166 - op_bin_acc: 0.4092 - op_dir_acc: 0.9473\n",
      "Epoch 522/7000\n",
      "7111/7111 [==============================] - 6s 891us/step - loss: 2.7588 - op_feat_loss: 0.8475 - op_bin_loss: 2.5828 - op_dir_loss: 0.1307 - op_feat_acc: 0.7228 - op_bin_acc: 0.4112 - op_dir_acc: 0.9490\n",
      "Epoch 523/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7522 - op_feat_loss: 0.8439 - op_bin_loss: 2.5768 - op_dir_loss: 0.1321 - op_feat_acc: 0.7202 - op_bin_acc: 0.4139 - op_dir_acc: 0.9474\n",
      "Epoch 524/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 2.7465 - op_feat_loss: 0.8398 - op_bin_loss: 2.5719 - op_dir_loss: 0.1329 - op_feat_acc: 0.7227 - op_bin_acc: 0.4132 - op_dir_acc: 0.9460\n",
      "Epoch 525/7000\n",
      "7111/7111 [==============================] - 7s 944us/step - loss: 2.7610 - op_feat_loss: 0.8460 - op_bin_loss: 2.5851 - op_dir_loss: 0.1342 - op_feat_acc: 0.7200 - op_bin_acc: 0.4080 - op_dir_acc: 0.9466\n",
      "Epoch 526/7000\n",
      "7111/7111 [==============================] - 7s 985us/step - loss: 2.8528 - op_feat_loss: 0.8898 - op_bin_loss: 2.6680 - op_dir_loss: 0.1362 - op_feat_acc: 0.7038 - op_bin_acc: 0.3973 - op_dir_acc: 0.9449\n",
      "Epoch 527/7000\n",
      "7111/7111 [==============================] - 7s 923us/step - loss: 2.8853 - op_feat_loss: 0.9150 - op_bin_loss: 2.6953 - op_dir_loss: 0.1392 - op_feat_acc: 0.6917 - op_bin_acc: 0.3850 - op_dir_acc: 0.9457\n",
      "Epoch 528/7000\n",
      "7111/7111 [==============================] - 7s 966us/step - loss: 2.8402 - op_feat_loss: 0.8977 - op_bin_loss: 2.6536 - op_dir_loss: 0.1412 - op_feat_acc: 0.6989 - op_bin_acc: 0.3888 - op_dir_acc: 0.9440\n",
      "Epoch 529/7000\n",
      "7111/7111 [==============================] - 6s 883us/step - loss: 2.7851 - op_feat_loss: 0.8642 - op_bin_loss: 2.6054 - op_dir_loss: 0.1361 - op_feat_acc: 0.7112 - op_bin_acc: 0.4026 - op_dir_acc: 0.9478\n",
      "Epoch 530/7000\n",
      "7111/7111 [==============================] - 6s 888us/step - loss: 2.8921 - op_feat_loss: 0.9339 - op_bin_loss: 2.6975 - op_dir_loss: 0.1552 - op_feat_acc: 0.6875 - op_bin_acc: 0.3876 - op_dir_acc: 0.9405\n",
      "Epoch 531/7000\n",
      "7111/7111 [==============================] - 7s 988us/step - loss: 2.9050 - op_feat_loss: 0.9384 - op_bin_loss: 2.7098 - op_dir_loss: 0.1511 - op_feat_acc: 0.6799 - op_bin_acc: 0.3866 - op_dir_acc: 0.9409\n",
      "Epoch 532/7000\n",
      "7111/7111 [==============================] - 7s 923us/step - loss: 2.8112 - op_feat_loss: 0.8844 - op_bin_loss: 2.6273 - op_dir_loss: 0.1408 - op_feat_acc: 0.7026 - op_bin_acc: 0.3950 - op_dir_acc: 0.9447\n",
      "Epoch 533/7000\n",
      "7111/7111 [==============================] - 7s 953us/step - loss: 2.7669 - op_feat_loss: 0.8585 - op_bin_loss: 2.5882 - op_dir_loss: 0.1391 - op_feat_acc: 0.7134 - op_bin_acc: 0.4067 - op_dir_acc: 0.9454\n",
      "Epoch 534/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 2.7537 - op_feat_loss: 0.8536 - op_bin_loss: 2.5761 - op_dir_loss: 0.1387 - op_feat_acc: 0.7148 - op_bin_acc: 0.4116 - op_dir_acc: 0.9460\n",
      "Epoch 535/7000\n",
      "7111/7111 [==============================] - 7s 993us/step - loss: 2.7570 - op_feat_loss: 0.8522 - op_bin_loss: 2.5797 - op_dir_loss: 0.1377 - op_feat_acc: 0.7166 - op_bin_acc: 0.4109 - op_dir_acc: 0.9454\n",
      "Epoch 536/7000\n",
      "7111/7111 [==============================] - 7s 933us/step - loss: 2.7510 - op_feat_loss: 0.8487 - op_bin_loss: 2.5744 - op_dir_loss: 0.1374 - op_feat_acc: 0.7173 - op_bin_acc: 0.4092 - op_dir_acc: 0.9449\n",
      "Epoch 537/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7325 - op_feat_loss: 0.8366 - op_bin_loss: 2.5584 - op_dir_loss: 0.1364 - op_feat_acc: 0.7234 - op_bin_acc: 0.4133 - op_dir_acc: 0.9482\n",
      "Epoch 538/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7243 - op_feat_loss: 0.8330 - op_bin_loss: 2.5509 - op_dir_loss: 0.1355 - op_feat_acc: 0.7247 - op_bin_acc: 0.4156 - op_dir_acc: 0.9466\n",
      "Epoch 539/7000\n",
      "7111/7111 [==============================] - 7s 956us/step - loss: 2.7180 - op_feat_loss: 0.8325 - op_bin_loss: 2.5449 - op_dir_loss: 0.1327 - op_feat_acc: 0.7277 - op_bin_acc: 0.4198 - op_dir_acc: 0.9478\n",
      "Epoch 540/7000\n",
      "7111/7111 [==============================] - 7s 978us/step - loss: 2.7123 - op_feat_loss: 0.8271 - op_bin_loss: 2.5402 - op_dir_loss: 0.1326 - op_feat_acc: 0.7306 - op_bin_acc: 0.4229 - op_dir_acc: 0.9471\n",
      "Epoch 541/7000\n",
      "7111/7111 [==============================] - 7s 940us/step - loss: 2.7183 - op_feat_loss: 0.8283 - op_bin_loss: 2.5459 - op_dir_loss: 0.1336 - op_feat_acc: 0.7266 - op_bin_acc: 0.4199 - op_dir_acc: 0.9466\n",
      "Epoch 542/7000\n",
      "7111/7111 [==============================] - 7s 994us/step - loss: 2.7107 - op_feat_loss: 0.8254 - op_bin_loss: 2.5389 - op_dir_loss: 0.1335 - op_feat_acc: 0.7272 - op_bin_acc: 0.4188 - op_dir_acc: 0.9471\n",
      "Epoch 543/7000\n",
      "7111/7111 [==============================] - 7s 965us/step - loss: 2.7200 - op_feat_loss: 0.8311 - op_bin_loss: 2.5471 - op_dir_loss: 0.1348 - op_feat_acc: 0.7251 - op_bin_acc: 0.4182 - op_dir_acc: 0.9478\n",
      "Epoch 544/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7075 - op_feat_loss: 0.8239 - op_bin_loss: 2.5361 - op_dir_loss: 0.1322 - op_feat_acc: 0.7300 - op_bin_acc: 0.4250 - op_dir_acc: 0.9480\n",
      "Epoch 545/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7056 - op_feat_loss: 0.8188 - op_bin_loss: 2.5353 - op_dir_loss: 0.1319 - op_feat_acc: 0.7283 - op_bin_acc: 0.4210 - op_dir_acc: 0.9481\n",
      "Epoch 546/7000\n",
      "7111/7111 [==============================] - 7s 992us/step - loss: 2.7082 - op_feat_loss: 0.8235 - op_bin_loss: 2.5369 - op_dir_loss: 0.1327 - op_feat_acc: 0.7280 - op_bin_acc: 0.4189 - op_dir_acc: 0.9466\n",
      "Epoch 547/7000\n",
      "7111/7111 [==============================] - 7s 992us/step - loss: 2.7030 - op_feat_loss: 0.8192 - op_bin_loss: 2.5325 - op_dir_loss: 0.1323 - op_feat_acc: 0.7321 - op_bin_acc: 0.4216 - op_dir_acc: 0.9482\n",
      "Epoch 548/7000\n",
      "7111/7111 [==============================] - 7s 963us/step - loss: 2.7171 - op_feat_loss: 0.8268 - op_bin_loss: 2.5450 - op_dir_loss: 0.1346 - op_feat_acc: 0.7269 - op_bin_acc: 0.4160 - op_dir_acc: 0.9452\n",
      "Epoch 549/7000\n",
      "7111/7111 [==============================] - 7s 962us/step - loss: 2.7054 - op_feat_loss: 0.8211 - op_bin_loss: 2.5346 - op_dir_loss: 0.1311 - op_feat_acc: 0.7282 - op_bin_acc: 0.4215 - op_dir_acc: 0.9457\n",
      "Epoch 550/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7039 - op_feat_loss: 0.8221 - op_bin_loss: 2.5328 - op_dir_loss: 0.1323 - op_feat_acc: 0.7306 - op_bin_acc: 0.4222 - op_dir_acc: 0.9484\n",
      "Epoch 551/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7124 - op_feat_loss: 0.8231 - op_bin_loss: 2.5412 - op_dir_loss: 0.1321 - op_feat_acc: 0.7276 - op_bin_acc: 0.4195 - op_dir_acc: 0.9473: 7s - loss: 2.7229 - op_feat_loss: 0.8679 -\n",
      "Epoch 552/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 2.7361 - op_feat_loss: 0.8392 - op_bin_loss: 2.5615 - op_dir_loss: 0.1346 - op_feat_acc: 0.7220 - op_bin_acc: 0.4106 - op_dir_acc: 0.9467\n",
      "Epoch 553/7000\n",
      "7111/7111 [==============================] - 7s 964us/step - loss: 2.7054 - op_feat_loss: 0.8214 - op_bin_loss: 2.5345 - op_dir_loss: 0.1329 - op_feat_acc: 0.7280 - op_bin_acc: 0.4167 - op_dir_acc: 0.9485\n",
      "Epoch 554/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7122 - op_feat_loss: 0.8256 - op_bin_loss: 2.5403 - op_dir_loss: 0.1343 - op_feat_acc: 0.7270 - op_bin_acc: 0.4153 - op_dir_acc: 0.9453\n",
      "Epoch 555/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.7034 - op_feat_loss: 0.8168 - op_bin_loss: 2.5334 - op_dir_loss: 0.1323 - op_feat_acc: 0.7311 - op_bin_acc: 0.4174 - op_dir_acc: 0.9481\n",
      "Epoch 556/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.6935 - op_feat_loss: 0.8215 - op_bin_loss: 2.5226 - op_dir_loss: 0.1327 - op_feat_acc: 0.7252 - op_bin_acc: 0.4226 - op_dir_acc: 0.9463\n",
      "Epoch 557/7000\n",
      "7111/7111 [==============================] - 8s 1ms/step - loss: 2.7018 - op_feat_loss: 0.8183 - op_bin_loss: 2.5314 - op_dir_loss: 0.1337 - op_feat_acc: 0.7365 - op_bin_acc: 0.4198 - op_dir_acc: 0.9447\n",
      "Epoch 558/7000\n",
      "7111/7111 [==============================] - 7s 960us/step - loss: 2.6946 - op_feat_loss: 0.8148 - op_bin_loss: 2.5251 - op_dir_loss: 0.1325 - op_feat_acc: 0.7297 - op_bin_acc: 0.4220 - op_dir_acc: 0.9482\n",
      "Epoch 559/7000\n",
      "7111/7111 [==============================] - 7s 1ms/step - loss: 2.6817 - op_feat_loss: 0.8091 - op_bin_loss: 2.5133 - op_dir_loss: 0.1316 - op_feat_acc: 0.7352 - op_bin_acc: 0.4216 - op_dir_acc: 0.9475\n",
      "Epoch 560/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7111/7111 [==============================] - 7s 988us/step - loss: 2.6859 - op_feat_loss: 0.8111 - op_bin_loss: 2.5171 - op_dir_loss: 0.1306 - op_feat_acc: 0.7331 - op_bin_acc: 0.4222 - op_dir_acc: 0.9482\n",
      "Epoch 561/7000\n",
      "7111/7111 [==============================] - 7s 962us/step - loss: 2.7116 - op_feat_loss: 0.8199 - op_bin_loss: 2.5410 - op_dir_loss: 0.1333 - op_feat_acc: 0.7279 - op_bin_acc: 0.4185 - op_dir_acc: 0.9487\n",
      "Epoch 562/7000\n",
      "7111/7111 [==============================] - 7s 957us/step - loss: 2.7077 - op_feat_loss: 0.8218 - op_bin_loss: 2.5366 - op_dir_loss: 0.1347 - op_feat_acc: 0.7338 - op_bin_acc: 0.4137 - op_dir_acc: 0.9474\n",
      "Epoch 563/7000\n",
      "7111/7111 [==============================] - 7s 932us/step - loss: 2.6892 - op_feat_loss: 0.8154 - op_bin_loss: 2.5195 - op_dir_loss: 0.1326 - op_feat_acc: 0.7328 - op_bin_acc: 0.4246 - op_dir_acc: 0.9475\n",
      "Epoch 564/7000\n",
      "4480/7111 [=================>............] - ETA: 2s - loss: 2.6844 - op_feat_loss: 0.8164 - op_bin_loss: 2.5142 - op_dir_loss: 0.1372 - op_feat_acc: 0.7344 - op_bin_acc: 0.4243 - op_dir_acc: 0.9462"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-53720f425ff4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'op_feat'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'op_bin'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'op_dir'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model.fit([x_latent, x_feat, x_bin, x_dir], [y_feat, y_bin, y_dir],batch_size=128, epochs=7000, verbose=1,\n\u001b[1;32m----> 6\u001b[1;33m           callbacks=[WandbCallback()])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\wandb\\keras\\__init__.py\u001b[0m in \u001b[0;36mnew_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnew_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## multiple stacked RNN, multi-op approach, \n",
    "x_latent = get_hidden_x(path_latent_input, model=label_model)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], loss_weights={'op_feat': 0.2,'op_bin': 1.0,'op_dir': 0.05})\n",
    "model.fit([x_latent, x_feat, x_bin, x_dir], [y_feat, y_bin, y_dir],batch_size=128, epochs=7000, verbose=1,\n",
    "          callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "009cde0f-cb04-4981-a774-f2bddab7b415",
    "_uuid": "43fd6da4-538b-4c04-b67f-5e8fa1ff96bf",
    "id": "FMmOYkU1Xm8g",
    "outputId": "9db85a54-e46f-4e16-cc07-52c20d212917"
   },
   "outputs": [],
   "source": [
    " !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "28fd8a18-a5e0-419e-8987-b56d95e24cfa",
    "_uuid": "8db400d9-902f-41f0-bb29-33c02b9b189d",
    "id": "TGMLGnWFXz9K",
    "outputId": "df38e564-278e-45f7-d478-7ea6e3d1061f"
   },
   "outputs": [],
   "source": [
    "!wandb login 3c44930157a5a6c5455f6a1ca690543cd2a34362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1c1c59d4-9932-4601-bdd4-904f69891482",
    "_uuid": "e4ea1286-5966-4888-9bab-dc9a1159813c",
    "id": "xWF9uec645ce",
    "outputId": "a7def373-f5d0-4cc3-c157-bf8436ed559d"
   },
   "outputs": [],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "45808314-a7a6-47a2-a48e-561432a720ba",
    "_uuid": "6ad5ba93-a885-4049-9d13-9c6bade40fb3",
    "id": "kaJ54FjpbwMJ",
    "outputId": "d9ea4316-8afe-4112-e584-76b87a30bd1d"
   },
   "outputs": [],
   "source": [
    "!cat /var/log/colab-jupyter.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "93a3acee-e485-4ea6-96e1-1937d834b4c9",
    "_uuid": "99868ac2-cf78-4912-9942-e7cba618accb",
    "id": "R9Fi0Qqapfq4",
    "outputId": "3a76953d-9ae8-4850-8c22-0bca80969967"
   },
   "outputs": [],
   "source": [
    "!pip show keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "f5339a23-eb10-4e18-a3f0-069be2678e99",
    "_uuid": "45f264a8-31d9-4e57-a22b-156865ea546c",
    "id": "xQQrjU33pkwr",
    "outputId": "70c57acb-ad6e-4bf4-828b-09d0b2e9c928"
   },
   "outputs": [],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "1097733b-97e7-4dc5-a0f7-d26234b9be21",
    "_uuid": "179b9739-d2d4-4250-9f6a-9a74d3ea76bc",
    "id": "3JJrzcmykMCd",
    "outputId": "cf2947aa-b414-4d86-f673-a56d44995662"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_cell_guid": "f4d2eaff-abaa-4e8b-86e7-5d87caf71ba6",
    "_uuid": "d2aaaaa5-de0d-44ec-98b6-3d1d999319fc",
    "id": "Tu2oIOHXkMCe"
   },
   "outputs": [],
   "source": [
    "def get_hidden_x(x, model, layer_num=3):\n",
    "    def get_hidden_x_inner(model, layer_num=layer_num):\n",
    "        return K.function([model.layers[0].input], [model.layers[layer_num].output])\n",
    "    return get_hidden_x_inner(model, layer_num=layer_num)([x])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b660422b-fb61-4b5c-83dc-9c6755ac513c",
    "_uuid": "ce9df232-b67e-4014-b209-dc154ca42fe5",
    "id": "bj5XW7rykMCf"
   },
   "source": [
    "### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "09759530-a3fc-4db3-a895-e5d767be0604",
    "_uuid": "8c3059fc-7cf8-436c-a2d8-8df6145ddd3f",
    "id": "wB_sdQP-kMCf",
    "outputId": "604738cd-deef-4c72-9f14-004208309fb5"
   },
   "outputs": [],
   "source": [
    "x_latent = get_hidden_x(path_latent_input, model=label_model)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit([x_latent, x_feat, x_bin, x_dir], [y_feat, y_bin, y_dir],batch_size=6000, epochs=20000, verbose=1,\n",
    "          callbacks=[WandbCallback()])\n",
    "## dag_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "5d1cc9f7-9deb-4d43-afef-0d26efe04b09",
    "_uuid": "2ea5ed86-7064-4d8c-a19f-a660fa2c8bad",
    "id": "2HHZO5ijkMCi",
    "outputId": "31e96cb6-ac23-4bf5-902b-6c08dbe1ea88"
   },
   "outputs": [],
   "source": [
    "feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "0b28917a-0454-49f4-aace-1229e8274959",
    "_uuid": "94743a3b-99c9-430d-ac73-3201f7f91c4b",
    "id": "ANfITI8skMCi",
    "outputId": "b021dfdd-b40e-4bdc-9929-28b9f9178ea2"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "6fe5df71-5ac2-4582-b00b-58bd5ae1e865",
    "_uuid": "4f61ade3-223d-4bce-9642-20e5e1a4c709",
    "id": "VIv_ZSTjkMCk",
    "outputId": "5f15967a-f7f3-4a78-be04-1acdb20d1e7a"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "e87c02de-dabe-473f-b912-42c2bd127270",
    "_uuid": "3181cc6c-db06-4aaa-a38b-72c4b047cb47",
    "id": "okrJFnW-kMCl",
    "outputId": "00f18094-42de-40c1-87f8-a49c28c1fff7"
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "bcceb98e-3ca0-4787-8856-e20a81adec8a",
    "_uuid": "4379ba65-4a3b-4de9-87e8-89bb3b9fd072",
    "id": "weSc7S8hkMCn"
   },
   "outputs": [],
   "source": [
    "path = ['S', '4A1', '3D0', 'E']\n",
    "feat_ip = ['S', 4, 3, E]\n",
    "ip_2 = [0, 'A', 'D', 0]\n",
    "ip_3 = [0,'']\n",
    "# Correct masking issue\n",
    "# Interconnect RNNS, first to second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "a794675c-237e-4496-af42-95cd805661f2",
    "_uuid": "507faba2-f003-469f-9f09-f4058434fb7f",
    "id": "v3foX_tCkMCp",
    "outputId": "806b366e-16ec-40ca-9d29-68aeedff18f2"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "eb4244b1-c944-4e8e-b512-49250e87d756",
    "_uuid": "6679ea3d-a49e-493f-a21b-f598b2f53154",
    "id": "vJbIJQWKkMCr",
    "outputId": "694ad77b-8cb2-4385-858a-0f6f71ceb0e5"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "da717c5b-2525-4c6b-a350-3212f2169113",
    "_uuid": "d8650211-7e9f-4896-84c4-8fadc6a63896",
    "id": "HiS3rwHCkMCs",
    "outputId": "0c9e58e2-1737-4e5e-ab3a-e64b12bb5fbe"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "f63bdb3f-9254-408b-bbc9-ef3e8d55cc03",
    "_uuid": "b7f1cd78-ea3a-406b-892b-bc48bedf1a63",
    "id": "U4aQIbvVkMCt",
    "outputId": "b6f273d9-512c-41e9-977b-b1c59e953ac0"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "15f918b3-c471-41cc-8518-c31f7205abf6",
    "_uuid": "870dc6a4-611c-4315-8335-b6beddbd6e0a",
    "id": "FnSCA-l2kMCv"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='dag_approach_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "044bf647-59cc-4147-bba2-97ef4da03231",
    "_uuid": "5c5e93c9-bf3a-4e7d-b551-fa57ec6d4096",
    "id": "0Ps475nVkMCv",
    "outputId": "6a6fedec-ea13-4b9b-9038-26c2a71bf466"
   },
   "outputs": [],
   "source": [
    "path_latent_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "089914d3-d3a1-4351-9431-9623fac3764f",
    "_uuid": "e576948e-56aa-4f55-b227-1544fc39d2fc",
    "id": "srMJDziYkMCx",
    "outputId": "08213437-6740-41c2-a209-287fee7ca0c7"
   },
   "outputs": [],
   "source": [
    "x_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "a6afb1a4-8ebd-4c6e-bdf1-6b23a78e5cac",
    "_uuid": "13873e50-cb1f-4535-91b6-a711947d92b9",
    "id": "lpLvi168kMCy",
    "outputId": "c840fda6-334e-4a37-bb04-2c0739079710"
   },
   "outputs": [],
   "source": [
    "x_dir.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "cc206e80-7a46-497b-91ea-eabececccdbe",
    "_uuid": "f43e68af-0467-44f5-bfbc-076c3686d5ef",
    "id": "X2WEaSNakMDC",
    "outputId": "a6e661bb-154f-4575-cd64-014cece38cc8"
   },
   "outputs": [],
   "source": [
    "x_dir[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "5cfa5527-4e30-4612-be7e-e9cd868d03a2",
    "_uuid": "2f002e82-0a6c-4f35-96b7-7a709c240a10",
    "id": "7xIGvzQYkMDC",
    "outputId": "f551074f-421f-4748-ce39-4b07e287b323"
   },
   "outputs": [],
   "source": [
    "x_bin[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "21363866-ddfc-433b-b6c0-f250634e87c7",
    "_uuid": "d98c575b-25c0-43d8-afca-818343317163",
    "id": "KmzLVgCBkMDF",
    "outputId": "68a7f9f8-4d5d-4b90-ac54-0a2cf01caad4"
   },
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y)\n",
    "\n",
    "# label_model_trial_6.compile(\n",
    "#     optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# label_model_trial_6.fit(\n",
    "#     X, y_cat, batch_size=30, epochs=150, verbose=1, shuffle=True, validation_split=0.2)\n",
    "\n",
    "x_latent = get_hidden_x(path_latent_input, model=label_model_trial_6)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit([x_latent, x_feat, x_bin, x_dir], [y_feat, y_bin, y_dir],batch_size=80, epochs=20000, verbose=1)\n",
    "# Latent dim -- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "2d7307d7-5dbc-4520-90d3-275c33d6df00",
    "_uuid": "f60a3d9c-d561-4fc1-a8d9-15057c8b469c",
    "id": "mQm975JokMDM",
    "outputId": "8aad3c32-200c-48dd-d3c1-0a7551d49771"
   },
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y)\n",
    "\n",
    "x_latent = get_hidden_x(path_latent_input, model=label_model_trial_6)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit([x_latent, x_feat, x_bin, x_dir], [y_feat, y_bin, y_dir],batch_size=80, epochs=2000, verbose=1)\n",
    "# latent_dim -- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "6a9deaaa-73de-46c8-b5ce-b81b781933bc",
    "_uuid": "2fc5b7b8-02cc-4d6e-a5c9-7d23d9f9ae61",
    "id": "KUqpVVZHkMDO",
    "outputId": "b7928f97-bc22-43b3-911a-5210641d85cf"
   },
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y)\n",
    "\n",
    "x_latent = get_hidden_x(path_latent_input, model=label_model_trial_6)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit([x_latent, x_feat, x_bin, x_dir], [y_feat, y_bin, y_dir],batch_size=80, epochs=4000, verbose=1)\n",
    "# latent_dim -- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "50d22afa-b702-42ea-9159-3f8d51fa57dd",
    "_uuid": "fdf49b7f-7408-4f46-b7e6-1834f8e06b7b",
    "id": "IfRJTR2NkMDQ",
    "outputId": "c54fc731-a30e-4d68-e951-506592a33ce0"
   },
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y)\n",
    "\n",
    "x_latent = get_hidden_x(path_latent_input, model=label_model_trial_6)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit([x_latent, x_feat, x_bin, x_dir], [y_feat, y_bin, y_dir],batch_size=80, epochs=10000, verbose=1)\n",
    "# latent_dim -- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "6a07e903-708c-4540-be20-b0182dbe0992",
    "_uuid": "2c002962-42e1-4199-8e4a-d126e1bc2d60",
    "id": "LHN6nPH2kMDT",
    "outputId": "f23107a6-adc5-4d6f-ab53-664697649b15"
   },
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y)\n",
    "\n",
    "x_latent = get_hidden_x(path_latent_input, model=label_model_trial_6)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit([x_latent, x_feat, x_bin, x_dir], [y_feat, y_bin, y_dir],batch_size=80, epochs=2000, verbose=1)\n",
    "# latent_dim -- 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "ccafa13c-6b2b-4058-bbb9-3d015b144320",
    "_uuid": "528d0434-13b9-4cd8-b91c-c30e906bacbc",
    "id": "nHYMLRhCkMDV",
    "outputId": "4d1252d9-7397-4868-b8db-6c6954b4a571"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "cf4a251f-ff74-440f-b428-a34680e53d80",
    "_uuid": "a950eee8-a485-423f-93aa-34fcc509b5f6",
    "id": "MzigVVWLkMDW",
    "outputId": "6a1a75b9-dff5-49be-cfb9-fa316b0085bd"
   },
   "outputs": [],
   "source": [
    "from addition_rnn_sample_code import CharacterTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8c987f83-a225-4d2f-af8e-f7ffd6cc7083",
    "_uuid": "6685e634-cb22-4b68-a72b-d143eb4bd351",
    "id": "BUxefYMbkMDX"
   },
   "source": [
    "### dag_arch inference flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow' from 'C:\\\\Users\\\\shakk\\\\Anaconda2\\\\envs\\\\py36\\\\lib\\\\site-packages\\\\tensorflow\\\\__init__.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Unrecognized keyword arguments:', dict_keys(['ragged']))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-3a989f7e5d77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../data/raw/bilstm_model_final.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    228\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No model found in config file.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;31m# set weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    308\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[0;32m    309\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    171\u001b[0m             custom_objects=dict(\n\u001b[0;32m    172\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 list(custom_objects.items())))\n\u001b[0m\u001b[0;32m    174\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[1;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[0mprocess_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[1;34m(layer_data)\u001b[0m\n\u001b[0;32m   1276\u001b[0m       \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdeserialize_layer\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeserialize_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m       \u001b[0mcreated_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    173\u001b[0m                 list(custom_objects.items())))\n\u001b[0;32m    174\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m       \u001b[1;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1605\u001b[0m     \"\"\"\n\u001b[1;32m-> 1606\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized keyword arguments:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Unrecognized keyword arguments:', dict_keys(['ragged']))"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('../../data/raw/bilstm_model_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bd443df3-ce72-435b-bc20-f2b673e71851",
    "_uuid": "160b688a-3821-44e5-be4c-aa6c74fa2489",
    "id": "EGjuZ-xTkMDY",
    "outputId": "67901e96-b601-4c5f-87f0-fed898972d97"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "395af070-3508-413a-8f58-eb975f8dd101",
    "_uuid": "78b84134-65da-459a-a575-599207458b18",
    "id": "FgBQ899HkMDZ",
    "outputId": "042d431f-5766-4a9e-a3c0-43033522f1ad"
   },
   "outputs": [],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "573c4fbd-a228-4c81-ae71-0cb06b63a875",
    "_uuid": "99d8b493-4f2e-4e08-84c2-a7c65b1653bc",
    "id": "T-g0YJG-kMDb",
    "outputId": "b856d74d-289c-4445-a6ae-b4c21c3f7741"
   },
   "outputs": [],
   "source": [
    "dir_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "215355a4-badb-497f-bffc-a4610a41b723",
    "_uuid": "6b073dfc-ba2d-4fb5-b317-dcfed70f39b5",
    "id": "T8E81_0skMDc",
    "outputId": "1e805595-bcb3-410a-e1a5-28f0c388921e"
   },
   "outputs": [],
   "source": [
    "iris['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "918666c6-086c-4314-b3d5-a01bbd6be401",
    "_uuid": "86d46c28-5f91-4b34-aefb-400303037020",
    "id": "H-X3Z1BikMDd"
   },
   "outputs": [],
   "source": [
    "token = 'S'\n",
    "\n",
    "x = iris['data'][0]\n",
    "\n",
    "x_f = x.reshape(1, feature_size)\n",
    "\n",
    "x_feat = np.zeros((1, paths_maxlen, feature_vocab_size), dtype=np.bool)\n",
    "x_bin = np.zeros((1, paths_maxlen, bin_vocab_size), dtype=np.bool)\n",
    "x_dir = np.zeros((1, paths_maxlen, dir_vocab_size), dtype=np.bool)\n",
    "\n",
    "x_latent = get_hidden_x(x_f, model=label_model_trial_6)\n",
    "x_latent = x_latent.reshape(1, latent_dim)\n",
    "\n",
    "x_feat[0, 0, feature_indices[token]] = 1\n",
    "x_bin[0, 0, 0] = 1 # Start token for bin is 0. End token is 1.\n",
    "x_feat[0, 0, dir_indices[token]] = 1\n",
    "pred = label_model_trial_6.predict(x_f)\n",
    "label = [np.argmax(pred[0])]\n",
    "\n",
    "pred = model.predict([x_latent, x_feat, x_bin, x_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "ee5a5840-541b-4ded-84c9-2cd57d9aca8b",
    "_uuid": "34dce9bc-bb45-4300-b6b3-ce9051f31dc7",
    "id": "j1TVlMt9kMDf",
    "outputId": "1c1679a7-aa43-47e8-f4bd-9a47807f7310"
   },
   "outputs": [],
   "source": [
    "pred[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "720040fd-9569-49ba-bf2e-6052b248c5b1",
    "_uuid": "4635f8dd-b2cf-4263-9f59-f2b126272829",
    "id": "2lKNdscOkMDg"
   },
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    latent_dim = 25\n",
    "    x_f = x.reshape(1, feature_size)\n",
    "    token = 'S'\n",
    "    cont = True\n",
    "    path = [token]\n",
    "    # x_path = np.zeros((1, paths_maxlen, path_vocab_size), dtype=np.bool)\n",
    "    x_feat = np.zeros((1, paths_maxlen, feature_vocab_size), dtype=np.bool)\n",
    "    x_bin = np.zeros((1, paths_maxlen, bin_vocab_size), dtype=np.bool)\n",
    "    x_dir = np.zeros((1, paths_maxlen, dir_vocab_size), dtype=np.bool)\n",
    "\n",
    "    x_latent = get_hidden_x(x_f, model=label_model_trial_6)\n",
    "    x_latent = x_latent.reshape(1, latent_dim)\n",
    "    # x_path[0, 0, label_indices[token]] = 1\n",
    "    x_feat[0, 0, feature_indices[token]] = 1\n",
    "    x_bin[0, 0, 0] = 1 # Start token for bin is 0. End token is 1.\n",
    "    x_feat[0, 0, dir_indices[token]] = 1\n",
    "    pred = label_model_trial_6.predict(x_f)\n",
    "    label = [np.argmax(pred[0])]\n",
    "    index = 1\n",
    "    while cont & (index < paths_maxlen):\n",
    "        # pred = combined_model.predict([x_latent, x_path])\n",
    "        pred = model.predict([x_latent, x_feat, x_bin, x_dir])\n",
    "        feature_index = np.argmax(pred[0])\n",
    "        bin_index = np.argmax(pred[1])\n",
    "        dir_index = np.argmax(pred[2])\n",
    "        x_feat[0, index, feature_index] = 1\n",
    "        x_bin[0, index, bin_index] = 1\n",
    "        x_dir[0, index, dir_index] = 1\n",
    "        next_feat = indices_feat[feature_index]\n",
    "        next_bin = indices_bin[bin_index]\n",
    "        next_dir = indices_dir[dir_index]\n",
    "        if next_feat == 'E':\n",
    "            path.append('E')\n",
    "            cont = False\n",
    "        elif next_bin == 1 or next_dir == 'E' or next_bin == 0 or next_dir == 'S':\n",
    "            if next_bin == 1 or next_bin == 0:\n",
    "                x_bin[0, index, bin_index] = 0\n",
    "                # bin_index = np.argmax(np.argsort(pred[1]) == 15)\n",
    "                bin_index = np.argmax(pred[1][0][2:]) + 2\n",
    "                x_bin[0, index, bin_index] = 1\n",
    "                next_bin = indices_bin[bin_index]\n",
    "            else:\n",
    "                x_dir[0, index, dir_index] = 0\n",
    "                # dir_index = np.argmax(np.argsort(pred[2]) == 2)\n",
    "                dir_index = np.argmax(pred[2][0][2:]) + 2\n",
    "                x_dir[0, index, dir_index] = 1\n",
    "                next_dir = indices_dir[dir_index]\n",
    "            print('-----from second ifelse', [next_feat, next_bin, next_dir])\n",
    "            path.append(''.join([next_feat, next_bin, next_dir]))\n",
    "            index += 1            \n",
    "        else:\n",
    "            print('-----', [next_feat, next_bin, next_dir])\n",
    "            path.append(''.join([next_feat, next_bin, next_dir]))\n",
    "            index += 1\n",
    "\n",
    "#     if path[-1] != 'E':\n",
    "#         path.append('E')\n",
    "\n",
    "    return [path, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "a5f34746-54fd-4f84-986f-7d98a6579a5c",
    "_uuid": "d7c14e9f-f903-4f0b-8bb3-c0d028685a66",
    "id": "WB9jIQbGkMDh",
    "outputId": "b86907a2-c749-4289-8b19-40c4a50244eb"
   },
   "outputs": [],
   "source": [
    "dir_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "6e536349-1b7f-4f07-bfa6-65ed3df36a57",
    "_uuid": "36ae371f-4d3b-4b03-b8f9-15100f4e77e9",
    "id": "Js9sZlsIkMDi",
    "outputId": "2a300b13-f945-45ec-d9df-a27edeaf4668"
   },
   "outputs": [],
   "source": [
    "bin_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "e9722740-ebdc-4287-91c0-812076485a58",
    "_uuid": "a80c3726-2bcd-4c97-b9c3-0e16673c962b",
    "id": "kqFrHcKOkMDj",
    "outputId": "f240f449-c06b-4d80-eebb-bcef3f9e0a56"
   },
   "outputs": [],
   "source": [
    "test_value = np.array([1,3,2,5])\n",
    "np.argmax(np.argsort(test_value) == 2)\n",
    "np.argmax(test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "fb9114be-1e49-41e9-b2b9-803f0558afd6",
    "_uuid": "71efe0bc-5b01-42bc-897d-6601bbf7f43e",
    "id": "KdOL-kYbkMDl"
   },
   "outputs": [],
   "source": [
    "shuffle_data[4] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "ac03bfa1-0e49-4304-90d0-104a8d598093",
    "_uuid": "c4671c0c-172e-42ab-97bc-5dc620ba0869",
    "id": "riWEMwSZkMDm",
    "outputId": "a252cf57-c7b1-476e-daf1-85e437caae34"
   },
   "outputs": [],
   "source": [
    "shuffle_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "2a468db3-7b48-4069-a348-57adafd7efb3",
    "_uuid": "1e77f6dd-abc9-43e8-868a-e472442617e2",
    "id": "w7wavbvikMDo",
    "outputId": "beb28749-8789-41bd-8be5-57792523c590"
   },
   "outputs": [],
   "source": [
    "shuffle_data.iloc[1, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "c57ab2e2-ecda-4309-b114-2842fa761752",
    "_uuid": "411c304c-71f0-4549-9b55-7cdc91645ea3",
    "id": "r7EHv9IRkMDp"
   },
   "outputs": [],
   "source": [
    "def score():\n",
    "    count = []\n",
    "    bleu_score = []\n",
    "    j_coeff = []\n",
    "    l_dist = []\n",
    "    path_mismatch_count = []\n",
    "    traverse_check_count = []\n",
    "    order_mismatch_count = []\n",
    "    subset_path_count = []\n",
    "    # for i in range(test_data.shape[0]):\n",
    "    for i in range(140,150):\n",
    "        curr_feat = np.array([shuffle_data.iloc[i, 0:X.shape[1]]])\n",
    "        path, label = predict(curr_feat)\n",
    "        actual_path = shuffle_data.iloc[i, -1]\n",
    "\n",
    "#         actual_path_tok = [label_indices[char] for char in actual_path]\n",
    "#         pred_path_tok = [label_indices[char] for char in path]\n",
    "\n",
    "        # j_coeff.append(super().get_j_coeff(actual_path_tok, pred_path_tok))\n",
    "\n",
    "        print('actual vs predicted: ', shuffle_data.iloc[i, -1], ' vs ', ' '.join(\n",
    "            path), 'labels: ', shuffle_data.iloc[i,4], label[0])\n",
    "        count.append(shuffle_data.iloc[i,4] == label[0])\n",
    "        # print('Actual path -- ', actual_path)\n",
    "        # print('Pred path -- ', path)\n",
    "        if actual_path != path:\n",
    "            print(' -- Path mismatch -- ')\n",
    "            if sorted(actual_path) == sorted(path):\n",
    "                print(' -- Order mismatch -- ')\n",
    "                order_mismatch_count.append(1)\n",
    "            else:\n",
    "                path_mismatch_count.append(1)\n",
    "                # pred_target, subset_path = self.check_path(path)\n",
    "                pred_val = return_yval(path, i+1)\n",
    "                # subset_path_count.append(subset_path)\n",
    "                if pred_val != -1 and pred_val == shuffle_data.iloc[i,4]:\n",
    "                    traverse_check_count.append(1)\n",
    "\n",
    "\n",
    "        path = list(''.join(path))\n",
    "        actual_path = list(''.join(shuffle_data.iloc[i, -1]))\n",
    "        bleu_score.append(sentence_bleu([actual_path], path))\n",
    "\n",
    "#         lev_path = []\n",
    "#         for i in range(len(path)):\n",
    "#             if i in ['S','L','R','E']:\n",
    "#                 lev_path.append(i)\n",
    "#         l_dist.append(distance.levenshtein(\n",
    "#             self.df.iloc[i, self.X.shape[1]].replace(' ', ''), ''.join(lev_path)))\n",
    "\n",
    "\n",
    "    print('\\nLabel accuracy - ', np.mean(count))\n",
    "#     print('Path metric (Jaccard) - ', np.mean(j_coeff))\n",
    "#     print('Path metric (Levenshtein) - ', np.mean(l_dist))\n",
    "    print('Path mismatch count - ', np.sum(path_mismatch_count))\n",
    "    print('Right traverse count - ', np.sum(traverse_check_count))\n",
    "    print('Order mismatch count - ', np.sum(order_mismatch_count))\n",
    "#     print('Subset path count - ', np.sum(subset_path_count))\n",
    "    print('Bleu score of paths - ', np.mean(bleu_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "1328448a-b7bb-4c16-9498-f329e9571b5f",
    "_uuid": "9a6287db-9d3d-42ca-a1ad-d5c7c949d74d",
    "id": "4tqrLJNSkMDq",
    "outputId": "369bf6a8-d317-4f1e-827b-e95c832ddc86"
   },
   "outputs": [],
   "source": [
    "score() ## 3000 epochs, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "80ce8833-8c59-4abb-9ea7-fbc1b58fa04a",
    "_uuid": "ab4aa282-7b7c-4dfe-9db2-5e43af657dd9",
    "id": "DmMZso6IkMDr",
    "outputId": "c11baed9-28d4-4998-886f-4b4fb150125f"
   },
   "outputs": [],
   "source": [
    "bin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "615cd976-bca4-4e7b-ba9c-2abf6ae6aa09",
    "_uuid": "e329c1ec-5e81-4247-b714-7185f0fc0e88",
    "id": "Benhk-s2kMDt",
    "outputId": "711a6408-1c0d-4dac-ee92-61a998896274"
   },
   "outputs": [],
   "source": [
    "score() ## 2000 epochs, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "674ff810-c5c9-4933-a945-58670d827310",
    "_uuid": "760bfb9b-2507-4bc0-93ee-b0804dc42dcb",
    "id": "EbzE3aExkMDv",
    "outputId": "532929f9-9d9d-4eff-a021-5e32a2340ef7"
   },
   "outputs": [],
   "source": [
    "score() ## 3000 epochs, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "c828a965-7cf8-445d-a244-463f6ce3deb5",
    "_uuid": "68ab9b08-2ce4-4613-bbe2-dee812d58215",
    "id": "kAOCsMkRkMDw"
   },
   "outputs": [],
   "source": [
    "## Global tree comparison\n",
    "## Neural fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "666fb9db-f3c0-4524-a07a-8fff5b6ddc54",
    "_uuid": "11ace1df-b2bc-45d2-98a1-19b4317a75c7",
    "id": "AT3x_s-7kMDx"
   },
   "outputs": [],
   "source": [
    "test_value = [0.99, 0.98, 0.32, 0.51]\n",
    "a = np.argsort(test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "82f18685-a42c-465c-b7c9-395738a77328",
    "_uuid": "91422c4b-7545-4f00-8bd2-28cb6ba20c21",
    "id": "-z5_-EOykMDy",
    "outputId": "076b828e-775d-4806-eb54-533a8b1a9462"
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "72c57104-ff3e-464d-853d-f6f5a1d20ca1",
    "_uuid": "84b17f57-7516-478e-b926-08a6289ab518",
    "id": "RxK6mlC_kMD0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "d4cd3e60-89da-45c7-9e9f-9fc757b45d37",
    "_uuid": "c4cd77e6-fc8b-4d4f-8648-90c5477f3248",
    "id": "UiAs8D8LkMD3",
    "outputId": "f2733264-d715-4776-e2b0-eab1ca46a4ea"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "57e54caa-f037-4f73-9d83-1792625e85d2",
    "_uuid": "f0b09016-a3a8-4551-9b62-b8398e4241dd",
    "id": "0rYxc_-vkMD5"
   },
   "outputs": [],
   "source": [
    "## Second best argmax for bin_gru and dir_gru\n",
    "## Stack one more gru cell on bin_gru\n",
    "## normal LSTM\n",
    "## Bipartite\n",
    "## Path invariance\n",
    "## Agreement between all grus as error metric(in terms of end token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "097a4f3b-d5c5-4e40-b888-82dc34d014ad",
    "_uuid": "afe36cf2-33cd-42f4-927a-c74638cdae74",
    "id": "yXiqMr7lkMD7"
   },
   "outputs": [],
   "source": [
    "indices_feat = {}\n",
    "indices_bin = {}\n",
    "indices_dir = {}\n",
    "for val, i in feature_indices.items():\n",
    "    indices_feat.update({i: val})\n",
    "for val, i in bin_indices.items():\n",
    "    indices_bin.update({i: val})\n",
    "for val, i in dir_indices.items():\n",
    "    indices_dir.update({i: val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "1bde6ade-5614-4bf2-925a-15ae0ef2ad6d",
    "_uuid": "5fb74dcc-f46f-4fdf-944d-b6cfc232a8c1",
    "id": "Z-K1-srKkMD9",
    "outputId": "0d62b8a8-3c4b-4359-9337-7eb175427e34"
   },
   "outputs": [],
   "source": [
    "indices_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "922ad30f-e817-4871-97f3-fc7157299b8d",
    "_uuid": "72b24841-f1b9-4dd0-895b-9711f36c7478",
    "id": "dBxbpUK8kMD_",
    "outputId": "29ccfef3-1c6c-400d-8a07-14a946b3af0d"
   },
   "outputs": [],
   "source": [
    "indices_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "9c622419-36b8-42c5-85b1-fe3219b93655",
    "_uuid": "6ff149a1-1e2e-4239-8a81-38cfbd635a3c",
    "id": "z85fzIgWkMEB",
    "outputId": "9c656df9-1377-4b77-859f-c20065da8a21"
   },
   "outputs": [],
   "source": [
    "indices_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "8900c315-d0b5-4c17-955b-2b6cedac046c",
    "_uuid": "70ab6e4e-bbb1-4f39-8213-ee6b78495750",
    "id": "aLfWsbQskMEC",
    "outputId": "b5a2f613-da4a-437f-db32-bfefbfa1393e"
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "d3b83d63-ab8b-43af-90f8-53c4422e2340",
    "_uuid": "5d00ac3d-cd1f-4ac3-9730-b2a22ed259ee",
    "id": "fYEMf9sukMEE",
    "outputId": "0207d932-1af6-4e63-8c3e-456cfa458e97"
   },
   "outputs": [],
   "source": [
    "bin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "f4b11e6d-4b63-4303-a844-9e9577cbaaec",
    "_uuid": "fd28afe0-0d37-4d4a-b72a-5630c7911240",
    "id": "CqBqu1FNkMEF",
    "outputId": "3195edfa-10bf-4506-f80a-6c1dd6d473a7"
   },
   "outputs": [],
   "source": [
    "bin_labels.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "790973ad-3f97-4a98-8e69-d6b3d1e4b635",
    "_uuid": "710deee4-d992-4fe8-820c-62143f4db59c",
    "id": "rHOilsqLkMEH"
   },
   "source": [
    "### Bipartite graph trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "ec63dd9c-16f6-4369-9d3f-3ad37f4bf7b4",
    "_uuid": "28608709-6203-47f0-bd11-f8e84bc96dfd",
    "id": "ERRNoVlDkMEH"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "B = nx.Graph()\n",
    "B.add_nodes_from(bin_labels['x'], bipartite=0)\n",
    "B.add_nodes_from(bin_labels['new_bins'], bipartite=1)\n",
    "# Add edges only between nodes of opposite node sets\n",
    "# B.add_edges_from([(1, 'a'), (1, 'b'), (2, 'b'), (2, 'c'), (3, 'c'), (4, 'a')])\n",
    "B.add_edges_from([(row['x'], row['new_bins']) for idx, row in bin_labels.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "bd8d44c2-bdc2-43e0-8137-4940bff2aa94",
    "_uuid": "fc2c3c44-de96-4d80-95fa-64f866da4a84",
    "id": "s0nYjcyVkMEI",
    "outputId": "db53d5a6-ff4d-4cd1-b342-89b4a367753b"
   },
   "outputs": [],
   "source": [
    "# labels = dict((n, \"(\" + n + \",\" + d['_type'] + \")\") for n,d in B.nodes(data=True))\n",
    "labels = dict((n, d) for n,d in B.nodes(data=True))\n",
    "pos = {node:[0, i] for i,node in enumerate(bin_labels['x'])}\n",
    "pos.update({node:[1, i] for i,node in enumerate(bin_labels['new_bins'])})\n",
    "nx.draw(B, pos, with_labels=False)\n",
    "for p in pos:  # raise text positions\n",
    "    pos[p][1] += 0.25\n",
    "nx.draw_networkx_labels(B, pos)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "36094af7-83fa-4110-8dd2-5081ac77e7bf",
    "_uuid": "6b81a6f6-5988-4a0c-993a-2180f7221ae7",
    "id": "NyShiAPzkMEJ",
    "outputId": "6fa0e8db-d032-436d-882f-d4abde8c313f"
   },
   "outputs": [],
   "source": [
    "B.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "3d1f4711-0614-4c10-88e4-6d0593de5f56",
    "_uuid": "c0d88501-1802-45e6-b59c-ba87f3536234",
    "id": "ekZbL2FHkMEL"
   },
   "outputs": [],
   "source": [
    "labels_as_dict = dict((val['label'], val['x']) for key, val in bin_labels.iterrows() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "76c95dc4-7835-4c23-8878-513f595374b1",
    "_uuid": "437e1c42-bafa-40d1-b517-cf2b682e23e4",
    "id": "bYA0ZWaykMEM",
    "outputId": "5867b5ad-84df-4ef4-b543-e8b2ad7cd523"
   },
   "outputs": [],
   "source": [
    "labels_as_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "f1841fb9-5ae8-4540-81bf-4bfa869dd348",
    "_uuid": "74c1920f-7739-43d2-a0c3-83ec723d7a70",
    "id": "SymRwXAjkMEN"
   },
   "outputs": [],
   "source": [
    "new_bins_df = bin_labels.loc[:,('new_labels','new_bins')].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "85bc095b-8e27-4f3d-830c-eb9ee734f0cb",
    "_uuid": "a59062d9-95ba-4340-8f53-2af9fb416b0b",
    "id": "1NeokD0XkMEO",
    "outputId": "9c36cf67-2eea-4d51-fb8f-5743cdc0a92d"
   },
   "outputs": [],
   "source": [
    "new_bins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "ff9956fb-9a44-4fdf-9e83-662992b00956",
    "_uuid": "08dea0e0-21ae-4e0d-80e7-50f30233b79c",
    "id": "51yM0e9bkMEQ"
   },
   "outputs": [],
   "source": [
    "labels_as_dict.update(dict((val['new_labels'], val['new_bins']) for key, val in new_bins_df.iterrows() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "dfbc8947-61b3-4cbf-88f1-6de75f71ddfb",
    "_uuid": "9b7ca8ab-7bbb-49f6-8b7a-b1fc3a799ec6",
    "id": "g69KlwJckMES",
    "outputId": "2431d321-06c4-4b00-f434-e11cd49d71fb"
   },
   "outputs": [],
   "source": [
    "labels_as_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "cf8385ba-b07f-486f-b605-779d6b14c5b8",
    "_uuid": "7194126c-0ce1-43a7-8366-37ec6b84979b",
    "id": "qaGX6CCgkMET",
    "outputId": "9da35b4a-ce78-45f7-a513-957ad03245cf"
   },
   "outputs": [],
   "source": [
    "dict((n, d) for n,d in B.nodes(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "0d1700b9-2718-49cb-9abd-af4c3d2c6c32",
    "_uuid": "8fc5b8b6-9648-4c92-8653-5290a527e0c6",
    "id": "X5DB7denkMEU",
    "outputId": "8211dbdf-2715-4c6d-8b8a-480c0189c3a0"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BG = nx.Graph()\n",
    "employees = [str(i) for i in range(3)]\n",
    "movies = [\"mA\", \"mB\", \"mC\"]\n",
    "BG.add_nodes_from(employees, bipartite=0, _type='emp')\n",
    "BG.add_nodes_from(movies, bipartite=1, _type='mov')\n",
    "edges = [(\"0\", \"mA\"), (\"0\", \"mC\"), (\"1\", \"mA\"),(\"1\", \"mB\"), (\"2\", \"mA\")]\n",
    "BG.add_edges_from(edges)\n",
    "labels = dict((n, \"(\" + n + \",\" + d['_type'] + \")\") for n,d in BG.nodes(data=True))\n",
    "\n",
    "# Setting up pos for drawing bipartite graph. See the reference for more info\n",
    "X, Y = bipartite.sets(BG)\n",
    "pos = dict()\n",
    "pos.update( (n, (1, i)) for i, n in enumerate(X) ) # put nodes from X at x=1\n",
    "pos.update( (n, (2, i)) for i, n in enumerate(Y) ) # put nodes from Y at x=2\n",
    "\n",
    "plt.figure()\n",
    "edges = BG.edges()\n",
    "nx.draw_networkx(BG, pos, edges=edges, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "3834c337-23b9-4e2d-9f3c-33ae3e89f5aa",
    "_uuid": "1b0da50a-eb67-4d7e-95f0-b9d70ff074a7",
    "id": "0yN0Hdj1kMEV",
    "outputId": "d0215332-2a02-47c0-da81-67d318527e72"
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "7b184187-0308-479a-9ba4-c3057c9a22ce",
    "_uuid": "3bf06a0f-423b-4db2-9ed6-2f21e0c12e78",
    "id": "5CtYeuLbkMEX",
    "outputId": "e87f0469-43d5-447c-b293-da20d436233c"
   },
   "outputs": [],
   "source": [
    "bin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "727a0670-81a3-4619-9a90-1cd104f69f15",
    "_uuid": "55bc07f5-898a-40f4-b672-0597b5c78eca",
    "id": "CA4HHo59kMEY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1.4-sa-adult-local-decision-tree-trials.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242.1px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
